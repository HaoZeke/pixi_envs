From 2a07d5ba1829272c6f4b0036545e4f38d0c41c8c Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Wed, 14 May 2025 15:49:13 +0200
Subject: [PATCH 01/37] Add pair_style metatomic, including the kokkos variant

---
 cmake/CMakeLists.txt                          |    5 +-
 cmake/Modules/Packages/KOKKOS.cmake           |    4 +
 cmake/Modules/Packages/ML-METATOMIC.cmake     |  118 +
 cmake/presets/all_off.cmake                   |    1 +
 cmake/presets/all_on.cmake                    |    1 +
 cmake/presets/nolib.cmake                     |    1 +
 examples/PACKAGES/metatomic/.gitignore        |    2 +
 .../PACKAGES/metatomic/create-lj-nickel.py    |   34 +
 .../PACKAGES/metatomic/in.kokkos.metatomic    |   31 +
 examples/PACKAGES/metatomic/in.metatomic      |   27 +
 examples/PACKAGES/metatomic/nickel-lj.pt      |  Bin 0 -> 47169 bytes
 metatensor.patch                              | 4127 +++++++++++++++++
 src/KOKKOS/metatomic_system_kokkos.cpp        |  392 ++
 src/KOKKOS/metatomic_system_kokkos.h          |   99 +
 src/KOKKOS/pair_metatomic_kokkos.cpp          |  283 ++
 src/KOKKOS/pair_metatomic_kokkos.h            |   50 +
 src/ML-METATOMIC/metatomic_system.cpp         |  561 +++
 src/ML-METATOMIC/metatomic_system.h           |  143 +
 src/ML-METATOMIC/metatomic_timer.cpp          |   63 +
 src/ML-METATOMIC/metatomic_timer.h            |   42 +
 src/ML-METATOMIC/metatomic_types.cpp          |   97 +
 src/ML-METATOMIC/metatomic_types.h            |   56 +
 src/ML-METATOMIC/pair_metatomic.cpp           |  564 +++
 src/ML-METATOMIC/pair_metatomic.h             |   72 +
 src/ML-METATOMIC/patch-torch.sh               |   45 +
 src/STUBS/mpi.cpp                             |    7 +
 src/STUBS/mpi.h                               |    7 +
 27 files changed, 6830 insertions(+), 2 deletions(-)
 create mode 100644 cmake/Modules/Packages/ML-METATOMIC.cmake
 create mode 100644 examples/PACKAGES/metatomic/.gitignore
 create mode 100644 examples/PACKAGES/metatomic/create-lj-nickel.py
 create mode 100644 examples/PACKAGES/metatomic/in.kokkos.metatomic
 create mode 100644 examples/PACKAGES/metatomic/in.metatomic
 create mode 100644 examples/PACKAGES/metatomic/nickel-lj.pt
 create mode 100644 metatensor.patch
 create mode 100644 src/KOKKOS/metatomic_system_kokkos.cpp
 create mode 100644 src/KOKKOS/metatomic_system_kokkos.h
 create mode 100644 src/KOKKOS/pair_metatomic_kokkos.cpp
 create mode 100644 src/KOKKOS/pair_metatomic_kokkos.h
 create mode 100644 src/ML-METATOMIC/metatomic_system.cpp
 create mode 100644 src/ML-METATOMIC/metatomic_system.h
 create mode 100644 src/ML-METATOMIC/metatomic_timer.cpp
 create mode 100644 src/ML-METATOMIC/metatomic_timer.h
 create mode 100644 src/ML-METATOMIC/metatomic_types.cpp
 create mode 100644 src/ML-METATOMIC/metatomic_types.h
 create mode 100644 src/ML-METATOMIC/pair_metatomic.cpp
 create mode 100644 src/ML-METATOMIC/pair_metatomic.h
 create mode 100755 src/ML-METATOMIC/patch-torch.sh

diff --git a/cmake/CMakeLists.txt b/cmake/CMakeLists.txt
index f22fa401a26..85e2e1e35e7 100644
--- a/cmake/CMakeLists.txt
+++ b/cmake/CMakeLists.txt
@@ -162,7 +162,7 @@ endif()
 if(CMAKE_CXX_STANDARD LESS 17)
   message(WARNING "Selecting C++17 standard is preferred over C++${CMAKE_CXX_STANDARD}")
 endif()
-if(PKG_KOKKOS AND (CMAKE_CXX_STANDARD LESS 17))
+if((PKG_KOKKOS OR PKG_ML-METATOMIC) AND (CMAKE_CXX_STANDARD LESS 17))
   set(CMAKE_CXX_STANDARD 17)
 endif()
 # turn off C++17 check in lmptype.h
@@ -324,6 +324,7 @@ set(STANDARD_PACKAGES
   MISC
   ML-HDNNP
   ML-IAP
+  ML-METATOMIC
   ML-PACE
   ML-POD
   ML-QUIP
@@ -605,7 +606,7 @@ else()
 endif()
 
 foreach(PKG_WITH_INCL KSPACE PYTHON ML-IAP VORONOI COLVARS ML-HDNNP MDI MOLFILE NETCDF
-        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE LEPTON EXTRA-COMMAND)
+        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE ML-METATOMIC LEPTON EXTRA-COMMAND)
   if(PKG_${PKG_WITH_INCL})
     include(Packages/${PKG_WITH_INCL})
   endif()
diff --git a/cmake/Modules/Packages/KOKKOS.cmake b/cmake/Modules/Packages/KOKKOS.cmake
index f878db654cc..f699ae0192f 100644
--- a/cmake/Modules/Packages/KOKKOS.cmake
+++ b/cmake/Modules/Packages/KOKKOS.cmake
@@ -203,6 +203,10 @@ if(PKG_ML-IAP)
   endif()
 endif()
 
+if(PKG_ML-METATOMIC)
+  list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/metatomic_system_kokkos.cpp)
+endif()
+
 if(PKG_PHONON)
   list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/dynamical_matrix_kokkos.cpp)
   list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/third_order_kokkos.cpp)
diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
new file mode 100644
index 00000000000..f187c7bc10a
--- /dev/null
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -0,0 +1,118 @@
+# metatensor requires C++17 due to Torch requiring C++17
+if(CMAKE_CXX_STANDARD LESS 17)
+  message(FATAL_ERROR "The ML-METATOMIC package requires the C++ standard to
+be set to at least C++17")
+endif()
+
+if (BUILD_OMP AND APPLE)
+    message(FATAL_ERROR
+        "Can not enable both BUILD_OMP and PGK_ML-METATOMIC on Apple systems, "
+        "since this results in two different versions of the OpenMP library (one "
+        "from the system and one from Torch) being linked to the final "
+        "executable, which then crashes"
+    )
+endif()
+
+# Bring the `torch` target in scope to allow evaluation
+# of cmake generator expression from `metatensor_torch`
+find_package(Torch REQUIRED)
+
+# The caffe2::mkl target contains MKL_INCLUDE_DIR in it's
+# INTERFACE_INCLUDE_DIRECTORIES even if MKL was not found, causing a build
+# failure with "Imported target "torch" includes non-existent path" down the
+# line. This code removes the missing path from INTERFACE_INCLUDE_DIRECTORIES,
+# allowing the build to continue further.
+if (TARGET caffe2::mkl)
+    get_target_property(CAFFE2_MKL_INCLUDE_DIRECTORIES caffe2::mkl INTERFACE_INCLUDE_DIRECTORIES)
+    set(MKL_INCLUDE_DIR_NOTFOUND "")
+    foreach(_include_dir_ ${CAFFE2_MKL_INCLUDE_DIRECTORIES})
+        if ("${_include_dir_}" MATCHES "MKL_INCLUDE_DIR-NOTFOUND")
+            set(MKL_INCLUDE_DIR_NOTFOUND "${_include_dir_}")
+        endif()
+    endforeach()
+
+    if (NOT "${MKL_INCLUDE_DIR_NOTFOUND}" STREQUAL "")
+        list(REMOVE_ITEM CAFFE2_MKL_INCLUDE_DIRECTORIES "${MKL_INCLUDE_DIR_NOTFOUND}")
+    endif()
+    set_target_properties(caffe2::mkl PROPERTIES
+        INTERFACE_INCLUDE_DIRECTORIES "${CAFFE2_MKL_INCLUDE_DIRECTORIES}"
+    )
+endif()
+
+################ definition of metatensor and metatomic targets ################
+
+set(METATENSOR_CORE_VERSION "0.1.14")
+set(METATENSOR_CORE_SHA1 "9e21c48d9059d8a37618958d9d253220dedf7562")
+
+set(METATENSOR_TORCH_VERSION "0.7.6")
+set(METATENSOR_TORCH_SHA1 "5668f5088a42507e9ca4a7b723b3baac0286035c")
+
+set(METATOMIC_TORCH_VERSION "0.1.0")
+set(METATOMIC_TORCH_SHA1 "a9d86ba4b9b6b8c367f9f21d3363e152b73833bf")
+
+set(DOWNLOAD_METATENSOR_DEFAULT ON)
+find_package(metatensor_torch QUIET ${METATOMIC_TORCH_VERSION})
+if (metatensor_torch_FOUND)
+    set(DOWNLOAD_METATENSOR_DEFAULT OFF)
+endif()
+
+set(DOWNLOAD_METATOMIC_DEFAULT ON)
+find_package(metatomic_torch QUIET ${METATOMIC_TORCH_VERSION})
+if (metatomic_torch_FOUND)
+    set(DOWNLOAD_METATOMIC_DEFAULT OFF)
+endif()
+
+
+option(DOWNLOAD_METATOMIC "Download metatomic package instead of using an already installed one" ${DOWNLOAD_METATOMIC_DEFAULT})
+option(DOWNLOAD_METATENSOR "Download metatensor package instead of using an already installed one" ${DOWNLOAD_METATENSOR_DEFAULT})
+
+if (DOWNLOAD_METATENSOR)
+    include(FetchContent)
+
+    set(URL_BASE "https://github.com/metatensor/metatensor/releases/download")
+    FetchContent_Declare(metatensor
+        URL ${URL_BASE}/metatensor-core-v${METATENSOR_CORE_VERSION}/metatensor-core-cxx-${METATENSOR_CORE_VERSION}.tar.gz
+        URL_HASH SHA1=${METATENSOR_CORE_SHA1}
+    )
+
+    message(STATUS "Fetching metatensor v${METATENSOR_CORE_VERSION} from github")
+    FetchContent_MakeAvailable(metatensor)
+
+    FetchContent_Declare(metatensor-torch
+        URL ${URL_BASE}/metatensor-torch-v${METATENSOR_TORCH_VERSION}/metatensor-torch-cxx-${METATENSOR_TORCH_VERSION}.tar.gz
+        URL_HASH SHA1=${METATENSOR_TORCH_SHA1}
+    )
+
+    message(STATUS "Fetching metatensor-torch v${METATENSOR_TORCH_VERSION} from github")
+    FetchContent_MakeAvailable(metatensor-torch)
+else()
+    # make sure to fail the configuration if cmake can not find metatensor-torch
+    find_package(metatensor_torch REQUIRED ${METATENSOR_TORCH_VERSION})
+endif()
+
+if (DOWNLOAD_METATOMIC)
+    include(FetchContent)
+
+    # set(URL_BASE "https://github.com/metatensor/metatomic/releases/download")
+    # FetchContent_Declare(metatomic-torch
+    #     URL ${URL_BASE}/metatomic-torch-v${METATOMIC_TORCH_VERSION}/metatomic-torch-cxx-${METATOMIC_TORCH_VERSION}.tar.gz
+    #     URL_HASH SHA1=${METATOMIC_TORCH_SHA1}
+    # )
+
+    FetchContent_Declare(metatomic-torch
+        GIT_REPOSITORY https://github.com/Luthaf/metatomic
+        GIT_TAG c078c2ca8f9060f9a3a384b15ba464c416ff77d0
+        SOURCE_SUBDIR metatomic-torch
+    )
+
+    message(STATUS "Fetching metatomic-torch v${METATOMIC_TORCH_VERSION} from github")
+    FetchContent_MakeAvailable(metatomic-torch)
+else()
+    # make sure to fail the configuration if cmake can not find metatensor-torch
+    find_package(metatomic_torch REQUIRED ${METATOMIC_TORCH_VERSION})
+endif()
+
+
+################ lammps target modifications ################
+
+target_link_libraries(lammps PUBLIC metatomic_torch metatensor_torch)
diff --git a/cmake/presets/all_off.cmake b/cmake/presets/all_off.cmake
index f2f57824804..4d1e7067839 100644
--- a/cmake/presets/all_off.cmake
+++ b/cmake/presets/all_off.cmake
@@ -56,6 +56,7 @@ set(ALL_PACKAGES
   MISC
   ML-HDNNP
   ML-IAP
+  ML-METATOMIC
   ML-PACE
   ML-POD
   ML-QUIP
diff --git a/cmake/presets/all_on.cmake b/cmake/presets/all_on.cmake
index 8dc4632138f..1649098d979 100644
--- a/cmake/presets/all_on.cmake
+++ b/cmake/presets/all_on.cmake
@@ -58,6 +58,7 @@ set(ALL_PACKAGES
   MISC
   ML-HDNNP
   ML-IAP
+  ML-METATOMIC
   ML-PACE
   ML-POD
   ML-QUIP
diff --git a/cmake/presets/nolib.cmake b/cmake/presets/nolib.cmake
index 4a4a5575055..852fa0e802f 100644
--- a/cmake/presets/nolib.cmake
+++ b/cmake/presets/nolib.cmake
@@ -16,6 +16,7 @@ set(PACKAGES_WITH_LIB
   MACHDYN
   MDI
   ML-HDNNP
+  ML-METATOMIC
   ML-PACE
   ML-QUIP
   MOLFILE
diff --git a/examples/PACKAGES/metatomic/.gitignore b/examples/PACKAGES/metatomic/.gitignore
new file mode 100644
index 00000000000..d848bd9194f
--- /dev/null
+++ b/examples/PACKAGES/metatomic/.gitignore
@@ -0,0 +1,2 @@
+collected-extensions/
+nickel-lj-extensions.pt
diff --git a/examples/PACKAGES/metatomic/create-lj-nickel.py b/examples/PACKAGES/metatomic/create-lj-nickel.py
new file mode 100644
index 00000000000..bea8ca4eaf3
--- /dev/null
+++ b/examples/PACKAGES/metatomic/create-lj-nickel.py
@@ -0,0 +1,34 @@
+try:
+    import metatomic_lj_test
+except ImportError as e:
+    raise ImportError(
+        "could not import metatomic_lj_test, please install it with "
+        "`pip install git+https://github.com/metatensor/lj-test/`"
+    ) from e
+
+
+model = metatomic_lj_test.lennard_jones_model(
+    atomic_type=28,
+    cutoff=6.5,
+    sigma=1.5808,
+    epsilon=0.1729,
+    length_unit="Angstrom",
+    energy_unit="eV",
+    with_extension=False,
+)
+
+model.save("nickel-lj.pt")
+print("created 'nickel-lj.pt' model")
+
+
+model = metatomic_lj_test.lennard_jones_model(
+    atomic_type=28,
+    cutoff=6.5,
+    sigma=1.5808,
+    epsilon=0.1729,
+    length_unit="Angstrom",
+    energy_unit="eV",
+    with_extension=True,
+)
+model.save("nickel-lj-extensions.pt", collect_extensions="collected-extensions/")
+print("created 'nickel-lj-extensions.pt' model")
diff --git a/examples/PACKAGES/metatomic/in.kokkos.metatomic b/examples/PACKAGES/metatomic/in.kokkos.metatomic
new file mode 100644
index 00000000000..4d7d90130e8
--- /dev/null
+++ b/examples/PACKAGES/metatomic/in.kokkos.metatomic
@@ -0,0 +1,31 @@
+# Use the correct kokkos settings. `neigh half` does not imply the use of a half
+# neighbor list, only a change in how contributions are summed together.
+# cf https://github.com/lammps/lammps/pull/4412
+package kokkos newton on neigh half
+
+units metal
+boundary p p p
+
+atom_style atomic/kk
+lattice fcc 3.6
+region box block 0 2 0 2 0 2
+create_box 1 box
+create_atoms 1 box
+
+mass 1 58.693
+
+velocity all create 123 42
+
+pair_style metatomic/kk nickel-lj.pt
+pair_coeff * * 28
+
+timestep 0.001
+run_style verlet/kk
+fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
+
+thermo 10
+thermo_style custom step temp pe etotal press vol
+
+# dump 1 all atom 10 dump.metatomic
+
+run 100
diff --git a/examples/PACKAGES/metatomic/in.metatomic b/examples/PACKAGES/metatomic/in.metatomic
new file mode 100644
index 00000000000..12e008ae148
--- /dev/null
+++ b/examples/PACKAGES/metatomic/in.metatomic
@@ -0,0 +1,27 @@
+units metal
+boundary p p p
+
+atom_style atomic
+lattice fcc 3.6
+region box block 0 2 0 2 0 2
+create_box 1 box
+create_atoms 1 box
+
+labelmap atom 1 Ni
+mass Ni 58.693
+
+velocity all create 123 42
+
+pair_style metatomic nickel-lj.pt
+# pair_style metatomic nickel-lj-extensions.pt extensions collected-extensions/
+pair_coeff * * 28
+
+timestep 0.001
+fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
+
+thermo 10
+thermo_style custom step temp pe etotal press vol
+
+# dump 1 all atom 10 dump.metatomic
+
+run 100
diff --git a/metatensor.patch b/metatensor.patch
new file mode 100644
index 00000000000..193a49fe96e
--- /dev/null
+++ b/metatensor.patch
@@ -0,0 +1,4127 @@
+diff --git a/cmake/CMakeLists.txt b/cmake/CMakeLists.txt
+index f22fa401a2..b87e45aa0b 100644
+--- a/cmake/CMakeLists.txt
++++ b/cmake/CMakeLists.txt
+@@ -162,7 +162,7 @@ endif()
+ if(CMAKE_CXX_STANDARD LESS 17)
+   message(WARNING "Selecting C++17 standard is preferred over C++${CMAKE_CXX_STANDARD}")
+ endif()
+-if(PKG_KOKKOS AND (CMAKE_CXX_STANDARD LESS 17))
++if((PKG_KOKKOS OR PKG_ML-METATENSOR) AND (CMAKE_CXX_STANDARD LESS 17))
+   set(CMAKE_CXX_STANDARD 17)
+ endif()
+ # turn off C++17 check in lmptype.h
+@@ -324,6 +324,7 @@ set(STANDARD_PACKAGES
+   MISC
+   ML-HDNNP
+   ML-IAP
++  ML-METATENSOR
+   ML-PACE
+   ML-POD
+   ML-QUIP
+@@ -605,7 +606,7 @@ else()
+ endif()
+
+ foreach(PKG_WITH_INCL KSPACE PYTHON ML-IAP VORONOI COLVARS ML-HDNNP MDI MOLFILE NETCDF
+-        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE LEPTON EXTRA-COMMAND)
++        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE ML-METATENSOR LEPTON EXTRA-COMMAND)
+   if(PKG_${PKG_WITH_INCL})
+     include(Packages/${PKG_WITH_INCL})
+   endif()
+diff --git a/cmake/Modules/Packages/KOKKOS.cmake b/cmake/Modules/Packages/KOKKOS.cmake
+index f878db654c..c638a49398 100644
+--- a/cmake/Modules/Packages/KOKKOS.cmake
++++ b/cmake/Modules/Packages/KOKKOS.cmake
+@@ -203,6 +203,10 @@ if(PKG_ML-IAP)
+   endif()
+ endif()
+
++if(PKG_ML-METATENSOR)
++  list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/metatensor_system_kokkos.cpp)
++endif()
++
+ if(PKG_PHONON)
+   list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/dynamical_matrix_kokkos.cpp)
+   list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/third_order_kokkos.cpp)
+diff --git a/cmake/Modules/Packages/ML-METATENSOR.cmake b/cmake/Modules/Packages/ML-METATENSOR.cmake
+new file mode 100644
+index 0000000000..dedc940894
+--- /dev/null
++++ b/cmake/Modules/Packages/ML-METATENSOR.cmake
+@@ -0,0 +1,84 @@
++# metatensor requires C++17 due to Torch requiring C++17
++if(CMAKE_CXX_STANDARD LESS 17)
++  message(FATAL_ERROR "The ML-METATENSOR package requires the C++ standard to
++be set to at least C++17")
++endif()
++
++if (BUILD_OMP AND APPLE)
++    message(FATAL_ERROR
++        "Can not enable both BUILD_OMP and PGK_ML-METATENSOR on Apple systems, "
++        "since this results in two different versions of the OpenMP library (one "
++        "from the system and one from Torch) being linked to the final "
++        "executable, which then crashes"
++    )
++endif()
++
++# Bring the `torch` target in scope to allow evaluation
++# of cmake generator expression from `metatensor_torch`
++find_package(Torch REQUIRED)
++
++# The caffe2::mkl target contains MKL_INCLUDE_DIR in it's
++# INTERFACE_INCLUDE_DIRECTORIES even if MKL was not found, causing a build
++# failure with "Imported target "torch" includes non-existent path" down the
++# line. This code removes the missing path from INTERFACE_INCLUDE_DIRECTORIES,
++# allowing the build to continue further.
++if (TARGET caffe2::mkl)
++    get_target_property(CAFFE2_MKL_INCLUDE_DIRECTORIES caffe2::mkl INTERFACE_INCLUDE_DIRECTORIES)
++    set(MKL_INCLUDE_DIR_NOTFOUND "")
++    foreach(_include_dir_ ${CAFFE2_MKL_INCLUDE_DIRECTORIES})
++        if ("${_include_dir_}" MATCHES "MKL_INCLUDE_DIR-NOTFOUND")
++            set(MKL_INCLUDE_DIR_NOTFOUND "${_include_dir_}")
++        endif()
++    endforeach()
++
++    if (NOT "${MKL_INCLUDE_DIR_NOTFOUND}" STREQUAL "")
++        list(REMOVE_ITEM CAFFE2_MKL_INCLUDE_DIRECTORIES "${MKL_INCLUDE_DIR_NOTFOUND}")
++    endif()
++    set_target_properties(caffe2::mkl PROPERTIES
++        INTERFACE_INCLUDE_DIRECTORIES "${CAFFE2_MKL_INCLUDE_DIRECTORIES}"
++    )
++endif()
++
++########### definition of metatensor and metatensor-torch targets ###########
++
++set(METATENSOR_CORE_VERSION "0.1.12")
++set(METATENSOR_TORCH_VERSION "0.7.3")
++
++set(DOWNLOAD_METATENSOR_DEFAULT ON)
++find_package(metatensor_torch QUIET ${METATENSOR_TORCH_VERSION})
++if (metatensor_torch_FOUND)
++    set(DOWNLOAD_METATENSOR_DEFAULT OFF)
++endif()
++
++
++option(DOWNLOAD_METATENSOR "Download metatensor package instead of using an already installed one" ${DOWNLOAD_METATENSOR_DEFAULT})
++
++if (DOWNLOAD_METATENSOR)
++    include(FetchContent)
++
++    set(URL_BASE "https://github.com/lab-cosmo/metatensor/releases/download")
++
++    FetchContent_Declare(metatensor
++        URL ${URL_BASE}/metatensor-core-v${METATENSOR_CORE_VERSION}/metatensor-core-cxx-${METATENSOR_CORE_VERSION}.tar.gz
++        URL_HASH SHA1=aec0963624f7fcd470e71471eb22b8912aec912e
++    )
++
++    message(STATUS "Fetching metatensor v${METATENSOR_CORE_VERSION} from github")
++    FetchContent_MakeAvailable(metatensor)
++
++    FetchContent_Declare(metatensor-torch
++        URL ${URL_BASE}/metatensor-torch-v${METATENSOR_TORCH_VERSION}/metatensor-torch-cxx-${METATENSOR_TORCH_VERSION}.tar.gz
++        URL_HASH SHA1=26f989650d29008ab640aa6bdea706f88adc4fba
++    )
++
++    message(STATUS "Fetching metatensor-torch v${METATENSOR_TORCH_VERSION} from github")
++    FetchContent_MakeAvailable(metatensor-torch)
++else()
++    # make sure to fail the configuration if cmake can not find metatensor-torch
++    find_package(metatensor_torch REQUIRED ${METATENSOR_TORCH_VERSION})
++endif()
++
++
++################ lammps target modifications ################
++
++target_link_libraries(lammps PRIVATE metatensor_torch)
+diff --git a/cmake/presets/all_off.cmake b/cmake/presets/all_off.cmake
+index f2f5782480..7ad382b94f 100644
+--- a/cmake/presets/all_off.cmake
++++ b/cmake/presets/all_off.cmake
+@@ -56,6 +56,7 @@ set(ALL_PACKAGES
+   MISC
+   ML-HDNNP
+   ML-IAP
++  ML-METATENSOR
+   ML-PACE
+   ML-POD
+   ML-QUIP
+diff --git a/cmake/presets/all_on.cmake b/cmake/presets/all_on.cmake
+index 8dc4632138..b09f8bbf68 100644
+--- a/cmake/presets/all_on.cmake
++++ b/cmake/presets/all_on.cmake
+@@ -58,6 +58,7 @@ set(ALL_PACKAGES
+   MISC
+   ML-HDNNP
+   ML-IAP
++  ML-METATENSOR
+   ML-PACE
+   ML-POD
+   ML-QUIP
+diff --git a/cmake/presets/nolib.cmake b/cmake/presets/nolib.cmake
+index 4a4a557505..4ebfd9568f 100644
+--- a/cmake/presets/nolib.cmake
++++ b/cmake/presets/nolib.cmake
+@@ -16,6 +16,7 @@ set(PACKAGES_WITH_LIB
+   MACHDYN
+   MDI
+   ML-HDNNP
++  ML-METATENSOR
+   ML-PACE
+   ML-QUIP
+   MOLFILE
+diff --git a/doc/src/Build_extras.rst b/doc/src/Build_extras.rst
+index 26cf776f4d..ce32ad4253 100644
+--- a/doc/src/Build_extras.rst
++++ b/doc/src/Build_extras.rst
+@@ -51,6 +51,7 @@ This is the list of packages that may require additional steps.
+    * :ref:`MISC <misc>`
+    * :ref:`ML-HDNNP <ml-hdnnp>`
+    * :ref:`ML-IAP <mliap>`
++   * :ref:`ML-METATENSOR <metatensor>`
+    * :ref:`ML-PACE <ml-pace>`
+    * :ref:`ML-POD <ml-pod>`
+    * :ref:`ML-QUIP <ml-quip>`
+@@ -1071,6 +1072,99 @@ Python version 3.6 or later.
+
+ ----------
+
++.. _metatensor:
++
++ML-METATENSOR package
++---------------------
++
++Building the ML-METATENSOR package requires three external dependencies: the C++
++version of ``libtorch``, the core ``metatensor`` library, and the
++``metatensor-torch`` library. You'll need to install ``libtorch`` manually,
++either by installing PyTorch with a Python package manager (``pip`` or
++``conda``), or by downloading the right prebuilt version of the code from
++https://pytorch.org/get-started/locally/.
++
++.. TODO: We should allow users to build the code with a different
++.. installation of metatensor/metatensor-torch, in particular pre-built
++.. versions from pip or conda.
++
++
++.. tabs::
++
++   .. tab:: CMake build
++
++      If you use the CMake build system of LAMMPS, ``metatensor`` and
++      ``metatensor-torch`` will automatically be downloaded and built for you,
++      using a compatible version for the current code. Building the core
++      ``metatensor`` library this way requires a `Rust <https://rust-lang.org>`_
++      compiler (version 1.65 or higher), which you can get using `rustup
++      <https://rustup.rs/>`_.
++
++      First, you should run the following code in a bash (or bash-compatible)
++      shell to tell CMake where to find ``libtorch``:
++
++      .. code-block:: bash
++
++         # point this to the path where you extracted the C++ libtorch
++         TORCH_PREFIX=<path/to/torch/installation>
++         # if you used Python to install torch, you can do this:
++         TORCH_PREFIX=$(python -c "import torch; print(torch.utils.cmake_prefix_path)")
++
++         # patch a bug from torch's MKL detection
++         cd <path/to/LAMMPS/sources>
++         ./src/ML-METATENSOR/patch-torch.sh "$TORCH_PREFIX"
++
++
++      Once PyTorch has been installed and patched, you'll need to use the
++      following CMake options:
++
++      .. code-block:: bash
++
++         -DPKG_ML-METATENSOR=ON
++         -DCMAKE_PREFIX_PATH="$TORCH_PREFIX"
++         -DLAMMPS_INSTALL_RPATH=ON
++
++      By default, this code will try to find the metatensor libraries on your
++      system and use them. If cmake can not find the libraries, it will download
++      and build them as part of the main LAMMPS build. If you want, you can
++      control this behavior using `-DDOWNLOAD_METATENSOR=ON` to always force a
++      download and `-DDOWNLOAD_METATENSOR=OFF` to prevent any download.
++
++   .. tab:: Traditional make
++
++      You can either download and build metatensor (and it's dependencies)
++      inside the `lib/metatensor` folder or use previously installed libraries
++      and point LAMMPS to their location.
++
++      All the dependencies can be automatically downloaded and built from the
++      `src` folder with the followig make arguments:
++
++      .. code-block:: bash
++
++         make lib-metatensor           # print help message
++         make lib-metatensor args="-b" # download dependencies in lib/metatensor, and create the corresponding Makefile.lammps
++
++      Once this is done, you can install the metatensor package and compile
++      LAMMPS in the usual manner:
++
++      .. code-block:: bash
++
++         make yes-metatensor
++         make <machine>
++
++   .. tab:: Metatensor and Kokkos
++
++      The metatensor-kokkos interface should be compiled as
++
++      .. code-block:: bash
++
++         cmake ../cmake/ -DPKG_KOKKOS=ON -DKokkos_ENABLE_CUDA=ON -DPKG_ML-METATENSOR=ON -DCMAKE_PREFIX_PATH=/.../libtorch/share/cmake/
++
++      where ``/.../libtorch/`` is the path to a libtorch C++11 ABI distribution (which can be downloaded from https://pytorch.org/get-started/locally/).
++      The OpenMP version (as opposed to the CUDA version) can be enabled with -DKokkos_ENABLE_OPENMP=ON instead of -DKokkos_ENABLE_CUDA=ON
++
++----------
++
+ .. _opt:
+
+ OPT package
+diff --git a/doc/src/Commands_pair.rst b/doc/src/Commands_pair.rst
+index 048a54ed37..da5a661a1d 100644
+--- a/doc/src/Commands_pair.rst
++++ b/doc/src/Commands_pair.rst
+@@ -201,6 +201,7 @@ OPT.
+    * :doc:`meam/sw/spline <pair_meam_sw_spline>`
+    * :doc:`mesocnt <pair_mesocnt>`
+    * :doc:`mesocnt/viscous <pair_mesocnt>`
++   * :doc:`metatensor <pair_metatensor>`
+    * :doc:`mgpt <pair_mgpt>`
+    * :doc:`mie/cut (g) <pair_mie>`
+    * :doc:`mliap (k) <pair_mliap>`
+diff --git a/doc/src/Packages_details.rst b/doc/src/Packages_details.rst
+index 870dc8fbf7..173d58def9 100644
+--- a/doc/src/Packages_details.rst
++++ b/doc/src/Packages_details.rst
+@@ -80,6 +80,7 @@ gives those details.
+    * :ref:`MISC <PKG-MISC>`
+    * :ref:`ML-HDNNP <PKG-ML-HDNNP>`
+    * :ref:`ML-IAP <PKG-ML-IAP>`
++   * :ref:`ML-METATENSOR <PKG-ML-METATENSOR>`
+    * :ref:`ML-PACE <PKG-ML-PACE>`
+    * :ref:`ML-POD <PKG-ML-POD>`
+    * :ref:`ML-QUIP <PKG-ML-QUIP>`
+@@ -1791,6 +1792,37 @@ therefore also needs to be installed to run those examples.
+
+ ----------
+
++.. _PKG-ML-METATENSOR:
++
++ML-METATENSOR package
++---------------------
++
++**Contents:**
++
++This package provides a pair style which allow using arbitrary machine learning
++models that follow the `metatensor interface`_. These models are based on
++`PyTorch`_ and can predict the energy of a system using a variety of machine
++learning technics. Users can defined and train their own models with fully
++custom Python code, use separate packages such as `metatensor-models`_ to train
++existing architectures with their own dataset; or use pre-trained models
++provided by others.
++
++.. _metatensor interface: https://docs.metatensor.org/latest/atomistic/index.html
++.. _PyTorch: https://pytorch.org/
++.. _metatensor-models: https://github.com/lab-cosmo/metatensor-models/
++
++**Author:** Guillaume Fraux (EPFL)
++
++.. versionadded:: TBD
++
++**Supporting info:**
++
++* src/ML-METATENSOR: filenames -> commands
++* :doc:`pair_style metatensor <pair_metatensor>`
++* examples/metatensor
++
++----------
++
+ .. _PKG-ML-PACE:
+
+ ML-PACE package
+diff --git a/doc/src/Packages_list.rst b/doc/src/Packages_list.rst
+index e1b4af694c..8094db114f 100644
+--- a/doc/src/Packages_list.rst
++++ b/doc/src/Packages_list.rst
+@@ -298,6 +298,11 @@ whether an extra library is needed to build and use the package:
+      - :doc:`pair_style mliap <pair_mliap>`
+      - mliap
+      - no
++   * - :ref:`ML-METATENSOR <PKG-ML-METATENSOR>`
++     - interface to metatensor powered machine-learning potentials
++     - :doc:`pair_style metatensor <pair_metatensor>`
++     - metatensor
++     - ext
+    * - :ref:`ML-PACE <PKG-ML-PACE>`
+      - Atomic Cluster Expansion potential
+      - :doc:`pair pace <pair_pace>`
+diff --git a/doc/src/pair_metatensor.rst b/doc/src/pair_metatensor.rst
+new file mode 100644
+index 0000000000..fa89291796
+--- /dev/null
++++ b/doc/src/pair_metatensor.rst
+@@ -0,0 +1,105 @@
++.. index:: pair_style metatensor
++
++pair_style metatensor command
++=============================
++
++Accelerator Variants: *metatensor/kk*
++
++Syntax
++""""""
++
++.. code-block:: LAMMPS
++
++   pair_style metatensor model_path ... keyword values ...
++
++* model_path = path to the file containing the exported metatensor model
++* keyword = *device* or *extensions* or *check_consistency*
++
++  .. parsed-literal::
++
++       *device* values = device_name
++         device_name = name of the Torch device to use for the calculations
++       *extensions* values = directory
++         directory = path to a directory containing TorchScript extensions as
++         shared libraries. If the model uses extensions, we will try to load
++         them from this directory first
++       *check_consistency* values = on or off
++         set this to on/off to enable/disable internal consistency checks,
++         verifying both the data passed by LAMMPS to the model, and the data
++         returned by the model to LAMMPS.
++
++Examples
++""""""""
++
++.. code-block:: LAMMPS
++
++   pair_style metatensor exported-model.pt device cuda extensions /home/user/torch-extensions/
++   pair_style metatensor soap-gap.pt check_consistency on
++   pair_coeff * * 6 8 1
++
++Description
++"""""""""""
++
++Pair style *metatensor* provides access to models following `metatensor's
++atomistic models <https://docs.metatensor.org/latest/atomistic/index.html>`
++interface; and enable using such models as interatomic potentials to drive a
++LAMMPS simulation. The models can be fully defined and trained by the user using
++Python code, or be existing pre-trained models. The interface can be used with
++any type of machine learning model, as long as the implementation of the model
++is compatible with TorchScript.
++
++The only required argument for *pair_style metatensor* is the path to the model
++file, which should be an exported metatensor model.
++
++Optionally, users can define which torch *device* (e.g. cpu, cuda, cuda:0,
++*etc.*) should be used to run the model. If this is not given, the code will run
++on the best available device. If the model uses custom TorchScript operators
++defined in a TorchScript extension, the shared library defining these extensions
++will be searched in the *extensions* path, and loaded before trying to load the
++model itself. Finally, *check_consistency* can be set to *on* or *off* to enable
++(respectively disable) additional internal consistency checks in the data being
++passed from LAMMPS to the model and back.
++
++A single *pair_coeff* command should be used with the *metatensor* style,
++specifying the mapping from LAMMPS types to the atomic types the model can
++handle. The first 2 arguments must be \* \* so as to span all LAMMPS atom types.
++This is followed by a list of N arguments that specify the mapping of metatensor
++atomic types to LAMMPS types, where N is the number of LAMMPS atom types.
++
++.. See the :doc:`pair_coeff <pair_coeff>` page for alternate ways
++.. to specify the path for the *model* and *extensions*.
++
++
++Mixing, shift, table, tail correction, restart, rRESPA info
++"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
++
++This pair style does not support the :doc:`pair_modify <pair_modify>` shift,
++table, and tail options.
++
++This pair style does not write its information to :doc:`binary restart files
++<restart>`, since it is stored in model files.  Thus, you need to re-specify the
++pair_style and pair_coeff commands in an input script that reads a restart file.
++
++This pair style can only be used via the *pair* keyword of the :doc:`run_style
++respa <run_style>` command.  It does not support the *inner*, *middle*, *outer*
++keywords.
++
++----------
++
++Restrictions
++""""""""""""
++
++This pair style is part of the ML-METATENSOR package.  It is only enabled if
++LAMMPS was built with that package. See the :doc:`Build package <Build_package>`
++page for more info.
++
++
++Related commands
++""""""""""""""""
++
++:doc:`pair_coeff <pair_coeff>`
++
++Default
++"""""""
++
++none
+diff --git a/doc/src/pair_style.rst b/doc/src/pair_style.rst
+index bdf06d6b66..546367abe5 100644
+--- a/doc/src/pair_style.rst
++++ b/doc/src/pair_style.rst
+@@ -294,6 +294,7 @@ accelerated styles exist.
+ * :doc:`meam/sw/spline <pair_meam_sw_spline>` - Splined version of MEAM with a Stillinger-Weber term
+ * :doc:`mesocnt <pair_mesocnt>` - Mesoscopic vdW potential for (carbon) nanotubes
+ * :doc:`mesocnt/viscous <pair_mesocnt>` - Mesoscopic vdW potential for (carbon) nanotubes with friction
++* :doc:`metatensor <pair_metatensor>` - interface to metatensor powered machine-learning potentials
+ * :doc:`mgpt <pair_mgpt>` - Simplified model generalized pseudopotential theory (MGPT) potential
+ * :doc:`mie/cut <pair_mie>` - Mie potential
+ * :doc:`mliap <pair_mliap>` - Multiple styles of machine-learning potential
+diff --git a/examples/PACKAGES/metatensor/.gitignore b/examples/PACKAGES/metatensor/.gitignore
+new file mode 100644
+index 0000000000..d848bd9194
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/.gitignore
+@@ -0,0 +1,2 @@
++collected-extensions/
++nickel-lj-extensions.pt
+diff --git a/examples/PACKAGES/metatensor/create-lj-nickel.py b/examples/PACKAGES/metatensor/create-lj-nickel.py
+new file mode 100644
+index 0000000000..08752dd705
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/create-lj-nickel.py
+@@ -0,0 +1,27 @@
++# https://github.com/Luthaf/metatensor-lj-test/
++import metatensor_lj_test
++
++
++model = metatensor_lj_test.lennard_jones_model(
++    atomic_type=28,
++    cutoff=6.5,
++    sigma=1.5808,
++    epsilon=0.1729,
++    length_unit="Angstrom",
++    energy_unit="eV",
++    with_extension=False,
++)
++
++model.save("nickel-lj.pt")
++
++
++model = metatensor_lj_test.lennard_jones_model(
++    atomic_type=28,
++    cutoff=6.5,
++    sigma=1.5808,
++    epsilon=0.1729,
++    length_unit="Angstrom",
++    energy_unit="eV",
++    with_extension=True,
++)
++model.save("nickel-lj-extensions.pt", collect_extensions="collected-extensions/")
+diff --git a/examples/PACKAGES/metatensor/in.kokkos.metatensor b/examples/PACKAGES/metatensor/in.kokkos.metatensor
+new file mode 100644
+index 0000000000..2ca2abf127
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/in.kokkos.metatensor
+@@ -0,0 +1,31 @@
++# Use the correct kokkos settings. `neigh half` does not imply the use of a half
++# neighbor list, only a change in how contributions are summed together.
++# cf https://github.com/lammps/lammps/pull/4412
++package kokkos newton on neigh half
++
++units metal
++boundary p p p
++
++atom_style atomic/kk
++lattice fcc 3.6
++region box block 0 2 0 2 0 2
++create_box 1 box
++create_atoms 1 box
++
++mass 1 58.693
++
++velocity all create 123 42
++
++pair_style metatensor/kk nickel-lj.pt
++pair_coeff * * 28
++
++timestep 0.001
++run_style verlet/kk
++fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
++
++thermo 10
++thermo_style custom step temp pe etotal press vol
++
++# dump 1 all atom 10 dump.metatensor
++
++run 100
+diff --git a/examples/PACKAGES/metatensor/in.metatensor b/examples/PACKAGES/metatensor/in.metatensor
+new file mode 100644
+index 0000000000..59a32c89e4
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/in.metatensor
+@@ -0,0 +1,27 @@
++units metal
++boundary p p p
++
++atom_style atomic
++lattice fcc 3.6
++region box block 0 2 0 2 0 2
++create_box 1 box
++create_atoms 1 box
++
++labelmap atom 1 Ni
++mass Ni 58.693
++
++velocity all create 123 42
++
++pair_style metatensor nickel-lj.pt
++# pair_style metatensor nickel-lj-extensions.pt extensions collected-extensions/
++pair_coeff * * 28
++
++timestep 0.001
++fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
++
++thermo 10
++thermo_style custom step temp pe etotal press vol
++
++# dump 1 all atom 10 dump.metatensor
++
++run 100
+diff --git a/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.1 b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.1
+new file mode 100644
+index 0000000000..e400bfa088
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.1
+@@ -0,0 +1,135 @@
++LAMMPS (17 Apr 2024 - Development - patch_17Apr2024-557-gef1630afd2)
++  using 1 OpenMP thread(s) per MPI task
++units metal
++boundary p p p
++
++atom_style atomic
++lattice fcc 3.6
++Lattice spacing in x,y,z = 3.6 3.6 3.6
++region box block 0 2 0 2 0 2
++create_box 1 box
++Created orthogonal box = (0 0 0) to (7.2 7.2 7.2)
++  1 by 1 by 1 MPI processor grid
++create_atoms 1 box
++Created 32 atoms
++  using lattice units in orthogonal box = (0 0 0) to (7.2 7.2 7.2)
++  create_atoms CPU = 0.000 seconds
++
++labelmap atom 1 Ni
++mass Ni 58.693
++
++velocity all create 123 42
++
++pair_style metatensor nickel-lj.pt
++
++This is the Test Lennard-Jones model
++====================================
++
++Minimal shifted Lennard-Jones potential, to be used when testing the
++integration of metatensor atomistic models with various simulation engines.
++
++Model authors
++-------------
++
++- Guillaume Fraux <guillaume.fraux@epfl.ch>
++
++Model references
++----------------
++
++Please cite the following references when using this model:
++- about this specific model:
++  * https://github.com/luthaf/metatensor-lj-test
++- about the implementation of this model:
++  * https://github.com/lab-cosmo/metatensor
++
++Running simulation on cpu device with float64 data
++# pair_style metatensor nickel-lj-extensions.pt extensions collected-extensions/
++pair_coeff * * 28
++
++timestep 0.001
++fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
++fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 $(1000 * dt) drag 1.0
++fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 1 drag 1.0
++
++thermo 10
++thermo_style custom step temp pe etotal press vol
++
++# dump 1 all atom 10 dump.metatensor
++
++run 100
++
++CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
++
++Your simulation uses code contributions which should be cited:
++
++- Type Label Framework: https://doi.org/10.1021/acs.jpcb.3c08419
++
++@Article{Gissinger24,
++ author = {Jacob R. Gissinger, Ilia Nikiforov, Yaser Afshar, Brendon Waters, Moon-ki Choi, Daniel S. Karls, Alexander Stukowski, Wonpil Im, Hendrik Heinz, Axel Kohlmeyer, and Ellad B. Tadmor},
++ title = {Type Label Framework for Bonded Force Fields in LAMMPS},
++ journal = {J. Phys. Chem. B},
++ year =    2024,
++ volume =  128,
++ number =  13,
++ pages =   {3282–-3297}
++}
++
++- https://github.com/lab-cosmo/metatensor
++- https://github.com/luthaf/metatensor-lj-test
++CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
++
++Generated 0 of 0 mixed pair_coeff terms from geometric mixing rule
++Neighbor list info ...
++  update: every = 1 steps, delay = 0 steps, check = yes
++  max neighbors/atom: 2000, page size: 100000
++  master list distance cutoff = 8.5
++  ghost atom cutoff = 8.5
++  binsize = 4.25, bins = 2 2 2
++  1 neighbor lists, perpetual/occasional/extra = 1 0 0
++  (1) pair metatensor, perpetual
++      attributes: full, newton on, ghost
++      pair build: full/bin/ghost
++      stencil: full/ghost/bin/3d
++      bin: standard
++Per MPI rank memory allocation (min/avg/max) = 3.377 | 3.377 | 3.377 Mbytes
++   Step          Temp          PotEng         TotEng         Press          Volume
++         0   123           -8.2814195     -7.7885506     -67585.536      373.248
++        10   124.8498      -8.395127      -7.8948458     -68884.117      370.7507
++        20   130.60229     -8.7447028     -8.221371      -72913.372      363.3685
++        30   140.95014     -9.3595663     -8.79477       -80162.936      351.36119
++        40   157.33663     -10.29346      -9.6630017     -91879.643      335.18851
++        50   181.74279     -11.619487     -10.891232     -108735.54      315.60425
++        60   216.75162     -13.405317     -12.536779     -131438.83      293.736
++        70   264.39963     -15.685874     -14.626408     -160402.97      270.99304
++        80   319.4713      -18.40371      -17.123568     -192237.03      248.74525
++        90   350.37789     -21.272294     -19.868307     -215596.99      227.98439
++       100   298.01005     -23.674365     -22.48022      -206922.9       209.26415
++Loop time of 4.01198 on 1 procs for 100 steps with 32 atoms
++
++Performance: 2.154 ns/day, 11.144 hours/ns, 24.925 timesteps/s, 797.611 atom-step/s
++99.4% CPU use with 1 MPI tasks x 1 OpenMP threads
++
++MPI task timing breakdown:
++Section |  min time  |  avg time  |  max time  |%varavg| %total
++---------------------------------------------------------------
++Pair    | 3.9962     | 3.9962     | 3.9962     |   0.0 | 99.61
++Neigh   | 0.01366    | 0.01366    | 0.01366    |   0.0 |  0.34
++Comm    | 0.00055756 | 0.00055756 | 0.00055756 |   0.0 |  0.01
++Output  | 0.00016915 | 0.00016915 | 0.00016915 |   0.0 |  0.00
++Modify  | 0.001224   | 0.001224   | 0.001224   |   0.0 |  0.03
++Other   |            | 0.00021    |            |       |  0.01
++
++Nlocal:             32 ave          32 max          32 min
++Histogram: 1 0 0 0 0 0 0 0 0 0
++Nghost:           1655 ave        1655 max        1655 min
++Histogram: 1 0 0 0 0 0 0 0 0 0
++Neighs:              0 ave           0 max           0 min
++Histogram: 1 0 0 0 0 0 0 0 0 0
++FullNghs:        11490 ave       11490 max       11490 min
++Histogram: 1 0 0 0 0 0 0 0 0 0
++
++Total # of neighbors = 11490
++Ave neighs/atom = 359.0625
++Neighbor list builds = 2
++Dangerous builds = 0
++Total wall time: 0:00:04
+diff --git a/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.4 b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.4
+new file mode 100644
+index 0000000000..d6dbff0d78
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.4
+@@ -0,0 +1,135 @@
++LAMMPS (17 Apr 2024 - Development - patch_17Apr2024-557-gef1630afd2)
++  using 1 OpenMP thread(s) per MPI task
++units metal
++boundary p p p
++
++atom_style atomic
++lattice fcc 3.6
++Lattice spacing in x,y,z = 3.6 3.6 3.6
++region box block 0 2 0 2 0 2
++create_box 1 box
++Created orthogonal box = (0 0 0) to (7.2 7.2 7.2)
++  1 by 2 by 2 MPI processor grid
++create_atoms 1 box
++Created 32 atoms
++  using lattice units in orthogonal box = (0 0 0) to (7.2 7.2 7.2)
++  create_atoms CPU = 0.001 seconds
++
++labelmap atom 1 Ni
++mass Ni 58.693
++
++velocity all create 123 42
++
++pair_style metatensor nickel-lj.pt
++
++This is the Test Lennard-Jones model
++====================================
++
++Minimal shifted Lennard-Jones potential, to be used when testing the
++integration of metatensor atomistic models with various simulation engines.
++
++Model authors
++-------------
++
++- Guillaume Fraux <guillaume.fraux@epfl.ch>
++
++Model references
++----------------
++
++Please cite the following references when using this model:
++- about this specific model:
++  * https://github.com/luthaf/metatensor-lj-test
++- about the implementation of this model:
++  * https://github.com/lab-cosmo/metatensor
++
++Running simulation on cpu device with float64 data
++# pair_style metatensor nickel-lj-extensions.pt extensions collected-extensions/
++pair_coeff * * 28
++
++timestep 0.001
++fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
++fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 $(1000 * dt) drag 1.0
++fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 1 drag 1.0
++
++thermo 10
++thermo_style custom step temp pe etotal press vol
++
++# dump 1 all atom 10 dump.metatensor
++
++run 100
++
++CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
++
++Your simulation uses code contributions which should be cited:
++
++- Type Label Framework: https://doi.org/10.1021/acs.jpcb.3c08419
++
++@Article{Gissinger24,
++ author = {Jacob R. Gissinger, Ilia Nikiforov, Yaser Afshar, Brendon Waters, Moon-ki Choi, Daniel S. Karls, Alexander Stukowski, Wonpil Im, Hendrik Heinz, Axel Kohlmeyer, and Ellad B. Tadmor},
++ title = {Type Label Framework for Bonded Force Fields in LAMMPS},
++ journal = {J. Phys. Chem. B},
++ year =    2024,
++ volume =  128,
++ number =  13,
++ pages =   {3282–-3297}
++}
++
++- https://github.com/lab-cosmo/metatensor
++- https://github.com/luthaf/metatensor-lj-test
++CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
++
++Generated 0 of 0 mixed pair_coeff terms from geometric mixing rule
++Neighbor list info ...
++  update: every = 1 steps, delay = 0 steps, check = yes
++  max neighbors/atom: 2000, page size: 100000
++  master list distance cutoff = 8.5
++  ghost atom cutoff = 8.5
++  binsize = 4.25, bins = 2 2 2
++  1 neighbor lists, perpetual/occasional/extra = 1 0 0
++  (1) pair metatensor, perpetual
++      attributes: full, newton on, ghost
++      pair build: full/bin/ghost
++      stencil: full/ghost/bin/3d
++      bin: standard
++Per MPI rank memory allocation (min/avg/max) = 3.359 | 3.359 | 3.359 Mbytes
++   Step          Temp          PotEng         TotEng         Press          Volume
++         0   123           -8.2814195     -7.7885506     -67585.536      373.248
++        10   124.79957     -8.3949245     -7.8948446     -68883.161      370.7507
++        20   130.37558     -8.7437731     -8.2213497     -72909.223      363.36859
++        30   140.35202     -9.3570472     -8.7946476     -80147.272      351.36165
++        40   156.04321     -10.287834     -9.6625589     -91867.312      335.19011
++        50   179.24129     -11.608375     -10.890143     -108707.41      315.60758
++        60   212.26895     -13.385134     -12.534558     -131437.18      293.74143
++        70   257.12553     -15.653741     -14.623422     -160605.1       270.99882
++        80   309.97318     -18.367667     -17.125584     -193391.56      248.74226
++        90   345.50571     -21.286382     -19.901918     -220089.9       227.94171
++       100   318.19414     -23.90463      -22.629605     -220782.88      209.09539
++Loop time of 4.16296 on 4 procs for 100 steps with 32 atoms
++
++Performance: 2.075 ns/day, 11.564 hours/ns, 24.021 timesteps/s, 768.684 atom-step/s
++97.4% CPU use with 4 MPI tasks x 1 OpenMP threads
++
++MPI task timing breakdown:
++Section |  min time  |  avg time  |  max time  |%varavg| %total
++---------------------------------------------------------------
++Pair    | 3.8847     | 3.9666     | 4.0708     |   3.8 | 95.28
++Neigh   | 0.008984   | 0.0098269  | 0.012274   |   1.4 |  0.24
++Comm    | 0.060256   | 0.16685    | 0.24951    |  18.7 |  4.01
++Output  | 0.00014112 | 0.0021948  | 0.0083534  |   7.6 |  0.05
++Modify  | 0.010689   | 0.016268   | 0.018145   |   2.5 |  0.39
++Other   |            | 0.001203   |            |       |  0.03
++
++Nlocal:              8 ave          10 max           6 min
++Histogram: 2 0 0 0 0 0 0 0 0 2
++Nghost:           1259 ave        1261 max        1257 min
++Histogram: 2 0 0 0 0 0 0 0 0 2
++Neighs:              0 ave           0 max           0 min
++Histogram: 4 0 0 0 0 0 0 0 0 0
++FullNghs:         2891 ave        3614 max        2167 min
++Histogram: 2 0 0 0 0 0 0 0 0 2
++
++Total # of neighbors = 11564
++Ave neighs/atom = 361.375
++Neighbor list builds = 2
++Dangerous builds = 0
++Total wall time: 0:00:04
+diff --git a/examples/PACKAGES/metatensor/readme.txt b/examples/PACKAGES/metatensor/readme.txt
+new file mode 100644
+index 0000000000..87b15be34c
+--- /dev/null
++++ b/examples/PACKAGES/metatensor/readme.txt
+@@ -0,0 +1,16 @@
++The base package can be compiled as cmake ../cmake -DPKG_ML-METATENSOR=ON
++-DCMAKE_PREFIX_PATH=/.../site-packages/torch/share/cmake/ where
++/.../site-packages/torch/ is the path to a pip installation of torch
++
++The kokkos version should be compiled as cmake ../cmake/ -DPKG_KOKKOS=ON
++-DKokkos_ENABLE_CUDA=ON -DPKG_ML-METATENSOR=ON
++-DCMAKE_PREFIX_PATH=/.../libtorch/share/cmake/ where /.../libtorch/ is the path
++to a libtorch C++11 ABI distribution (which can be downloaded from
++https://pytorch.org/get-started/locally/). The OpenMP version (as opposed to the
++CUDA version) can be enabled with -DKokkos_ENABLE_OPENMP=ON instead of
++-DKokkos_ENABLE_CUDA=ON
++
++The consistency between the two interfaces can be checked with
++../../../build/lmp -k on g 1 -in in.kokkos.metatensor (or `t Nt` instead of `g
++1` for an OpenMP run with Nt threads) and the output can be compared with that
++of the plain metatensor interface ../../../build/lmp -in in.metatensor
+diff --git a/lib/metatensor/.gitignore b/lib/metatensor/.gitignore
+new file mode 100644
+index 0000000000..a2d7b3571a
+--- /dev/null
++++ b/lib/metatensor/.gitignore
+@@ -0,0 +1,6 @@
++virtualenv/
++*.tar.gz
++metatensor-core/
++metatensor-torch/
++
++usr/
+diff --git a/lib/metatensor/Install.py b/lib/metatensor/Install.py
+new file mode 100644
+index 0000000000..7f8f853c69
+--- /dev/null
++++ b/lib/metatensor/Install.py
+@@ -0,0 +1,453 @@
++#!/usr/bin/env python
++"""
++Install.py tool to download, compile, and setup the ml-metatensor LAMMPS package.
++This automates the steps described in the README file in this dir.
++"""
++
++import glob
++import os
++import shutil
++import subprocess
++import sys
++from argparse import ArgumentParser
++
++sys.path.append("..")
++from install_helpers import checkmd5sum, fullpath, geturl  # noqa F401
++
++if sys.version_info < (3, 6):
++    sys.exit("this script requires at least Python 3.6")
++
++# settings
++
++HERE = fullpath(".")
++METATENSOR_CORE_VERSION_DEFAULT = "0.1.7"
++METATENSOR_TORCH_VERSION_DEFAULT = "0.5.1"
++LIBTORCH_VERSION_DEFAULT = "2.2.2"
++
++# known checksums for different versions. used to validate the download.
++METATENSOR_CORE_CHECKSUMS = {
++    "0.1.6": "3edaf5ffd1af8892965f1f618c04083d",
++    "0.1.7": "43aeb651e6d040fbc82d4b5191e2f6cb",
++    "0.1.8": "22ae27fb3b26f356ca6e477326be6470",
++}
++METATENSOR_TORCH_CHECKSUMS = {
++    "0.5.0": "8ef9e235bbd5db22520f3abdc110f904",
++    "0.5.1": "a4c535faae3a811784679a55b32d9dce",
++}
++
++GITHUB_RELEASES = "https://github.com/lab-cosmo/metatensor/releases/download"
++
++CMAKE_EXE = os.environ.get("CMAKE", "cmake")
++
++
++def download_unpack(url, unpacked_dir, checksum=None, verbose=False):
++    file_name = os.path.basename(url)
++    print(f"===> Downloading {file_name}")
++
++    geturl(url, os.path.basename(url))
++    if checksum is not None:
++        if not checkmd5sum(checksum, file_name):
++            sys.exit(f"ERROR: checksum for {file_name} does not match!")
++
++    print(f"===> Unpacking to {unpacked_dir}")
++    if verbose:
++        stdout = sys.stdout
++        stderr = sys.stderr
++    else:
++        stdout = subprocess.PIPE
++        stderr = subprocess.PIPE
++
++    shutil.rmtree(unpacked_dir, ignore_errors=True)
++    subprocess.run(
++        [CMAKE_EXE, "-E", "tar", "xf", file_name],
++        stdout=stdout,
++        stderr=stderr,
++        check=True,
++    )
++    extracted = file_name[:-7]
++    shutil.move(extracted, unpacked_dir)
++
++
++def install_with_pip(python, package, verbose=False):
++    print(f"===> Installing {package} with pip")
++    if verbose:
++        stdout = sys.stdout
++        stderr = sys.stderr
++    else:
++        stdout = subprocess.PIPE
++        stderr = subprocess.PIPE
++
++    subprocess.run(
++        [
++            python,
++            "-m",
++            "pip",
++            "install",
++            "--disable-pip-version-check",
++            package,
++        ],
++        stdout=stdout,
++        stderr=stderr,
++        check=True,
++    )
++
++
++def copy_from_pip(python, package, paths, install_dir, verbose=False):
++    print(f"===> Copying files for {package} from Python installation")
++    prefix = subprocess.check_output(
++        [python, "-c", f"import {package}; print({package}.__file__)"],
++        encoding="utf8",
++    )
++    prefix = os.path.dirname(prefix.strip())
++
++    for src, dst in paths:
++        shutil.copytree(
++            os.path.join(prefix, src),
++            os.path.join(install_dir, dst),
++            dirs_exist_ok=True,
++        )
++
++
++def build_cmake(source_dir, install_dir, cmake_opts, verbose=False):
++    print(f"===> Building {source_dir} with cmake")
++    if verbose:
++        stdout = sys.stdout
++        stderr = sys.stderr
++    else:
++        stdout = subprocess.PIPE
++        stderr = subprocess.PIPE
++
++    build_dir = os.path.join(source_dir, "build")
++
++    subprocess.run(
++        [
++            CMAKE_EXE,
++            "-S",
++            source_dir,
++            "-B",
++            build_dir,
++            *cmake_opts,
++            f"-DCMAKE_INSTALL_PREFIX={install_dir}",
++            "-DCMAKE_BUILD_TYPE=Release",
++        ],
++        stdout=stdout,
++        stderr=stderr,
++        check=True,
++    )
++
++    subprocess.run(
++        [
++            CMAKE_EXE,
++            "--build",
++            build_dir,
++            "--config",
++            "Release",
++            "--target",
++            "install",
++        ],
++        stdout=stdout,
++        stderr=stderr,
++        check=True,
++    )
++
++
++if __name__ == "__main__":
++
++    parser = ArgumentParser(
++        prog="Install.py", description="LAMMPS library build wrapper script"
++    )
++
++    # help message
++
++    HELP = """
++This script tries to install all the dependencies of the ml-metatensor package. This
++includes libtorch, metatensor and metatensor-torch. Different options are available for
++the different dependencies:
++
++- libtorch can be downloaded from pip, or taken from another installation on your
++  system.
++    - If downloaded by pip, we will create a virtual environment and install it there,
++      unless `--python` is given as an option, in which case we will try to install it
++      using the provided python executable.
++    - If you want to use another installation of libtorch, please use the `--no-torch`
++      option and export the TORCH_PREFIX environment variable containing the path of the
++      installation.
++- metatensor and metatensor-torch can be downloaded from pip or built from sources
++    - if downloaded by pip, the same options as torch applies. This is triggered by the
++      `--metatensor-use-pip` option.
++    - if building from sources, you will need to install cmake and a rust compiler on
++      your system (we suggest https://rustup.rs/ to install a rust compiler).
++
++
++Syntax from src dir: make lib-metatensor args="-b ..."
++Syntax from lib dir: python Install.py -b ...
++
++Examples:
++
++# install with default versions and settings
++make lib-metatensor args="-b"
++
++# install specified version of libtorch
++make lib-metatensor args="-b --torch-version <version>"
++
++# install using python3 in the PATH
++make lib-metatensor args="-b --python $(which python3)"
++
++# build metatensor from sources
++make lib-metatensor args="-b --metatensor-from-sources"
++    """
++
++    parser.add_argument(
++        "-b",
++        "--build",
++        action="store_true",
++        help="download and build metatensor and metatensor-torch libraries",
++    )
++    parser.add_argument(
++        "--torch-version",
++        default=LIBTORCH_VERSION_DEFAULT,
++        help=f"version of libtorch to download (default: {LIBTORCH_VERSION_DEFAULT})",
++    )
++    parser.add_argument(
++        "--python",
++        help="path to a Python executable to use, this bypass the use of venv",
++    )
++
++    parser.add_argument(
++        "--no-torch",
++        action="store_true",
++        default=False,
++        help="disabled download of libtorch",
++    )
++    parser.add_argument(
++        "--metatensor-from-sources",
++        action="store_true",
++        help="build metatensor and metatensor-torch from sources",
++    )
++
++    parser.add_argument(
++        "--metatensor-version",
++        default=METATENSOR_CORE_VERSION_DEFAULT,
++        choices=METATENSOR_CORE_CHECKSUMS.keys(),
++        help=(
++            "version of metatensor-core to download and build "
++            f"(default: {METATENSOR_CORE_VERSION_DEFAULT})"
++        ),
++    )
++    parser.add_argument(
++        "--metatensor-torch-version",
++        default=METATENSOR_TORCH_VERSION_DEFAULT,
++        choices=METATENSOR_TORCH_CHECKSUMS.keys(),
++        help=(
++            "version of metatensor-torch to download and build "
++            f"(default: {METATENSOR_TORCH_VERSION_DEFAULT})"
++        ),
++    )
++    parser.add_argument(
++        "-vv",
++        "--verbose",
++        action="store_true",
++        help="be more verbose about is happening while this script runs",
++    )
++
++    args = parser.parse_args()
++
++    # print help message and exit, if build option is not given
++    if not args.build:
++        parser.print_help()
++        sys.exit(HELP)
++
++    do_build = args.build
++    verbose = args.verbose
++
++    metatensor_core_version = args.metatensor_version
++    metatensor_torch_version = args.metatensor_torch_version
++    metatensor_from_sources = args.metatensor_from_sources
++
++    do_torch = not args.no_torch
++    torch_version = args.torch_version
++
++    # If we don't know the version of torch, we need to build metatensor-torch from
++    # sources.
++    if args.no_torch and not metatensor_from_sources:
++        raise Exception("--no-torch requires --metatensor-from-sources")
++
++    python = args.python
++
++    if python is None:
++        python = sys.executable
++        do_venv = do_torch or not metatensor_from_sources
++    else:
++        do_venv = False
++
++    if verbose:
++        stdout = sys.stdout
++        stderr = sys.stderr
++    else:
++        stdout = subprocess.PIPE
++        stderr = subprocess.PIPE
++
++    if do_venv:
++        venv_path = os.path.join(HERE, "virtualenv")
++        print(f"===> Creating virtual environment at {venv_path}")
++
++        try:
++            import venv
++        except ImportError:
++            sys.exit(
++                "could not import 'venv', make sure 'python-venv' package is installed"
++            )
++
++        builder = venv.EnvBuilder(
++            with_pip=True,
++            symlinks=not sys.platform.startswith("win"),
++        )
++        builder.create(venv_path)
++
++        if sys.platform.startswith("win"):
++            python = os.path.join(venv_path, "Scripts", "python.exe")
++        else:
++            python = os.path.join(venv_path, "bin", "python")
++
++        if verbose:
++            print("===> Upgrading pip in virtualenv")
++
++        subprocess.run(
++            [python, "-m", "pip", "install", "--upgrade", "pip"],
++            stdout=stdout,
++            stderr=stderr,
++            check=True,
++        )
++
++    install_dir = os.path.join(HERE, "usr")
++    os.makedirs(os.path.join(install_dir, "lib"), exist_ok=True)
++    os.makedirs(os.path.join(install_dir, "include"), exist_ok=True)
++    os.makedirs(os.path.join(install_dir, "share"), exist_ok=True)
++
++    cmake_prefix_path = []
++    # Torch needs C++17 to compile
++    extra_cxx_flags = ["-std=c++17"]
++
++    torch_extra_include = os.path.join("torch", "csrc", "api", "include")
++    if do_torch:
++        install_with_pip(python, f"torch=={torch_version}", verbose=verbose)
++        install_with_pip(python, "numpy", verbose=verbose)
++
++        torch_prefix = subprocess.check_output(
++            [python, "-c", "import torch; print(torch.__file__)"],
++            encoding="utf8",
++        )
++        torch_prefix = os.path.dirname(torch_prefix.strip())
++
++        if sys.platform.startswith("linux"):
++            # the pip version of torch uses the pre-cxx11 ABI
++            extra_cxx_flags.append("-D_GLIBCXX_USE_CXX11_ABI=0")
++
++    else:
++        torch_prefix = os.environ.get("TORCH_PREFIX")
++
++    if torch_prefix is not None:
++        cmake_prefix_path.append(torch_prefix)
++
++        if os.path.exists(os.path.join(torch_prefix, "include")):
++            extra_cxx_flags.append(f"-I{os.path.join(torch_prefix, 'include')}")
++            extra_cxx_flags.append(
++                f"-I{os.path.join(torch_prefix, 'include', torch_extra_include)}"
++            )
++
++    if metatensor_from_sources:
++        # Download and build metatensor-core from source
++        download_unpack(
++            url=f"{GITHUB_RELEASES}/metatensor-core-v{metatensor_core_version}/metatensor-core-cxx-{metatensor_core_version}.tar.gz",  # noqa: E501
++            unpacked_dir="metatensor-core",
++            checksum=METATENSOR_CORE_CHECKSUMS.get(metatensor_core_version),
++            verbose=verbose,
++        )
++
++        build_cmake(
++            source_dir="metatensor-core",
++            install_dir=install_dir,
++            cmake_opts=[
++                "-DBUILD_SHARED_LIBS=ON",
++                "-DMETATENSOR_INSTALL_BOTH_STATIC_SHARED=OFF",
++            ],
++            verbose=verbose,
++        )
++
++        # Download and build metatensor-torch from source
++        cmake_prefix_path.append(f"{install_dir}/lib/")
++        download_unpack(
++            url=f"{GITHUB_RELEASES}/metatensor-torch-v{metatensor_torch_version}/metatensor-torch-cxx-{metatensor_torch_version}.tar.gz",  # noqa: E501
++            unpacked_dir="metatensor-torch",
++            checksum=METATENSOR_TORCH_CHECKSUMS.get(metatensor_torch_version),
++            verbose=verbose,
++        )
++
++        build_cmake(
++            source_dir="metatensor-torch",
++            install_dir=install_dir,
++            cmake_opts=[
++                "-DBUILD_SHARED_LIBS=ON",
++                f"-DCMAKE_PREFIX_PATH={';'.join(cmake_prefix_path)}",
++            ],
++            verbose=verbose,
++        )
++    else:
++        install_with_pip(
++            python,
++            f"metatensor-core=={metatensor_core_version}",
++            verbose=verbose,
++        )
++        copy_from_pip(
++            python,
++            "metatensor",
++            [("lib", "lib"), ("include", "include")],
++            install_dir=install_dir,
++            verbose=verbose,
++        )
++
++        install_with_pip(
++            python,
++            f"metatensor-torch=={metatensor_torch_version}",
++            verbose=verbose,
++        )
++        torch_version_prefix = "torch-" + ".".join(torch_version.split(".")[:2])
++        copy_from_pip(
++            python,
++            "metatensor.torch",
++            [
++                (os.path.join(torch_version_prefix, "lib"), "lib"),
++                (os.path.join(torch_version_prefix, "include"), "include"),
++            ],
++            install_dir=install_dir,
++            verbose=verbose,
++        )
++
++    print("===> Creating Makefile.lammps")
++    with open("Makefile.lammps", "w") as fd:
++        fd.write("# autogenerated file\n\n\n")
++
++        fd.write(f"metatensor_SYSINC = -I{os.path.join(install_dir, 'include')}")
++        fd.write(f" {' '.join(extra_cxx_flags)}")
++        fd.write("\n\n")
++
++        fd.write("metatensor_SYSLIB = -lmetatensor -lmetatensor_torch")
++        fd.write(" -ltorch -lc10 -ltorch_cpu")
++        if len(glob.glob(os.path.join(torch_prefix, "lib", "*torch_cuda*"))) != 0:
++            fd.write(" -ltorch_cuda -lc10_cuda")
++        fd.write("\n\n")
++
++        fd.write(f"metatensor_SYSPATH = -L{os.path.join(install_dir, 'lib')}")
++        fd.write(f" -L{os.path.join(torch_prefix, 'lib')}")
++
++        # set the rpath on the final binary
++        fd.write(f" -Wl,-rpath,{os.path.join(install_dir, 'lib')}")
++        fd.write(f" -Wl,-rpath,{os.path.join(torch_prefix, 'lib')}")
++
++        if sys.platform.startswith("linux"):
++            # force the use of rpath instead of runpath
++            fd.write(" -Wl,--disable-new-dtags")
++
++        fd.write("\n\n")
++
++    print("===> All done!")
+diff --git a/lib/metatensor/Makefile.lammps.empty b/lib/metatensor/Makefile.lammps.empty
+new file mode 100644
+index 0000000000..5d44a9aca4
+--- /dev/null
++++ b/lib/metatensor/Makefile.lammps.empty
+@@ -0,0 +1,6 @@
++# Settings that the LAMMPS build will import when metatensor is used. Rename
++# this file to `Makefile.lammps` and edit the flags below as required
++
++metatensor_SYSINC =
++metatensor_SYSLIB =
++metatensor_SYSPATH =
+diff --git a/lib/metatensor/README b/lib/metatensor/README
+new file mode 100644
+index 0000000000..ec96c3f2dc
+--- /dev/null
++++ b/lib/metatensor/README
+@@ -0,0 +1,23 @@
++# ML-METATENSOR
++
++The files in this directory are helpers to install all the dependencies of the
++ML-METATENSOR package:
++
++- the C++ version of libtorch;
++- the core metatensor library;
++- the metatensor_torch library;
++
++You can type "make lib-metatensor" from the src directory to see help on how to
++download and build this library via make commands, or you can do the same thing
++by typing "python Install.py" from within this directory. There are many options
++you can set to choose where to install the libraries and whether to download
++pre-built versions or compile your own.
++
++Alternatively, you can download and build the above dependencies (see
++https://docs.metatensor.org/latest/installation.html for information on how to
++do this) somewhere on your system; and then make a copy of
++`Makefile.lammps.empty` named `Makefile.lammps`, and edit it to add the right
++flags for your compiler. You'll need to add the three libraries above to the
++include search path, library search path; and you'll need to link LAMMPS with
++the `torch`, `c10`, (optionally `torch_cuda` and `c10_cuda` for GPU support),
++`metatensor` and `metatensor_torch` libraries.
+diff --git a/src/.gitignore b/src/.gitignore
+index 5debdebc50..d910a66902 100644
+--- a/src/.gitignore
++++ b/src/.gitignore
+@@ -1434,6 +1434,10 @@
+ /pair_peri_ves.h
+ /pair_quip.cpp
+ /pair_quip.h
++/pair_metatensor.cpp
++/pair_metatensor.h
++/metatensor_system.cpp
++/metatensor_system.h
+ /pair_reaxff.cpp
+ /pair_reaxff.h
+ /pair_rebo.cpp
+@@ -1801,4 +1805,3 @@
+ /pair_smtbq.h
+ /pair_vashishta*.cpp
+ /pair_vashishta*.h
+-
+diff --git a/src/KOKKOS/metatensor_system_kokkos.cpp b/src/KOKKOS/metatensor_system_kokkos.cpp
+new file mode 100644
+index 0000000000..b8e68b8f00
+--- /dev/null
++++ b/src/KOKKOS/metatensor_system_kokkos.cpp
+@@ -0,0 +1,392 @@
++/* ----------------------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++/* ----------------------------------------------------------------------
++   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
++                         Filippo Bigi <filippo.bigi@epfl.ch>
++------------------------------------------------------------------------- */
++#include "metatensor_system_kokkos.h"
++
++#include "metatensor_timer.h"
++
++#include "domain.h"
++#include "error.h"
++
++#include "atom_kokkos.h"
++
++#include <torch/cuda.h>
++
++using namespace LAMMPS_NS;
++
++template<typename T, class DeviceType>
++using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
++
++template<class DeviceType>
++MetatensorSystemAdaptorKokkos<DeviceType>::MetatensorSystemAdaptorKokkos(LAMMPS *lmp, MetatensorSystemOptions options):
++    MetatensorSystemAdaptor(lmp, options),
++    device_(KokkosDeviceToTorch<DeviceType>::convert())
++{
++    // MetatensorSystemAdaptor allocate on CPU, move to the right device
++    this->atomic_types_ = this->atomic_types_.to(this->device_);
++
++    auto tensor_options = torch::TensorOptions()
++        .dtype(torch::kFloat64)
++        .device(this->device_)
++        .requires_grad(true);
++
++    this->strain = torch::eye(3, tensor_options);
++}
++
++template<class DeviceType>
++void MetatensorSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatensor_torch::System& system, NeighListKokkos<DeviceType>* list) {
++    auto _ = MetatensorTimer("converting kokkos neighbors with ghosts remapping");
++    auto dtype = system->positions().scalar_type();
++
++    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
++
++    {
++        auto _ = MetatensorTimer("identifying ghosts and real atoms");
++        /*-------------- this will be done on CPU for now ------------------------*/
++        // The hashmap in the following code is not easy to implement in either Kokkos or torch
++        // The cost of this section seems to be very low anyway
++
++        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
++        // atoms which are periodic images of local atoms back to the local atoms.
++        //
++        // Metatensor expects pairs corresponding to periodic atoms to be between
++        // the main atoms, but using the actual distance vector between the atom and
++        // the ghost.
++        original_atom_id_.clear();
++        original_atom_id_.reserve(total_n_atoms);
++
++        // identify all local atom by their LAMMPS atom tag.
++        local_atoms_tags_.clear();
++        for (int i=0; i<atom->nlocal; i++) {
++            original_atom_id_.emplace_back(i);
++            local_atoms_tags_.emplace(atom->tag[i], i);
++        }
++
++        // now loop over ghosts & map them back to the main cell if needed
++        ghost_atoms_tags_.clear();
++        for (int i=atom->nlocal; i<total_n_atoms; i++) {
++            auto tag = atom->tag[i];
++            auto it = local_atoms_tags_.find(tag);
++            if (it != local_atoms_tags_.end()) {
++                // this is the periodic image of an atom already owned by this domain
++                original_atom_id_.emplace_back(it->second);
++            } else {
++                // this can either be a periodic image of an atom owned by another
++                // domain, or directly an atom from another domain. Since we can not
++                // really distinguish between these, we take the first atom as the
++                // "main" one and remap all atoms with the same tag to the first one
++                auto it = ghost_atoms_tags_.find(tag);
++                if (it != ghost_atoms_tags_.end()) {
++                    // we already found this atom elsewhere in the system
++                    original_atom_id_.emplace_back(it->second);
++                } else {
++                    // this is the first time we are seeing this atom
++                    original_atom_id_.emplace_back(i);
++                    ghost_atoms_tags_.emplace(tag, i);
++                }
++            }
++        }
++    }
++    /*----------- end of "this will be done on CPU for now" --------------*/
++
++    auto original_id = torch::from_blob(
++        original_atom_id_.data(),
++        {total_n_atoms},
++        torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
++    ).to(this->device_);
++
++    auto neighbors_kk = list->d_neighbors_transpose;
++    auto max_number_of_neighbors = list->maxneighs;
++
++    auto neighbors = torch::zeros(
++        {total_n_atoms, max_number_of_neighbors},
++        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
++    );
++    // mask neighbors_kk with NEIGHMASK. Torch doesn't have this functionality, we do it in Kokkos
++    auto neighbors_kk_masked = UnmanagedView<int32_t**, DeviceType>(
++        neighbors.template data_ptr<int32_t>(),
++        total_n_atoms,
++        max_number_of_neighbors
++    );
++    Kokkos::parallel_for(
++        Kokkos::MDRangePolicy({0, 0}, {total_n_atoms, max_number_of_neighbors}),
++        KOKKOS_LAMBDA(size_t i, size_t j) {
++            neighbors_kk_masked(i, j) = neighbors_kk(i, j) & NEIGHMASK;
++        }
++    );
++
++    // Convert NL-related data to torch tensors
++    auto numneigh = torch::from_blob(
++        list->d_numneigh.data(),
++        {total_n_atoms},
++        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
++    );
++    auto ilist = torch::from_blob(
++        list->d_ilist.data(),
++        {total_n_atoms},
++        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
++    );
++
++    auto x = system->positions().detach();
++    auto cell_inverse = system->cell().detach().inverse();
++
++    // convert from LAMMPS NL format to metatensor NL format
++    auto expanded_arange = torch::arange(
++        max_number_of_neighbors,
++        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
++    ).unsqueeze(0).expand({total_n_atoms, -1});
++    auto neighbor_2d_mask = expanded_arange < numneigh.unsqueeze(1);
++
++    auto expanded_arange_other_dim = torch::arange(
++        total_n_atoms,
++        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
++    ).unsqueeze(1).expand({-1, max_number_of_neighbors});
++    auto index_for_ilist = expanded_arange_other_dim.masked_select(neighbor_2d_mask);
++
++    auto centers_id = ilist.index_select(0, index_for_ilist);
++    auto neighbors_id = neighbors.masked_select(neighbor_2d_mask);
++
++    // change centers and neighbors to the original atom ids
++    auto centers_original_id = original_id.index_select(0, centers_id);
++    auto neighbors_original_id = original_id.index_select(0, neighbors_id);
++
++    // The following code is a direct translation of the code in the non-Kokkos
++    // version (MetaTensorSystemAdaptor::setup_neighbors_remap), but rewritten
++    // in torch to use the GPU
++    for (auto& cache: caches_) {
++        // current values of various tensors, these change depending on full/half setting
++        torch::Tensor centers_id_cur;
++        torch::Tensor neighbors_id_cur;
++        torch::Tensor centers_original_id_cur;
++        torch::Tensor neighbors_original_id_cur;
++
++        // filtered tensors, i.e. only containing pairs actually below the cutoff
++        torch::Tensor centers_original_id_filt_cur;
++        torch::Tensor neighbors_original_id_filt_cur;
++        torch::Tensor distances_filt_cur;
++        torch::Tensor cell_shifts_cur;
++
++        // other tensors that need to live across multiple timed sections
++        torch::Tensor samples_indices;
++        torch::Tensor samples_values;
++        {
++            auto _ = MetatensorTimer("filtering LAMMPS neighbor list");
++            // half list mask, if necessary
++            auto full_list = cache.options->full_list();
++
++            if (full_list) {
++                centers_id_cur = centers_id;
++                neighbors_id_cur = neighbors_id;
++                centers_original_id_cur = centers_original_id;
++                neighbors_original_id_cur = neighbors_original_id;
++            } else {
++                auto half_list_mask = centers_original_id <= neighbors_original_id;
++                centers_id_cur = centers_id.masked_select(half_list_mask);
++                neighbors_id_cur = neighbors_id.masked_select(half_list_mask);
++                centers_original_id_cur = centers_original_id.masked_select(half_list_mask);
++                neighbors_original_id_cur = neighbors_original_id.masked_select(half_list_mask);
++            }
++
++            // distance mask
++            auto distances = x.index_select(0, neighbors_id_cur) - x.index_select(0, centers_id_cur);
++            auto cutoff_mask = torch::sum(distances.pow(2), 1) < cache.cutoff*cache.cutoff;
++
++            // index everything with the mask
++            auto centers_original_id_filt = centers_original_id_cur.masked_select(cutoff_mask);
++            auto neighbors_original_id_filt = neighbors_original_id_cur.masked_select(cutoff_mask);
++            auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
++
++            // find filtered interatomic vectors using the original atoms
++            auto original_distances_filtered =
++                x.index_select(0, neighbors_original_id_filt)
++                - x.index_select(0, centers_original_id_filt);
++
++            // cell shifts
++            auto pair_shifts = distances_filt - original_distances_filtered;
++            auto cell_shifts = pair_shifts.matmul(cell_inverse);
++            cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
++
++            if (full_list) {
++                centers_original_id_filt_cur = centers_original_id_filt;
++                neighbors_original_id_filt_cur = neighbors_original_id_filt;
++                distances_filt_cur = distances_filt;
++                cell_shifts_cur = cell_shifts;
++            } else {
++                auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
++                auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
++                auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
++                // reproduce this mask (from MetaTensorSystemAdaptor::setup_neighbors_remap) with torch:
++                // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
++                auto edge_mask = (
++                    (torch::sum(cell_shifts, 1) == 0) & (
++                        (cell_shifts.index({torch::indexing::Slice(), 2}) < 0) | (
++                            cell_shifts.index({torch::indexing::Slice(), 2}) == 0 &
++                            cell_shifts.index({torch::indexing::Slice(), 1}) < 0
++                        )
++                    )
++                );
++                auto final_mask = torch::logical_not(
++                    half_list_cell_mask | (
++                        pair_with_image_mask & (negative_half_space_mask | edge_mask)
++                    )
++                );
++                centers_original_id_filt_cur = centers_original_id_filt.masked_select(final_mask);
++                neighbors_original_id_filt_cur = neighbors_original_id_filt.masked_select(final_mask);
++                distances_filt_cur = distances_filt.index({final_mask, torch::indexing::Slice()});
++                cell_shifts_cur = cell_shifts.index({final_mask, torch::indexing::Slice()});
++            }
++
++            // make sure all the sample are unique
++            samples_values = torch::concatenate({
++                centers_original_id_filt_cur.unsqueeze(-1),
++                neighbors_original_id_filt_cur.unsqueeze(-1),
++                cell_shifts_cur
++            }, /*dim=*/1);
++
++            auto [samples_values_unique, samples_inverse, _counts] = torch::unique_dim(
++                samples_values, /*dim=*/0, /*sorted=*/true, /*return_inverse=*/true, /*return_counts=*/false
++            );
++            samples_values = samples_values_unique;
++
++            auto permutation = torch::arange(samples_inverse.size(0), samples_inverse.options());
++            samples_inverse = samples_inverse.flip({0});
++            permutation = permutation.flip({0});
++
++            samples_indices = torch::empty(samples_values.size(0), samples_inverse.options());
++            samples_indices.scatter_(0, samples_inverse, permutation);
++        }
++
++        // wrap into metatensor data structures
++        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
++        {
++            auto n_pairs = samples_values.size(0);
++            auto _ = MetatensorTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
++            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
++                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
++                samples_values
++            );
++        }
++
++        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
++        {
++            auto _ = MetatensorTimer("creating neighbors TensorBlock");
++
++            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
++                distances_filt_cur.index_select(0, samples_indices).unsqueeze(-1),
++                samples,
++                std::vector<metatensor_torch::TorchLabels>{
++                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(this->device_),
++                },
++                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(this->device_)
++            );
++        }
++
++        metatensor_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
++        system->add_neighbor_list(cache.options, neighbors);
++    }
++}
++
++
++template<class DeviceType>
++metatensor_torch::System MetatensorSystemAdaptorKokkos<DeviceType>::system_from_lmp(
++    NeighList* list,
++    bool do_virial,
++    bool remap_pairs,
++    torch::ScalarType dtype,
++    torch::Device device
++) {
++    auto _ = MetatensorTimer("creating System from LAMMPS-kokkos data");
++    assert(device == this->device_);
++
++    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
++
++    atomic_types_.resize_({total_n_atoms});
++    auto atomic_types_kk = UnmanagedView<int32_t*, DeviceType>(atomic_types_.data_ptr<int32_t>(), total_n_atoms);
++    auto type_mapping_kk = UnmanagedView<int32_t*, DeviceType>(options_.types_mapping, atomKK->ntypes + 1);
++    auto types_kk = atomKK->k_type.view<DeviceType>();
++    Kokkos::parallel_for(total_n_atoms, KOKKOS_LAMBDA(int i) {
++        atomic_types_kk(i) = type_mapping_kk(types_kk(i));
++    });
++
++    // atomKK->k_x contains "real" and then ghost atoms, in that order
++    auto k_x = atomKK->k_x.view<DeviceType>();
++    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
++
++    this->positions = torch::from_blob(
++        k_x.data(), {total_n_atoms, 3},
++        // requires_grad=true since we always need gradients w.r.t. positions
++        tensor_options.requires_grad(true)
++    );
++
++    auto cell = torch::zeros({3, 3}, tensor_options);
++    cell[0][0] = domain->xprd;
++
++    cell[1][0] = domain->xy;
++    cell[1][1] = domain->yprd;
++
++    cell[2][0] = domain->xz;
++    cell[2][1] = domain->yz;
++    cell[2][2] = domain->zprd;
++
++    auto system_positions = this->positions.to(dtype);
++    cell = cell.to(dtype);
++
++    if (do_virial) {
++        auto model_strain = this->strain.to(dtype);
++
++        // pretend to scale positions/cell by the strain so that
++        // it enters the computational graph.
++        system_positions = system_positions.matmul(model_strain);
++        cell = cell.matmul(model_strain);
++    }
++
++    // Periodic boundary conditions handling.
++    // While Metatensor atomistic models can support mixed PBC settings, we
++    // currently assume that the system is fully periodic and we throw an error
++    // otherwise
++    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
++        error->all(FLERR, "metatensor/kk currently requires a fully periodic system");
++    }
++    auto pbc = torch::tensor(
++        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
++        torch::TensorOptions().dtype(torch::kBool).device(this->device_)
++    );
++
++    auto system = torch::make_intrusive<metatensor_torch::SystemHolder>(
++        atomic_types_,
++        system_positions,
++        cell,
++        pbc
++    );
++
++    if (remap_pairs) {
++        auto* kk_list = dynamic_cast<NeighListKokkos<DeviceType>*>(list);
++        assert(kk_list != nullptr);
++        this->setup_neighbors_remap_kk(system, kk_list);
++    } else {
++        error->all(FLERR, "the kokkos version of metatensor requires remap_pairs to be true");
++    }
++
++    return system;
++}
++
++namespace LAMMPS_NS {
++template class MetatensorSystemAdaptorKokkos<LMPDeviceType>;
++#ifdef LMP_KOKKOS_GPU
++template class MetatensorSystemAdaptorKokkos<LMPHostType>;
++#endif
++}
+diff --git a/src/KOKKOS/metatensor_system_kokkos.h b/src/KOKKOS/metatensor_system_kokkos.h
+new file mode 100644
+index 0000000000..372a8b3a5b
+--- /dev/null
++++ b/src/KOKKOS/metatensor_system_kokkos.h
+@@ -0,0 +1,98 @@
++/* -*- c++ -*- ----------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++#ifndef LMP_METATENSOR_SYSTEM_KOKKOS_H
++#define LMP_METATENSOR_SYSTEM_KOKKOS_H
++
++#include "metatensor_system.h"
++#include "neigh_list_kokkos.h"
++
++namespace LAMMPS_NS {
++
++/* ---------------------------------------------------------------------- */
++
++// See https://kokkos.org/kokkos-core-wiki/API/core/execution_spaces.html for a
++// list of execution spaces.
++template<class DeviceType>
++struct KokkosDeviceToTorch {};
++
++#if defined(KOKKOS_ENABLE_SERIAL)
++template<> struct KokkosDeviceToTorch<Kokkos::Serial> {
++    static torch::Device convert() {
++        return torch::Device(torch::kCPU);
++    }
++};
++#endif
++
++#if defined(KOKKOS_ENABLE_CUDA)
++template<> struct KokkosDeviceToTorch<Kokkos::Cuda> {
++    static torch::Device convert() {
++        return torch::Device(torch::kCUDA, Kokkos::device_id());
++    }
++};
++#endif
++
++#if defined(KOKKOS_ENABLE_HIP)
++template<> struct KokkosDeviceToTorch<Kokkos::HIP> {
++    static torch::Device convert() {
++        return torch::Device(torch::kHIP, Kokkos::device_id());
++    }
++};
++#endif
++
++#if defined(KOKKOS_ENABLE_OPENMP)
++template<> struct KokkosDeviceToTorch<Kokkos::OpenMP> {
++    static torch::Device convert() {
++        return torch::Device(torch::kCPU);
++    }
++};
++#endif
++
++#if defined(KOKKOS_ENABLE_THREADS)
++template<> struct KokkosDeviceToTorch<Kokkos::Threads> {
++    static torch::Device convert() {
++        return torch::Device(torch::kCPU);
++    }
++};
++#endif
++
++// Kokkos::SYCL, Kokkos::OpenMPTarget, Kokkos::HPX don't have a matching device
++// in torch.
++
++/* ---------------------------------------------------------------------- */
++
++template<class DeviceType>
++class MetatensorSystemAdaptorKokkos : public MetatensorSystemAdaptor {
++public:
++    MetatensorSystemAdaptorKokkos(LAMMPS *lmp, MetatensorSystemOptions options);
++    ~MetatensorSystemAdaptorKokkos() override {}
++
++    // Create a metatensor system matching the LAMMPS-Kokkos system data
++    metatensor_torch::System system_from_lmp(
++        NeighList* list,
++        bool do_virial,
++        bool remap_pairs,
++        torch::ScalarType dtype,
++        torch::Device device
++    ) override;
++
++    void setup_neighbors_remap_kk(metatensor_torch::System& system, NeighListKokkos<DeviceType>* list);
++
++private:
++    /// Torch device corresponding to the kokkos `DeviceType`
++    torch::Device device_;
++};
++
++}    // namespace LAMMPS_NS
++
++#endif
+diff --git a/src/KOKKOS/pair_metatensor_kokkos.cpp b/src/KOKKOS/pair_metatensor_kokkos.cpp
+new file mode 100644
+index 0000000000..902b2ce82f
+--- /dev/null
++++ b/src/KOKKOS/pair_metatensor_kokkos.cpp
+@@ -0,0 +1,283 @@
++/* ----------------------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++/* ----------------------------------------------------------------------
++   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
++                         Filippo Bigi <filippo.bigi@epfl.ch>
++------------------------------------------------------------------------- */
++#include "pair_metatensor_kokkos.h"
++
++#include "error.h"
++#include "kokkos.h"
++#include "neigh_request.h"
++#include "atom_masks.h"
++
++#include "atom_kokkos.h"
++
++#include "metatensor_system_kokkos.h"
++#include "metatensor_types.h"
++#include "metatensor_timer.h"
++
++#include <algorithm>
++#include <cctype>
++
++using namespace LAMMPS_NS;
++
++// LAMMPS uses `LAMMPS_NS::tagint` and `int` for tags and neighbor lists, respectively.
++// For the moment, we require both to be int32_t for this interface
++static_assert(std::is_same_v<LAMMPS_NS::tagint, int32_t>, "Error: LAMMPS_NS::tagint must be int32_t to compile metatensor/kk");
++static_assert(std::is_same_v<int, int32_t>, "Error: int must be int32_t to compile metatensor/kk");
++
++template<typename T, class DeviceType>
++using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
++
++template<class DeviceType>
++PairMetatensorKokkos<DeviceType>::PairMetatensorKokkos(LAMMPS* lmp): PairMetatensor(lmp) {
++    // this will allow us to receive the NL in a GPU-friendly format
++    this->lmp->kokkos->neigh_transpose = 1;
++}
++
++template<class DeviceType>
++PairMetatensorKokkos<DeviceType>::~PairMetatensorKokkos() {}
++
++template<class DeviceType>
++void PairMetatensorKokkos<DeviceType>::init_style() {
++    PairMetatensor::init_style();
++
++    auto request = neighbor->find_request(this);
++    request->set_kokkos_host(
++        std::is_same_v<DeviceType, LMPHostType> &&
++        !std::is_same_v<DeviceType, LMPDeviceType>
++    );
++    request->set_kokkos_device(std::is_same_v<DeviceType, LMPDeviceType>);
++
++    // copy type mapping from host to device, to be able to give a device pointer
++    // to MetatensorSystemAdaptorKokkos
++    auto type_mapping_kk_host = UnmanagedView<int32_t*, LMPHostType>(this->type_mapping, atom->ntypes + 1);
++    this->type_mapping_kk = Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType>("type_mapping_kk", atom->ntypes + 1);
++    Kokkos::deep_copy(this->type_mapping_kk, type_mapping_kk_host);
++
++    auto options = MetatensorSystemOptions{
++        this->type_mapping_kk.data(),
++        mts_data->max_cutoff,
++        mts_data->check_consistency,
++    };
++
++    // override the system adaptor with the kokkos version
++    this->system_adaptor = std::make_unique<MetatensorSystemAdaptorKokkos<DeviceType>>(lmp, options);
++
++    // request NL with the new adaptor
++    auto requested_nl = mts_data->model->run_method("requested_neighbor_lists");
++    for (const auto& ivalue: requested_nl.toList()) {
++        auto options = ivalue.get().toCustomClass<metatensor_torch::NeighborListOptionsHolder>();
++        auto cutoff = options->engine_cutoff(mts_data->evaluation_options->length_unit());
++        assert(cutoff <= mts_data->max_cutoff);
++
++        this->system_adaptor->add_nl_request(cutoff, options);
++    }
++}
++
++template<class DeviceType>
++void PairMetatensorKokkos<DeviceType>::pick_device(torch::Device* device, const char* requested) {
++    *device = KokkosDeviceToTorch<DeviceType>::convert();
++
++    if (requested != nullptr) {
++        auto requested_str = std::string(requested);
++        std::transform(requested_str.begin(), requested_str.end(), requested_str.begin(), ::tolower);
++        if (c10::DeviceTypeName(device->type(), /*lower_case=*/true) != requested_str) {
++            error->all(FLERR,
++                "requested device '{}' does not match the device being used by kokkos '{}', "
++                "use the non-kokkos version of this pair style to use a different "
++                "device for the model and LAMMPS",
++                requested, device->str()
++            );
++        }
++    }
++}
++
++template<class DeviceType>
++void PairMetatensorKokkos<DeviceType>::compute(int eflag, int vflag) {
++    if (std::getenv("LAMMPS_METATENSOR_PROFILE") != nullptr) {
++        MetatensorTimer::enable(true);
++    } else {
++        MetatensorTimer::enable(false);
++    }
++
++    auto _ = MetatensorTimer("PairMetatensorKokkos::compute");
++
++    /// Declare what we need to read from the atomKK object and what we will modify
++    this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, X_MASK | F_MASK | TAG_MASK | TYPE_MASK | ENERGY_MASK | VIRIAL_MASK);
++    this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, ENERGY_MASK | F_MASK | VIRIAL_MASK);
++
++    if (eflag || vflag) {
++        ev_setup(eflag, vflag);
++    } else {
++        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
++    }
++
++    if (eflag_atom) {
++        mts_data->evaluation_options->outputs.at("energy")->per_atom = true;
++    } else {
++        mts_data->evaluation_options->outputs.at("energy")->per_atom = false;
++    }
++
++    auto dtype = torch::kFloat64;
++    if (mts_data->capabilities->dtype() == "float64") {
++        dtype = torch::kFloat64;
++    } else if (mts_data->capabilities->dtype() == "float32") {
++        dtype = torch::kFloat32;
++    } else {
++        error->all(FLERR, "the model requested an unsupported dtype '{}'", mts_data->capabilities->dtype());
++    }
++
++    // transform from LAMMPS to metatensor System
++    auto system = this->system_adaptor->system_from_lmp(
++        mts_list,
++        static_cast<bool>(vflag_global),
++        mts_data->remap_pairs,
++        dtype,
++        this->mts_data->device
++    );
++
++    // only run the calculation for atoms actually in the current domain
++    mts_data->selected_atoms_values.resize_({atom->nlocal, 2});
++    mts_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
++    auto options = mts_data->selected_atoms_values.options();
++    mts_data->selected_atoms_values.index_put_(
++        {torch::indexing::Slice(), 1},
++        torch::arange(atom->nlocal, options)
++    );
++
++    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
++        std::vector<std::string>{"system", "atom"}, mts_data->selected_atoms_values
++    );
++    mts_data->evaluation_options->set_selected_atoms(selected_atoms);
++
++    torch::IValue result_ivalue;
++    try {
++        auto _ = MetatensorTimer("running Model::forward");
++        result_ivalue = mts_data->model->forward({
++            std::vector<metatensor_torch::System>{system},
++            mts_data->evaluation_options,
++            mts_data->check_consistency
++        });
++    } catch (const std::exception& e) {
++        error->all(FLERR, "error evaluating the torch model: {}", e.what());
++    }
++
++    auto result = result_ivalue.toGenericDict();
++    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
++    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
++    auto energy_tensor = energy_block->values();
++
++    // compute forces/virial on device with backward propagation
++    {
++        // reset gradients to zero before calling backward
++        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
++        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
++
++        auto _ = MetatensorTimer("running Model::backward");
++        energy_tensor.backward(-torch::ones_like(energy_tensor));
++    }
++
++    {
++        auto _ = MetatensorTimer("storing model output in LAMMPS data structures");
++
++        // move results to cpu for storing
++        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
++        auto energy_samples = energy_block->samples();
++
++        // store the energy returned by the model
++        torch::Tensor global_energy;
++        if (eflag_atom) {
++            assert(energy_samples->size() == 2);
++            assert(energy_samples->names()[0] == "system");
++            assert(energy_samples->names()[1] == "atom");
++
++            auto samples_values = energy_samples->values().to(torch::kCPU);
++            auto samples = samples_values.accessor<int32_t, 2>();
++
++            int64_t n_atoms = atom->nlocal + atom->nghost;
++            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
++
++            auto energies = energy_detached.accessor<double, 2>();
++            for (int64_t i=0; i<energy_samples->count(); i++) {
++                assert(samples[i][0] == 0);
++                // handle potentially out of order samples in
++                // the per-atom energy tensor
++                auto atom_i = samples[i][1];
++                assert(atom_i < n_atoms);
++                eatom[atom_i] += energies[i][0];
++            }
++
++            global_energy = energy_detached.sum(0);
++            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
++        } else {
++            assert(energy_samples->size() == 1);
++            assert(energy_samples->names()[0] == "system");
++
++            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
++            global_energy = energy_detached.reshape({1});
++        }
++
++        if (eflag_global) {
++            eng_vdwl += global_energy.item<double>();
++        }
++
++        // store forces/virial
++        auto forces_tensor = this->system_adaptor->positions.grad().contiguous();
++        assert(forces_tensor.scalar_type() == torch::kFloat64);
++
++        auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
++        auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
++            forces_tensor.template data_ptr<double>(),
++            forces_tensor.size(0), 3
++        );
++
++        Kokkos::parallel_for(
++            system->size(),
++            KOKKOS_LAMBDA(size_t i) {
++                forces_lammps_kk(i, 0) += forces_metatensor_kk(i, 0);
++                forces_lammps_kk(i, 1) += forces_metatensor_kk(i, 1);
++                forces_lammps_kk(i, 2) += forces_metatensor_kk(i, 2);
++            }
++        );
++
++        assert(!vflag_fdotr);
++
++        if (vflag_global) {
++            auto virial_tensor = this->system_adaptor->strain.grad().to(torch::kCPU);
++            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
++            auto predicted_virial = virial_tensor.template accessor<double, 2>();
++
++            virial[0] += predicted_virial[0][0];
++            virial[1] += predicted_virial[1][1];
++            virial[2] += predicted_virial[2][2];
++
++            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
++            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
++            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
++        }
++
++        if (vflag_atom) {
++            error->all(FLERR, "per atom virial is not implemented");
++        }
++    }
++}
++
++namespace LAMMPS_NS {
++template class PairMetatensorKokkos<LMPDeviceType>;
++#ifdef LMP_KOKKOS_GPU
++template class PairMetatensorKokkos<LMPHostType>;
++#endif
++}
+diff --git a/src/KOKKOS/pair_metatensor_kokkos.h b/src/KOKKOS/pair_metatensor_kokkos.h
+new file mode 100644
+index 0000000000..1463574f9d
+--- /dev/null
++++ b/src/KOKKOS/pair_metatensor_kokkos.h
+@@ -0,0 +1,53 @@
++/* -*- c++ -*- ----------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++#ifdef PAIR_CLASS
++// clang-format off
++PairStyle(metatensor/kk, PairMetatensorKokkos<LMPDeviceType>);
++// clang-format on
++#else
++
++#ifndef LMP_PAIR_METATENSOR_KOKKOS_H
++#define LMP_PAIR_METATENSOR_KOKKOS_H
++
++#include "pair_kokkos.h"
++#include "pair_metatensor.h"
++
++namespace LAMMPS_NS {
++
++template<class DeviceType>
++class MetatensorSystemAdaptorKokkos;
++
++template<class DeviceType>
++struct PairMetatensorDataKokkos;
++
++/// I noticed that most other kokkos packages inherit from their non-kokkos
++/// counterparts. It doesn't look like a good idea to me because
++/// they end up overriding everything... Not doing it here for now.
++template<class DeviceType>
++class PairMetatensorKokkos : public PairMetatensor {
++public:
++    PairMetatensorKokkos(class LAMMPS *);
++    ~PairMetatensorKokkos();
++
++    void init_style() override;
++    void compute(int eflag, int vflag) override;
++private:
++    void pick_device(c10::Device* device, const char* requested) override;
++
++    Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType> type_mapping_kk;
++};
++
++}    // namespace LAMMPS_NS
++
++#endif
++#endif
+diff --git a/src/ML-METATENSOR/Install.sh b/src/ML-METATENSOR/Install.sh
+new file mode 100755
+index 0000000000..e590c689d7
+--- /dev/null
++++ b/src/ML-METATENSOR/Install.sh
+@@ -0,0 +1,64 @@
++# Install/unInstall package files in LAMMPS
++# mode = 0/1/2 for uninstall/install/update
++
++mode=$1
++
++# enforce using portable C locale
++LC_ALL=C
++export LC_ALL
++
++# arg1 = file, arg2 = file it depends on
++
++action () {
++  if (test $mode = 0) then
++    rm -f ../$1
++  elif (! cmp -s $1 ../$1) then
++    if (test -z "$2" || test -e ../$2) then
++      cp $1 ..
++      if (test $mode = 2) then
++        echo "  updating src/$1"
++      fi
++    fi
++  elif (test -n "$2") then
++    if (test ! -e ../$2) then
++      rm -f ../$1
++    fi
++  fi
++}
++
++# all package files with no dependencies
++
++for file in *.cpp *.h; do
++  test -f ${file} && action $file
++done
++
++# edit 2 Makefile.package files to include/exclude package info
++
++if (test $1 = 1) then
++
++  if (test -e ../Makefile.package) then
++    sed -i -e 's/[^ \t]*metatensor[^ \t]* //' ../Makefile.package
++    sed -i -e 's|^PKG_SYSINC =[ \t]*|&$(metatensor_SYSINC) |' ../Makefile.package
++    sed -i -e 's|^PKG_SYSLIB =[ \t]*|&$(metatensor_SYSLIB) |' ../Makefile.package
++    sed -i -e 's|^PKG_SYSPATH =[ \t]*|&$(metatensor_SYSPATH) |' ../Makefile.package
++  fi
++
++  if (test -e ../Makefile.package.settings) then
++    sed -i -e '/^[ \t]*include.*metatensor.*$/d' ../Makefile.package.settings
++    # multiline form needed for BSD sed on Macs
++    sed -i -e '4 i \
++include ..\/..\/lib\/metatensor\/Makefile.lammps\
++' ../Makefile.package.settings
++  fi
++
++elif (test $1 = 0) then
++
++  if (test -e ../Makefile.package) then
++    sed -i -e 's/[^ \t]*metatensor[^ \t]* //' ../Makefile.package
++  fi
++
++  if (test -e ../Makefile.package.settings) then
++    sed -i -e '/^[ \t]*include.*metatensor.*$/d' ../Makefile.package.settings
++  fi
++
++fi
+diff --git a/src/ML-METATENSOR/metatensor_system.cpp b/src/ML-METATENSOR/metatensor_system.cpp
+new file mode 100644
+index 0000000000..3c8ed68caa
+--- /dev/null
++++ b/src/ML-METATENSOR/metatensor_system.cpp
+@@ -0,0 +1,560 @@
++/* ----------------------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++/* ----------------------------------------------------------------------
++   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
++------------------------------------------------------------------------- */
++#include "metatensor_system.h"
++
++#include "atom.h"
++#include "domain.h"
++#include "error.h"
++
++#include "neigh_list.h"
++
++#include "./metatensor_timer.h"
++
++using namespace LAMMPS_NS;
++
++MetatensorSystemAdaptor::MetatensorSystemAdaptor(LAMMPS *lmp, MetatensorSystemOptions options):
++    Pointers(lmp),
++    options_(std::move(options)),
++    caches_(),
++    atomic_types_(torch::zeros({0}, torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)))
++{
++    auto tensor_options = torch::TensorOptions()
++        .dtype(torch::kFloat64)
++        .device(torch::kCPU)
++        .requires_grad(true);
++
++    this->strain = torch::eye(3, tensor_options);
++}
++
++MetatensorSystemAdaptor::~MetatensorSystemAdaptor() {}
++
++void MetatensorSystemAdaptor::add_nl_request(double cutoff, metatensor_torch::NeighborListOptions request) {
++    if (cutoff > options_.interaction_range) {
++        error->all(FLERR,
++            "Invalid metatensor model: one of the requested neighbor lists "
++            "has a cutoff ({}) larger than the model interaction range ({})",
++            cutoff, options_.interaction_range
++        );
++    } else if (cutoff < 0 || !std::isfinite(cutoff)) {
++        error->all(FLERR,
++            "model requested an invalid cutoff for neighbors list: {} "
++            "(cutoff in model units is {})",
++            cutoff, request->cutoff()
++        );
++    }
++
++    caches_.push_back({
++        cutoff,
++        request,
++        /*known_samples = */ {},
++        /*samples = */ {},
++        /*distances_f64 = */ {},
++        /*distances_f32 = */ {},
++    });
++}
++
++
++static std::array<int32_t, 3> cell_shifts(
++    const std::array<std::array<double, 3>, 3>& cell_inv,
++    const std::array<double, 3>& pair_shift
++) {
++    auto shift_a = static_cast<int32_t>(std::round(
++        cell_inv[0][0] * pair_shift[0] +
++        cell_inv[0][1] * pair_shift[1] +
++        cell_inv[0][2] * pair_shift[2]
++    ));
++    auto shift_b = static_cast<int32_t>(std::round(
++        cell_inv[1][0] * pair_shift[0] +
++        cell_inv[1][1] * pair_shift[1] +
++        cell_inv[1][2] * pair_shift[2]
++    ));
++    auto shift_c = static_cast<int32_t>(std::round(
++        cell_inv[2][0] * pair_shift[0] +
++        cell_inv[2][1] * pair_shift[1] +
++        cell_inv[2][2] * pair_shift[2]
++    ));
++
++    return {shift_a, shift_b, shift_c};
++}
++
++
++void MetatensorSystemAdaptor::setup_neighbors_remap(metatensor_torch::System& system, NeighList *list) {
++    auto _ = MetatensorTimer("converting neighbors with ghosts remapping");
++    auto dtype = system->positions().scalar_type();
++    auto device = system->positions().device();
++
++    double** x = atom->x;
++    auto total_n_atoms = atom->nlocal + atom->nghost;
++
++    auto cell_inv_tensor = system->cell().inverse().t().to(torch::kCPU).to(torch::kFloat64);
++    auto cell_inv_accessor = cell_inv_tensor.accessor<double, 2>();
++    auto cell_inv = std::array<std::array<double, 3>, 3>{{
++        {{cell_inv_accessor[0][0], cell_inv_accessor[0][1], cell_inv_accessor[0][2]}},
++        {{cell_inv_accessor[1][0], cell_inv_accessor[1][1], cell_inv_accessor[1][2]}},
++        {{cell_inv_accessor[2][0], cell_inv_accessor[2][1], cell_inv_accessor[2][2]}},
++    }};
++
++    {
++        auto _ = MetatensorTimer("identifying ghosts and real atoms");
++
++        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
++        // atoms which are periodic images of local atoms back to the local atoms.
++        //
++        // Metatensor expects pairs corresponding to periodic atoms to be between
++        // the main atoms, but using the actual distance vector between the atom and
++        // the ghost.
++        original_atom_id_.clear();
++        original_atom_id_.reserve(total_n_atoms);
++
++        // identify all local atom by their LAMMPS atom tag.
++        local_atoms_tags_.clear();
++        for (int i=0; i<atom->nlocal; i++) {
++            original_atom_id_.emplace_back(i);
++            local_atoms_tags_.emplace(atom->tag[i], i);
++        }
++
++        // now loop over ghosts & map them back to the main cell if needed
++        ghost_atoms_tags_.clear();
++        for (int i=atom->nlocal; i<total_n_atoms; i++) {
++            auto tag = atom->tag[i];
++            auto it = local_atoms_tags_.find(tag);
++            if (it != local_atoms_tags_.end()) {
++                // this is the periodic image of an atom already owned by this domain
++                original_atom_id_.emplace_back(it->second);
++            } else {
++                // this can either be a periodic image of an atom owned by another
++                // domain, or directly an atom from another domain. Since we can not
++                // really distinguish between these, we take the first atom as the
++                // "main" one and remap all atoms with the same tag to the first one
++                auto it = ghost_atoms_tags_.find(tag);
++                if (it != ghost_atoms_tags_.end()) {
++                    // we already found this atom elsewhere in the system
++                    original_atom_id_.emplace_back(it->second);
++                } else {
++                    // this is the first time we are seeing this atom
++                    original_atom_id_.emplace_back(i);
++                    ghost_atoms_tags_.emplace(tag, i);
++                }
++            }
++        }
++    }
++
++    for (auto& cache: caches_) {
++        {
++            auto _ = MetatensorTimer("filtering LAMMPS neighbor list");
++
++            auto cutoff2 = cache.cutoff * cache.cutoff;
++            auto full_list = cache.options->full_list();
++
++            // convert from LAMMPS neighbors list to metatensor format
++            cache.known_samples.clear();
++            cache.samples.clear();
++            cache.distances_f32.clear();
++            cache.distances_f64.clear();
++            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
++                auto atom_i = list->ilist[ii];
++                assert(atom_i < total_n_atoms);
++                auto original_atom_i = original_atom_id_[atom_i];
++
++                auto neighbors = list->firstneigh[ii];
++                for (int jj=0; jj<list->numneigh[ii]; jj++) {
++                    auto atom_j = neighbors[jj] & NEIGHMASK;
++                    assert(atom_j < total_n_atoms);
++                    auto original_atom_j = original_atom_id_[atom_j];
++
++                    if (!full_list && original_atom_i > original_atom_j) {
++                        // Remove extra pairs if the model requested half-lists
++                        continue;
++                    }
++
++                    auto distance = std::array<double, 3>{
++                        x[atom_j][0] - x[atom_i][0],
++                        x[atom_j][1] - x[atom_i][1],
++                        x[atom_j][2] - x[atom_i][2],
++                    };
++
++                    auto distance2 = (
++                        distance[0] * distance[0] +
++                        distance[1] * distance[1] +
++                        distance[2] * distance[2]
++                    );
++                    if (distance2 > cutoff2) {
++                        // LAMMPS neighbors list contains some pairs after the
++                        // cutoff, we filter them here
++                        continue;
++                    }
++
++                    // Compute the cell shift for the pair.
++                    auto shift_i = std::array<double, 3>{
++                        x[atom_i][0] - x[original_atom_i][0],
++                        x[atom_i][1] - x[original_atom_i][1],
++                        x[atom_i][2] - x[original_atom_i][2],
++                    };
++                    auto shift_j = std::array<double, 3>{
++                        x[atom_j][0] - x[original_atom_j][0],
++                        x[atom_j][1] - x[original_atom_j][1],
++                        x[atom_j][2] - x[original_atom_j][2],
++                    };
++                    auto pair_shift = std::array<double, 3>{
++                        shift_j[0] - shift_i[0],
++                        shift_j[1] - shift_i[1],
++                        shift_j[2] - shift_i[2],
++                    };
++
++                    auto shift = std::array<int32_t, 3>{0, 0, 0};
++                    if (pair_shift[0] != 0 || pair_shift[1] != 0 || pair_shift[2] != 0) {
++                        shift = cell_shifts(cell_inv, pair_shift);
++
++                        if (!full_list && original_atom_i == original_atom_j) {
++                            // If a half neighbors list has been requested, do
++                            // not include the same pair between an atom and
++                            // it's periodic image twice with opposite cell
++                            // shifts (e.g. [1, -1, 1] and [-1, 1, -1]).
++                            //
++                            // Instead we pick pairs in the positive plan of
++                            // shifts.
++                            if (shift[0] + shift[1] + shift[2] < 0) {
++                                // drop shifts on the negative half-space
++                                continue;
++                            }
++
++                            if ((shift[0] + shift[1] + shift[2] == 0)
++                                && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0))) {
++                                // drop shifts in the negative half plane or the
++                                // negative shift[1] axis.
++                                //
++                                // See below for a graphical representation: we are
++                                // keeping the shifts indicated with `O` and
++                                // dropping the ones indicated with `X`
++                                //
++                                //  O O O │ O O O
++                                //  O O O │ O O O
++                                //  O O O │ O O O
++                                // ─X─X─X─┼─O─O─O─
++                                //  X X X │ X X X
++                                //  X X X │ X X X
++                                //  X X X │ X X X
++                                continue;
++                            }
++                        }
++                    }
++
++                    auto sample = std::array<int32_t, 5>{
++                        original_atom_i,
++                        original_atom_j,
++                        shift[0],
++                        shift[1],
++                        shift[2],
++                    };
++
++                    // only add the pair if it is not already known. The same pair
++                    // can occur multiple time between two periodic ghosts shifted
++                    // around by the same amount, but we only want one of these pairs.
++                    if (cache.known_samples.insert(sample).second) {
++                        cache.samples.push_back(sample);
++
++                        if (dtype == torch::kFloat64) {
++                            cache.distances_f64.push_back(distance);
++                        } else if (dtype == torch::kFloat32) {
++                            cache.distances_f32.push_back({
++                                static_cast<float>(distance[0]),
++                                static_cast<float>(distance[1]),
++                                static_cast<float>(distance[2])
++                            });
++                        } else {
++                            // should be unreachable
++                            error->all(FLERR, "invalid dtype, this is a bug");
++                        }
++                    }
++                }
++            }
++        }
++
++        int64_t n_pairs = cache.samples.size();
++        auto samples_values = torch::from_blob(
++            reinterpret_cast<int32_t*>(cache.samples.data()),
++            {n_pairs, 5},
++            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
++        );
++
++        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
++        {
++            auto _ = MetatensorTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
++            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
++                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
++                samples_values
++            );
++        }
++
++        auto distances_vectors = torch::Tensor();
++        if (dtype == torch::kFloat64) {
++            distances_vectors = torch::from_blob(
++                cache.distances_f64.data(),
++                {n_pairs, 3, 1},
++                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
++            );
++        } else if (dtype == torch::kFloat32) {
++            distances_vectors = torch::from_blob(
++                cache.distances_f32.data(),
++                {n_pairs, 3, 1},
++                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
++            );
++        } else {
++            // should be unreachable
++            error->all(FLERR, "invalid dtype, this is a bug");
++        }
++
++        {
++            auto _ = MetatensorTimer("moving neighbor data to dtype/device");
++            distances_vectors = distances_vectors.to(dtype).to(device);
++            samples = samples->to(device);
++        }
++
++        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
++        {
++            auto _ = MetatensorTimer("creating neighbors TensorBlock");
++            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
++                distances_vectors,
++                samples,
++                std::vector<metatensor_torch::TorchLabels>{
++                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
++                },
++                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
++            );
++        }
++
++        metatensor_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
++        system->add_neighbor_list(cache.options, neighbors);
++    }
++}
++
++void MetatensorSystemAdaptor::setup_neighbors_no_remap(metatensor_torch::System& system, NeighList *list) {
++    auto _ = MetatensorTimer("converting neighbors without ghosts remapping");
++
++    auto dtype = system->positions().scalar_type();
++    auto device = system->positions().device();
++
++    double** x = atom->x;
++
++    for (auto& cache: caches_) {
++        {
++            auto _ = MetatensorTimer("filtering LAMMPS neighbor list");
++
++            auto cutoff2 = cache.cutoff * cache.cutoff;
++            auto full_list = cache.options->full_list();
++
++            // convert from LAMMPS neighbors list to metatensor format
++            cache.known_samples.clear();
++            cache.samples.clear();
++            cache.distances_f32.clear();
++            cache.distances_f64.clear();
++            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
++                auto atom_i = list->ilist[ii];
++
++                auto neighbors = list->firstneigh[ii];
++                for (int jj=0; jj<list->numneigh[ii]; jj++) {
++                    auto atom_j = neighbors[jj];
++
++                    if (!full_list && atom_i > atom_j) {
++                        // Remove extra pairs if the model requested half-lists
++                        continue;
++                    }
++
++                    auto distance = std::array<double, 3>{
++                        x[atom_j][0] - x[atom_i][0],
++                        x[atom_j][1] - x[atom_i][1],
++                        x[atom_j][2] - x[atom_i][2],
++                    };
++
++                    auto distance2 = (
++                        distance[0] * distance[0] +
++                        distance[1] * distance[1] +
++                        distance[2] * distance[2]
++                    );
++                    if (distance2 > cutoff2) {
++                        // LAMMPS neighbors list contains some pairs after the
++                        // cutoff, we filter them here
++                        continue;
++                    }
++
++                    auto sample = std::array<int32_t, 5>{atom_i, atom_j, 0, 0, 0};
++
++
++                    cache.samples.push_back(sample);
++
++                    if (dtype == torch::kFloat64) {
++                        cache.distances_f64.push_back(distance);
++                    } else if (dtype == torch::kFloat32) {
++                        cache.distances_f32.push_back({
++                            static_cast<float>(distance[0]),
++                            static_cast<float>(distance[1]),
++                            static_cast<float>(distance[2])
++                        });
++                    } else {
++                        // should be unreachable
++                        error->all(FLERR, "invalid dtype, this is a bug");
++                    }
++                }
++            }
++        }
++
++        int64_t n_pairs = cache.samples.size();
++        auto samples_values = torch::from_blob(
++            reinterpret_cast<int32_t*>(cache.samples.data()),
++            {n_pairs, 5},
++            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
++        );
++
++        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
++        {
++            auto _ = MetatensorTimer("creating samples Labels (" +  std::to_string(n_pairs) +" pairs)");
++            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
++                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
++                samples_values
++            );
++        }
++
++        auto distances_vectors = torch::Tensor();
++        if (dtype == torch::kFloat64) {
++            distances_vectors = torch::from_blob(
++                cache.distances_f64.data(),
++                {n_pairs, 3, 1},
++                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
++            );
++        } else if (dtype == torch::kFloat32) {
++            distances_vectors = torch::from_blob(
++                cache.distances_f32.data(),
++                {n_pairs, 3, 1},
++                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
++            );
++        } else {
++            // should be unreachable
++            error->all(FLERR, "invalid dtype, this is a bug");
++        }
++
++        {
++            auto _ = MetatensorTimer("moving neighbor data to dtype/device");
++            distances_vectors = distances_vectors.to(dtype).to(device);
++            samples = samples->to(device);
++        }
++
++        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
++        {
++            auto _ = MetatensorTimer("creating neighbors TensorBlock");
++            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
++                distances_vectors,
++                samples,
++                std::vector<metatensor_torch::TorchLabels>{
++                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
++                },
++                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
++            );
++        }
++
++        metatensor_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
++        system->add_neighbor_list(cache.options, neighbors);
++    }
++}
++
++
++metatensor_torch::System MetatensorSystemAdaptor::system_from_lmp(
++    NeighList* list,
++    bool do_virial,
++    bool remap_pairs,
++    torch::ScalarType dtype,
++    torch::Device device
++) {
++    auto _ = MetatensorTimer("creating System from LAMMPS data");
++
++    double** x = atom->x;
++    auto total_n_atoms = atom->nlocal + atom->nghost;
++
++    atomic_types_.resize_({total_n_atoms});
++    for (int i=0; i<total_n_atoms; i++) {
++        atomic_types_[i] = options_.types_mapping[atom->type[i]];
++    }
++
++    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU);
++
++    // atom->x contains "real" and then ghost atoms, in that order
++    this->positions = torch::from_blob(
++        *x, {total_n_atoms, 3},
++        // requires_grad=true since we always need gradients w.r.t. positions
++        tensor_options.requires_grad(true)
++    );
++
++    auto cell = torch::zeros({3, 3}, tensor_options);
++    cell[0][0] = domain->xprd;
++
++    cell[1][0] = domain->xy;
++    cell[1][1] = domain->yprd;
++
++    cell[2][0] = domain->xz;
++    cell[2][1] = domain->yz;
++    cell[2][2] = domain->zprd;
++
++    auto system_positions = this->positions.to(dtype).to(device);
++    cell = cell.to(dtype).to(device);
++
++    if (do_virial) {
++        auto model_strain = this->strain.to(dtype).to(device);
++
++        // pretend to scale positions/cell by the strain so that
++        // it enters the computational graph.
++        system_positions = system_positions.matmul(model_strain);
++        cell = cell.matmul(model_strain);
++    }
++
++    // Periodic boundary conditions handling.
++    // While Metatensor atomistic models can support mixed PBC settings, we
++    // currently assume that the system is fully periodic and we throw an error
++    // otherwise
++    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
++        error->all(FLERR, "pair_metatensor requires a fully periodic system");
++    }
++    auto pbc = torch::tensor(
++        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
++        torch::TensorOptions().dtype(torch::kBool).device(device)
++    );
++
++    // Note that something like this:
++    //     cell.index_put_(
++    //         {torch::logical_not(pbc)},
++    //         torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(device))
++    //     );
++    //
++    // would allow creating System with non-periodic directions, but we're using
++    // the inverse of the cell matrix to filter the neighbor list, and the cell
++    // matrix becomes singular if any of its rows are zero. This requires some
++    // changes in the neighbor list filtering code to handle non-periodic
++    // directions.
++
++    auto system = torch::make_intrusive<metatensor_torch::SystemHolder>(
++        atomic_types_.to(device),
++        system_positions,
++        cell,
++        pbc
++    );
++
++    if (remap_pairs) {
++        this->setup_neighbors_remap(system, list);
++    } else {
++        this->setup_neighbors_no_remap(system, list);
++    }
++
++    return system;
++}
+diff --git a/src/ML-METATENSOR/metatensor_system.h b/src/ML-METATENSOR/metatensor_system.h
+new file mode 100644
+index 0000000000..cebafd4a92
+--- /dev/null
++++ b/src/ML-METATENSOR/metatensor_system.h
+@@ -0,0 +1,143 @@
++/* -*- c++ -*- ----------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++#ifndef LMP_METATENSOR_SYSTEM_H
++#define LMP_METATENSOR_SYSTEM_H
++
++#include <vector>
++#include <array>
++#include <unordered_set>
++
++#include "pointers.h"
++#include "pair.h"
++#include "neigh_list.h"
++
++#include <metatensor/torch/atomistic.hpp>
++
++
++namespace LAMMPS_NS {
++
++struct MetatensorSystemOptions {
++    // Mapping from LAMMPS types to metatensor types.
++    // If used with kokkos, this should be a device pointer
++    int32_t* types_mapping;
++    // interaction range of the model, in LAMMPS units
++    double interaction_range;
++    // should we run extra checks on the neighbor lists?
++    bool check_consistency;
++};
++
++// data for metatensor neighbors lists
++struct MetatensorNeighborsData {
++    // single neighbors sample containing [i, j, S_a, S_b, S_c]
++    using sample_t = std::array<int32_t, 5>;
++
++    struct SampleHasher {
++        static void hash_combine(std::size_t& seed, const int32_t& v) {
++            seed ^= std::hash<int32_t>()(v) + 0x9e3779b9 + (seed<<6) + (seed>>2);
++        }
++
++        size_t operator()(const sample_t& s) const {
++            size_t hash = 0;
++            hash_combine(hash, s[0]);
++            hash_combine(hash, s[1]);
++            hash_combine(hash, s[2]);
++            hash_combine(hash, s[3]);
++            hash_combine(hash, s[4]);
++            return hash;
++        }
++    };
++
++    // cutoff for this NL in LAMMPS units
++    double cutoff;
++    // options of the NL as requested by the model
++    metatensor_torch::NeighborListOptions options;
++
++    // Below are cached allocations for the LAMMPS -> metatensor NL translation
++    // TODO: report memory usage for these?
++
++    // we keep the set of samples twice: once in `known_samples` to remove
++    // duplicated pairs, and once in `samples` in a format that can be
++    // used to create a torch::Tensor.
++    std::unordered_set<sample_t, SampleHasher> known_samples;
++    std::vector<sample_t> samples;
++    // pairs distances vectors
++    std::vector<std::array<double, 3>> distances_f64;
++    std::vector<std::array<float, 3>> distances_f32;
++};
++
++class MetatensorSystemAdaptor : public Pointers {
++public:
++    MetatensorSystemAdaptor(LAMMPS *lmp, MetatensorSystemOptions options);
++
++    virtual ~MetatensorSystemAdaptor();
++
++    void add_nl_request(double cutoff, metatensor_torch::NeighborListOptions request);
++
++    // Create a metatensor system matching the LAMMPS system data
++    virtual metatensor_torch::System system_from_lmp(
++        NeighList* list,
++        bool do_virial,
++        bool remap_pairs,
++        torch::ScalarType dtype,
++        torch::Device device
++    );
++
++    // Explicit strain for virial calculations. This uses the same dtype/device
++    // as LAMMPS data (positions, …)
++    torch::Tensor strain;
++    // keep the positions as coming from LAMMPS (before any dtype/device
++    // conversion) to access its gradient
++    torch::Tensor positions;
++
++ protected:
++    // setup the metatensor neighbors list from the internal LAMMPS one,
++    // remapping periodic ghosts to the corresponding local atom
++    void setup_neighbors_remap(metatensor_torch::System& system, NeighList* list);
++
++    // setup the metatensor neighbors list from the internal LAMMPS one,
++    // WITHOUT remapping periodic ghosts to the corresponding local atom.
++    //
++    // This produces a larger NL but skips the cost of the remapping
++    void setup_neighbors_no_remap(metatensor_torch::System& system, NeighList* list);
++
++    // options for this system adaptor
++    MetatensorSystemOptions options_;
++
++    // allocations caches for all the NL requested by the model
++    std::vector<MetatensorNeighborsData> caches_;
++    // allocation cache for the atomic types in the system
++    torch::Tensor atomic_types_;
++    // allocation cache holding the "original atom" id for all atoms in the
++    // system. This is the same as the atom id for all local atoms. For ghost
++    // atoms, this is either the id of the corresponding local atom if the ghost
++    // is a periodic image of a local atom, the id of the first ghost we found
++    // with a given atom tag if the ghost is a periodic image of another ghost;
++    // or the id of the ghost in all other cases.
++    std::vector<int> original_atom_id_;
++    // allocation cache holding the map from atom tag to atom id for local
++    // atoms.
++    std::unordered_map<tagint, int> local_atoms_tags_;
++    // allocation cache holding the map from atom tag to atom id for ghost
++    // atoms. When there are multiple periodic images of the same atom, only one
++    // will be included here.
++    std::unordered_map<tagint, int> ghost_atoms_tags_;
++
++    // TODO: should we use LAMMPS allocations/deallocation facilities for the
++    // allocation caches? If we don't, should we report memory usage from the
++    // allocations caches to LAMMPS one way or another?
++};
++
++}    // namespace LAMMPS_NS
++
++#endif
+diff --git a/src/ML-METATENSOR/metatensor_timer.cpp b/src/ML-METATENSOR/metatensor_timer.cpp
+new file mode 100644
+index 0000000000..8e269f95b6
+--- /dev/null
++++ b/src/ML-METATENSOR/metatensor_timer.cpp
+@@ -0,0 +1,63 @@
++#include <mutex>
++#include <iostream>
++
++#include "metatensor_timer.h"
++
++using namespace LAMMPS_NS;
++
++// lock to protect the other static from concurrent modification
++static std::mutex METATENSOR_TIMER_MUTEX = {};
++// depth of the timer, i.e. how many different timers are alive right now
++static int64_t METATENSOR_TIMER_DEPTH = -1;
++// strictly increasing timer counter, to know if a new one was created inside
++// the scope of the current one.
++static uint64_t METATENSOR_TIMER_COUNTER = 0;
++// Is profiling enabled?
++static bool METATENSOR_TIMER_ENABLED = false;
++
++
++void MetatensorTimer::enable(bool toggle) {
++    auto guard_ = std::lock_guard(METATENSOR_TIMER_MUTEX);
++
++    METATENSOR_TIMER_ENABLED = toggle;
++}
++
++
++MetatensorTimer::MetatensorTimer(std::string name):
++    enabled_(false),
++    name_(std::move(name))
++{
++    auto guard_ = std::lock_guard(METATENSOR_TIMER_MUTEX);
++    if (METATENSOR_TIMER_ENABLED) {
++        METATENSOR_TIMER_DEPTH += 1;
++        METATENSOR_TIMER_COUNTER += 1;
++
++        this->enabled_ = true;
++        this->starting_counter_ = METATENSOR_TIMER_COUNTER;
++        this->start_ = std::chrono::high_resolution_clock::now();
++        auto indent = std::string(METATENSOR_TIMER_DEPTH * 3, ' ');
++
++        if (METATENSOR_TIMER_DEPTH == 0) {
++            std::cerr << "\n";
++        }
++
++        std::cerr << "\n" << indent << this->name_ << " ...";
++    }
++}
++
++MetatensorTimer::~MetatensorTimer() {
++    auto guard_ = std::lock_guard(METATENSOR_TIMER_MUTEX);
++
++    if (METATENSOR_TIMER_ENABLED && this->enabled_) {
++        auto stop = std::chrono::high_resolution_clock::now();
++        auto elapsed = std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start_).count();
++
++        if (METATENSOR_TIMER_COUNTER != starting_counter_) {
++            auto indent = std::string(METATENSOR_TIMER_DEPTH * 3, ' ');
++            std::cerr << "\n" << indent << this->name_;
++        }
++
++        std::cerr << " took " << elapsed / 1e6 << "ms" << std::flush;
++        METATENSOR_TIMER_DEPTH -= 1;
++    }
++}
+diff --git a/src/ML-METATENSOR/metatensor_timer.h b/src/ML-METATENSOR/metatensor_timer.h
+new file mode 100644
+index 0000000000..2eac972bc8
+--- /dev/null
++++ b/src/ML-METATENSOR/metatensor_timer.h
+@@ -0,0 +1,42 @@
++/* -*- c++ -*- ----------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++#ifndef LMP_METATENSOR_TIMER_H
++#define LMP_METATENSOR_TIMER_H
++
++#include <chrono>
++#include <string>
++
++namespace LAMMPS_NS {
++
++/// Simple timer for profiling the LAMMPS/Metatensor integration. This starts
++/// the timer when created, and print the elapsed time to stderr when going out
++/// of scope.
++class MetatensorTimer {
++public:
++    MetatensorTimer(std::string name);
++    ~MetatensorTimer();
++
++    // enable/disable profiling
++    static void enable(bool toggle);
++
++private:
++    bool enabled_;
++    std::string name_;
++    size_t starting_counter_;
++    std::chrono::time_point<std::chrono::high_resolution_clock> start_;
++};
++
++}    // namespace LAMMPS_NS
++
++#endif
+diff --git a/src/ML-METATENSOR/metatensor_types.cpp b/src/ML-METATENSOR/metatensor_types.cpp
+new file mode 100644
+index 0000000000..3a017898a3
+--- /dev/null
++++ b/src/ML-METATENSOR/metatensor_types.cpp
+@@ -0,0 +1,97 @@
++/* ----------------------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++/* ----------------------------------------------------------------------
++   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
++------------------------------------------------------------------------- */
++#include "metatensor_types.h"
++
++#include "citeme.h"
++#include "comm.h"
++#include "error.h"
++
++using namespace LAMMPS_NS;
++
++PairMetatensorData::PairMetatensorData(std::string length_unit, std::string energy_unit):
++    device(torch::kCPU),
++    check_consistency(false),
++    remap_pairs(true),
++    max_cutoff(-1)
++{
++    auto options = torch::TensorOptions().dtype(torch::kInt32);
++    this->selected_atoms_values = torch::zeros({0, 2}, options);
++
++    // Initialize evaluation_options
++    this->evaluation_options = torch::make_intrusive<metatensor_torch::ModelEvaluationOptionsHolder>();
++    this->evaluation_options->set_length_unit(std::move(length_unit));
++
++    auto output = torch::make_intrusive<metatensor_torch::ModelOutputHolder>();
++    output->explicit_gradients = {};
++    output->set_quantity("energy");
++    output->set_unit(std::move(energy_unit));
++    output->per_atom = false;
++
++    this->evaluation_options->outputs.insert("energy", output);
++}
++
++void PairMetatensorData::load_model(
++   LAMMPS* lmp,
++   const char* path,
++   const char* extensions_directory
++) {
++   // TODO: seach for the model & extensions inside `$LAMMPS_POTENTIALS`?
++
++   if (this->model != nullptr) {
++       lmp->error->all(FLERR, "torch model is already loaded");
++   }
++
++   torch::optional<std::string> extensions = torch::nullopt;
++   if (extensions_directory != nullptr) {
++       extensions = std::string(extensions_directory);
++   }
++
++   try {
++       this->model = std::make_unique<torch::jit::Module>(
++           metatensor_torch::load_atomistic_model(path, extensions)
++       );
++   } catch (const c10::Error& e) {
++       lmp->error->all(FLERR, "failed to load metatensor model at '{}': {}", path, e.what());
++   }
++
++   auto capabilities_ivalue = this->model->run_method("capabilities");
++   this->capabilities = capabilities_ivalue.toCustomClass<metatensor_torch::ModelCapabilitiesHolder>();
++
++   if (!this->capabilities->outputs().contains("energy")) {
++       lmp->error->all(FLERR, "the model at '{}' does not have an \"energy\" output, we can not use it in pair_style metatensor", path);
++   }
++
++   if (lmp->comm->me == 0) {
++       auto metadata_ivalue = this->model->run_method("metadata");
++       auto metadata = metadata_ivalue.toCustomClass<metatensor_torch::ModelMetadataHolder>();
++       auto to_print = metadata->print();
++
++       if (lmp->screen) {
++           fprintf(lmp->screen, "\n%s\n", to_print.c_str());
++       }
++       if (lmp->logfile) {
++           fprintf(lmp->logfile,"\n%s\n", to_print.c_str());
++       }
++
++       // add the model references to LAMMPS citation handling mechanism
++       for (const auto& it: metadata->references) {
++           for (const auto& ref: it.value()) {
++               lmp->citeme->add(ref + "\n");
++           }
++       }
++   }
++}
+diff --git a/src/ML-METATENSOR/metatensor_types.h b/src/ML-METATENSOR/metatensor_types.h
+new file mode 100644
+index 0000000000..32cab47d89
+--- /dev/null
++++ b/src/ML-METATENSOR/metatensor_types.h
+@@ -0,0 +1,57 @@
++/* -*- c++ -*- ----------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++#include "lammps.h"
++
++#include <string>
++
++#include <torch/torch.h>
++#include <metatensor/torch.hpp>
++#include <metatensor/torch/atomistic.hpp>
++
++
++
++#ifndef LMP_METATENSOR_TYPES_H
++#define LMP_METATENSOR_TYPES_H
++
++namespace LAMMPS_NS {
++
++struct PairMetatensorData {
++   PairMetatensorData(std::string length_unit, std::string energy_unit);
++
++   void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
++
++   // torch model in metatensor format
++   std::unique_ptr<torch::jit::Module> model;
++   // device to use for the calculations
++   torch::Device device;
++   // model capabilities, declared by the model
++   metatensor_torch::ModelCapabilities capabilities;
++   // run-time evaluation options, decided by this class
++   metatensor_torch::ModelEvaluationOptions evaluation_options;
++   // should metatensor check the data LAMMPS send to the model
++   // and the data the model returns?
++   bool check_consistency;
++   // whether pairs should be remapped, removing pairs between ghosts if there
++   // is an equivalent pair involving at least one local atom.
++   bool remap_pairs;
++   // how far away the model needs to know about neighbors
++   double max_cutoff;
++
++   // allocation cache for the selected atoms
++   torch::Tensor selected_atoms_values;
++};
++
++}    // namespace LAMMPS_NS
++
++#endif
+diff --git a/src/ML-METATENSOR/pair_metatensor.cpp b/src/ML-METATENSOR/pair_metatensor.cpp
+new file mode 100644
+index 0000000000..d936c9579f
+--- /dev/null
++++ b/src/ML-METATENSOR/pair_metatensor.cpp
+@@ -0,0 +1,565 @@
++/* ----------------------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++
++/* ----------------------------------------------------------------------
++   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
++------------------------------------------------------------------------- */
++#include "pair_metatensor.h"
++#include "metatensor_types.h"
++
++#include "atom.h"
++#include "error.h"
++#include "force.h"
++#include "memory.h"
++#include "neighbor.h"
++#include "update.h"
++#include "comm.h"
++
++#include "neigh_list.h"
++#include "neigh_request.h"
++
++#include <torch/version.h>
++#include <torch/script.h>
++#include <torch/cuda.h>
++
++#if TORCH_VERSION_MAJOR >= 2
++    #include <torch/mps.h>
++#endif
++
++#include <memory>
++
++#include <metatensor/torch.hpp>
++#include <metatensor/torch/atomistic.hpp>
++
++#include "metatensor_system.h"
++
++#include "./metatensor_timer.h"
++
++using namespace LAMMPS_NS;
++
++PairMetatensor::PairMetatensor(LAMMPS *lmp):
++    Pair(lmp),
++    type_mapping(nullptr),
++    system_adaptor(nullptr)
++{
++    std::string energy_unit;
++    std::string length_unit;
++    if (strcmp(update->unit_style, "real") == 0) {
++        length_unit = "angstrom";
++        energy_unit = "kcal/mol";
++    } else if (strcmp(update->unit_style, "metal") == 0) {
++        length_unit = "angstrom";
++        energy_unit = "eV";
++    } else if (strcmp(update->unit_style, "si") == 0) {
++        length_unit = "meter";
++        energy_unit = "joule";
++    } else if (strcmp(update->unit_style, "electron") == 0) {
++        length_unit = "Bohr";
++        energy_unit = "Hartree";
++    } else {
++        error->all(FLERR, "unsupported units '{}' for pair metatensor ", update->unit_style);
++    }
++
++    // we might not be running a pure pair potential,
++    // so we can not compute virial as fdotr
++    this->no_virial_fdotr_compute = 1;
++
++    this->mts_data = new PairMetatensorData(std::move(length_unit), std::move(energy_unit));
++
++    // settings for metatensor pair style
++    this->single_enable = 0;
++    this->restartinfo = 0;
++    this->one_coeff = 1;
++    this->manybody_flag = 1;
++}
++
++PairMetatensor::~PairMetatensor() {
++    delete this->mts_data;
++
++    if (allocated) {
++        memory->destroy(setflag);
++        memory->destroy(cutsq);
++        memory->destroy(type_mapping);
++    }
++}
++
++// called when finding `pair_style metatensor` in the input
++void PairMetatensor::settings(int argc, char ** argv) {
++    if (argc == 0) {
++        error->all(FLERR, "expected at least 1 argument to pair_style metatensor, got {}", argc);
++    }
++
++    const char* model_path = argv[0];
++    const char* extensions_directory = nullptr;
++    const char* requested_device = nullptr;
++    for (int i=1; i<argc; i++) {
++        if (strcmp(argv[i], "check_consistency") == 0) {
++            if (i == argc - 1) {
++                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatensor, got nothing");
++            } else if (strcmp(argv[i + 1], "on") == 0) {
++                mts_data->check_consistency = true;
++            } else if (strcmp(argv[i + 1], "off") == 0) {
++                mts_data->check_consistency = false;
++            } else {
++                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatensor, got '{}'", argv[i + 1]);
++            }
++
++            i += 1;
++        } else if (strcmp(argv[i], "remap_pairs") == 0) {
++            if (i == argc - 1) {
++                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatensor, got nothing");
++            } else if (strcmp(argv[i + 1], "on") == 0) {
++                mts_data->remap_pairs = true;
++            } else if (strcmp(argv[i + 1], "off") == 0) {
++                mts_data->remap_pairs = false;
++            } else {
++                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatensor, got '{}'", argv[i + 1]);
++            }
++
++            i += 1;
++        } else if (strcmp(argv[i], "extensions") == 0) {
++            if (i == argc - 1) {
++                error->all(FLERR, "expected <path> after 'extensions' in pair_style metatensor, got nothing");
++            }
++            extensions_directory = argv[i + 1];
++            i += 1;
++        } else if (strcmp(argv[i], "device") == 0) {
++            if (i == argc - 1) {
++                error->all(FLERR, "expected string after 'device' in pair_style metatensor, got nothing");
++            }
++            requested_device = argv[i + 1];
++            i += 1;
++        } else {
++            error->all(FLERR, "unexpected argument to pair_style metatensor: '{}'", argv[i]);
++        }
++    }
++
++    // load the model and get it's capabilities (including supported devices)
++    mts_data->load_model(this->lmp, model_path, extensions_directory);
++
++    // Select the device to use based on the model's preference, the user choice
++    // and what's available.
++    this->pick_device(&mts_data->device, requested_device);
++
++    // move all data to the correct device
++    mts_data->model->to(mts_data->device);
++    mts_data->selected_atoms_values = mts_data->selected_atoms_values.to(mts_data->device);
++
++    auto message = "Running simulation on " + mts_data->device.str() + " device with " + mts_data->capabilities->dtype() + " data";
++    if (screen) {
++        fprintf(screen, "%s\n", message.c_str());
++    }
++    if (logfile) {
++        fprintf(logfile,"%s\n", message.c_str());
++    }
++
++    if (!allocated) {
++        allocate();
++    }
++}
++
++std::vector<torch::DeviceType> PairMetatensor::available_devices() {
++    auto devices = std::vector<torch::DeviceType>();
++    for (const auto& supported: this->mts_data->capabilities->supported_devices) {
++        if (supported == "cpu") {
++            devices.push_back(torch::kCPU);
++        } else if (supported == "cuda" && torch::cuda::is_available()) {
++            devices.push_back(torch::kCUDA);
++        } else if (supported == "mps") {
++            #if TORCH_VERSION_MAJOR >= 2
++            if (torch::mps::is_available()) {
++                devices.push_back(torch::kMPS);
++            }
++            #endif
++        } else {
++            error->warning(FLERR,
++                "the model declared support for unknown device '{}', it will be ignored", supported
++            );
++        }
++    }
++
++    if (devices.empty()) {
++        error->all(FLERR,
++            "failed to find a valid device for this model: "
++            "the model supports {}, none of these where available",
++            torch::str(this->mts_data->capabilities->supported_devices)
++        );
++    }
++
++    return devices;
++}
++
++void PairMetatensor::pick_device(torch::Device* device, const char* requested) {
++    auto available_devices = this->available_devices();
++
++    auto picked_device_type = torch::kCPU;
++    if (requested == nullptr) {
++        // no user request, pick the device the model prefers
++        picked_device_type = available_devices[0];
++    } else {
++        bool found_requested_device = false;
++        for (const auto& device_type: available_devices) {
++            if (device_type == torch::kCPU && strcmp(requested, "cpu") == 0) {
++                picked_device_type = device_type;
++                found_requested_device = true;
++                break;
++            } else if (device_type == torch::kCUDA && strcmp(requested, "cuda") == 0) {
++                picked_device_type = device_type;
++                found_requested_device = true;
++                break;
++            } else if (device_type == torch::kMPS && strcmp(requested, "mps") == 0) {
++                picked_device_type = device_type;
++                found_requested_device = true;
++                break;
++            }
++        }
++
++        if (!found_requested_device) {
++            error->all(FLERR,
++                "failed to find requested device ({}): it is either "
++                "not supported by this model or not available on this machine",
++                requested
++            );
++        }
++    }
++
++    if (picked_device_type == torch::kCUDA) {
++        // distribute GPUs between multiple MPI processes on the same node
++
++        // (1) get a MPI communicator for all processes on the current node
++        MPI_Comm local;
++        MPI_Comm_split_type(world, MPI_COMM_TYPE_SHARED, 0, MPI_INFO_NULL, &local);
++        // (2) get the rank of this MPI process on the current node
++        int local_rank;
++        MPI_Comm_rank(local, &local_rank);
++
++        int size;
++        MPI_Comm_size(local, &size);
++        if (size < torch::cuda::device_count()) {
++            if (comm->me == 0) {
++                error->warning(FLERR,
++                    "found {} CUDA-capable GPUs, but only {} MPI processes on the current node; the remaining GPUs will not be used",
++                    torch::cuda::device_count(), size
++                );
++            }
++        }
++
++        // (3) split GPUs between node-local processes using round-robin allocation
++        int gpu_to_use = local_rank % torch::cuda::device_count();
++        *device = torch::Device(picked_device_type, gpu_to_use);
++    } else {
++        *device = torch::Device(picked_device_type);
++    }
++}
++
++
++void PairMetatensor::allocate() {
++    allocated = 1;
++
++    // setflags stores whether the coeff for a given pair of atom types are known
++    setflag = memory->create(
++        setflag,
++        atom->ntypes + 1,
++        atom->ntypes + 1,
++        "pair:setflag"
++    );
++
++    for (int i = 1; i <= atom->ntypes; i++) {
++        for (int j = i; j <= atom->ntypes; j++) {
++            setflag[i][j] = 0;
++        }
++    }
++
++    // cutsq stores the squared cutoff for each pair
++    cutsq = memory->create(
++        cutsq,
++        atom->ntypes + 1,
++        atom->ntypes + 1,
++        "pair:cutsq"
++    );
++
++    // lammps_types_to_species stores the mapping from lammps atom types to
++    // the metatensor model species
++    type_mapping = memory->create(
++        type_mapping,
++        atom->ntypes + 1,
++        "PairMetatensor:type_mapping"
++    );
++
++    for (int i = 1; i <= atom->ntypes; i++) {
++        type_mapping[i] = -1;
++    }
++}
++
++double PairMetatensor::init_one(int, int) {
++    return mts_data->max_cutoff;
++}
++
++
++// called on pair_coeff
++void PairMetatensor::coeff(int argc, char ** argv) {
++    if (argc < 3 || strcmp(argv[0], "*") != 0 || strcmp(argv[1], "*") != 0) {
++        error->all(FLERR, "invalid pair_coeff, expected `pair_coeff * * <list of types>`");
++    }
++
++    if (atom->ntypes != argc - 2) {
++        error->all(FLERR,
++            "invalid pair_coeff, expected `pair_coeff * * <list of types>` with {} types",
++            atom->ntypes
++        );
++    }
++
++    for (int lammps_type=1; lammps_type<argc - 1; lammps_type++) {
++        int type = utils::inumeric(FLERR, argv[lammps_type + 1], true, lmp);
++        type_mapping[lammps_type] = type;
++    }
++
++    // mark all pairs coeffs as known
++    for (int i = 1; i <= atom->ntypes; i++) {
++        for (int j = 1; j <= atom->ntypes; j++) {
++            setflag[i][j] = 1;
++            setflag[j][i] = 1;
++        }
++    }
++}
++
++
++// called when the run starts
++void PairMetatensor::init_style() {
++    // Require newton pair on since we need to communicate forces accumulated on
++    // ghost atoms to neighboring domains. These forces contributions come from
++    // gradient of a local descriptor w.r.t. domain ghosts (periodic images
++    // ghosts are handled separately).
++    if (force->newton_pair != 1) {
++        error->all(FLERR, "Pair style metatensor requires newton pair on");
++    }
++
++    // get the model's interaction range
++    auto range = mts_data->capabilities->engine_interaction_range(mts_data->evaluation_options->length_unit());
++    if (range < 0) {
++        error->all(FLERR, "interaction_range is negative for this model");
++    } else if (!std::isfinite(range)) {
++        if (comm->nprocs > 1) {
++            error->all(FLERR,
++                "interaction_range is infinite for this model, "
++                "using multiple MPI domains is not supported"
++            );
++        }
++
++        // determine the maximal cutoff in the NL
++        auto requested_nl = mts_data->model->run_method("requested_neighbor_lists");
++        for (const auto& ivalue: requested_nl.toList()) {
++            auto options = ivalue.get().toCustomClass<metatensor_torch::NeighborListOptionsHolder>();
++            auto cutoff = options->engine_cutoff(mts_data->evaluation_options->length_unit());
++
++            mts_data->max_cutoff = std::max(mts_data->max_cutoff, cutoff);
++        }
++    } else {
++        mts_data->max_cutoff = range;
++    }
++
++    if (!std::isfinite(mts_data->max_cutoff)) {
++        error->all(FLERR,
++            "the largest cutoff of this model is infinite, "
++            "we can't compute the corresponding neighbor list"
++        );
++    }
++
++    // create system adaptor
++    auto options = MetatensorSystemOptions{
++        this->type_mapping,
++        mts_data->max_cutoff,
++        mts_data->check_consistency,
++    };
++    this->system_adaptor = std::make_unique<MetatensorSystemAdaptor>(lmp, options);
++
++    // We ask LAMMPS for a full neighbor lists because we need to know about
++    // ALL pairs, even if options->full_list() is false. We will then filter
++    // the pairs to only include each pair once where needed.
++    auto request = neighbor->add_request(this, NeighConst::REQ_FULL | NeighConst::REQ_GHOST);
++    request->set_cutoff(mts_data->max_cutoff);
++
++    // Translate from the metatensor neighbor lists requests to LAMMPS neighbor
++    // lists requests.
++    auto requested_nl = mts_data->model->run_method("requested_neighbor_lists");
++    for (const auto& ivalue: requested_nl.toList()) {
++        auto options = ivalue.get().toCustomClass<metatensor_torch::NeighborListOptionsHolder>();
++        auto cutoff = options->engine_cutoff(mts_data->evaluation_options->length_unit());
++        assert(cutoff <= mts_data->max_cutoff);
++
++        this->system_adaptor->add_nl_request(cutoff, options);
++    }
++}
++
++
++void PairMetatensor::init_list(int id, NeighList *ptr) {
++    mts_list = ptr;
++}
++
++
++void PairMetatensor::compute(int eflag, int vflag) {
++    if (std::getenv("LAMMPS_METATENSOR_PROFILE") != nullptr) {
++        MetatensorTimer::enable(true);
++    } else {
++        MetatensorTimer::enable(false);
++    }
++
++    auto _ = MetatensorTimer("PairMetatensor::compute");
++
++    if (eflag || vflag) {
++        ev_setup(eflag, vflag);
++    } else {
++        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
++    }
++
++    if (eflag_atom) {
++        mts_data->evaluation_options->outputs.at("energy")->per_atom = true;
++    } else {
++        mts_data->evaluation_options->outputs.at("energy")->per_atom = false;
++    }
++
++    auto dtype = torch::kFloat64;
++    if (mts_data->capabilities->dtype() == "float64") {
++        dtype = torch::kFloat64;
++    } else if (mts_data->capabilities->dtype() == "float32") {
++        dtype = torch::kFloat32;
++    } else {
++        error->all(FLERR, "the model requested an unsupported dtype '{}'", mts_data->capabilities->dtype());
++    }
++
++    // transform from LAMMPS to metatensor System
++    auto system = this->system_adaptor->system_from_lmp(
++        mts_list,
++        static_cast<bool>(vflag_global),
++        mts_data->remap_pairs,
++        dtype,
++        mts_data->device
++    );
++
++    // only run the calculation for atoms actually in the current domain
++    mts_data->selected_atoms_values.resize_({atom->nlocal, 2});
++    mts_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
++    auto options = mts_data->selected_atoms_values.options();
++    mts_data->selected_atoms_values.index_put_(
++        {torch::indexing::Slice(), 1},
++        torch::arange(atom->nlocal, options)
++    );
++
++    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
++        std::vector<std::string>{"system", "atom"}, mts_data->selected_atoms_values
++    );
++    mts_data->evaluation_options->set_selected_atoms(selected_atoms);
++
++    torch::IValue result_ivalue;
++    try {
++        auto _ = MetatensorTimer("running Model::forward");
++        result_ivalue = mts_data->model->forward({
++            std::vector<metatensor_torch::System>{system},
++            mts_data->evaluation_options,
++            mts_data->check_consistency
++        });
++    } catch (const std::exception& e) {
++        error->all(FLERR, "error evaluating the torch model: {}", e.what());
++    }
++
++    auto result = result_ivalue.toGenericDict();
++    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
++    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
++    auto energy_tensor = energy_block->values();
++
++    // compute forces/virial on device with backward propagation
++    {
++        // reset gradients to zero before calling backward
++        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
++        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
++
++        auto _ = MetatensorTimer("running Model::backward");
++        energy_tensor.backward(-torch::ones_like(energy_tensor));
++    }
++
++    {
++        auto _ = MetatensorTimer("storing model output in LAMMPS data structures");
++
++        // move results to cpu for storing
++        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
++        auto energy_samples = energy_block->samples();
++
++        // store the energy returned by the model
++        torch::Tensor global_energy;
++        if (eflag_atom) {
++            assert(energy_samples->size() == 2);
++            assert(energy_samples->names()[0] == "system");
++            assert(energy_samples->names()[1] == "atom");
++
++            auto samples_values = energy_samples->values().to(torch::kCPU);
++            auto samples = samples_values.accessor<int32_t, 2>();
++
++            int64_t n_atoms = atom->nlocal + atom->nghost;
++            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
++
++            auto energies = energy_detached.accessor<double, 2>();
++            for (int64_t i=0; i<energy_samples->count(); i++) {
++                assert(samples[i][0] == 0);
++                // handle potentially out of order samples in
++                // the per-atom energy tensor
++                auto atom_i = samples[i][1];
++                assert(atom_i < n_atoms);
++                eatom[atom_i] += energies[i][0];
++            }
++
++            global_energy = energy_detached.sum(0);
++            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
++        } else {
++            assert(energy_samples->size() == 1);
++            assert(energy_samples->names()[0] == "system");
++
++            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
++            global_energy = energy_detached.reshape({1});
++        }
++
++        if (eflag_global) {
++            eng_vdwl += global_energy.item<double>();
++        }
++
++        // store forces/virial
++        auto forces_tensor = this->system_adaptor->positions.grad();
++        assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
++
++        auto forces = forces_tensor.accessor<double, 2>();
++        for (int i=0; i<atom->nlocal + atom->nghost; i++) {
++            atom->f[i][0] += forces[i][0];
++            atom->f[i][1] += forces[i][1];
++            atom->f[i][2] += forces[i][2];
++        }
++
++        assert(!vflag_fdotr);
++
++        if (vflag_global) {
++            auto virial_tensor = this->system_adaptor->strain.grad();
++            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
++            auto predicted_virial = virial_tensor.accessor<double, 2>();
++
++            virial[0] += predicted_virial[0][0];
++            virial[1] += predicted_virial[1][1];
++            virial[2] += predicted_virial[2][2];
++
++            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
++            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
++            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
++        }
++
++        if (vflag_atom) {
++            error->all(FLERR, "per atom virial is not implemented");
++        }
++    }
++}
+diff --git a/src/ML-METATENSOR/pair_metatensor.h b/src/ML-METATENSOR/pair_metatensor.h
+new file mode 100644
+index 0000000000..9f7d1155d0
+--- /dev/null
++++ b/src/ML-METATENSOR/pair_metatensor.h
+@@ -0,0 +1,72 @@
++/* -*- c++ -*- ----------------------------------------------------------
++   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
++   https://www.lammps.org/, Sandia National Laboratories
++   LAMMPS Development team: developers@lammps.org
++
++   Copyright (2003) Sandia Corporation.  Under the terms of Contract
++   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
++   certain rights in this software.  This software is distributed under
++   the GNU General Public License.
++
++   See the README file in the top-level LAMMPS directory.
++------------------------------------------------------------------------- */
++#ifdef PAIR_CLASS
++// clang-format off
++PairStyle(metatensor, PairMetatensor);
++// clang-format on
++#else
++
++#ifndef LMP_PAIR_METATENSOR_H
++#define LMP_PAIR_METATENSOR_H
++
++#include "pair.h"
++
++#include <vector>
++
++// this is the actual namespace where `torch::Device` is defined
++namespace c10 {
++    class Device;
++
++    enum class DeviceType: int8_t;
++}
++
++namespace LAMMPS_NS {
++class MetatensorSystemAdaptor;
++struct PairMetatensorData;
++
++class PairMetatensor : public Pair {
++public:
++    PairMetatensor(class LAMMPS *);
++    ~PairMetatensor();
++
++    void compute(int, int) override;
++    void settings(int, char **) override;
++    void coeff(int, char **) override;
++    void init_style() override;
++    double init_one(int, int) override;
++    void init_list(int id, NeighList *ptr) override;
++
++    void allocate();
++
++protected:
++    // get the set of devices both available on the current machine and supported
++    // by the model
++    std::vector<c10::DeviceType> available_devices();
++
++    // pick the correct device to use from the user request (or nullptr) in
++    // `pair_style metatensor`
++    virtual void pick_device(c10::Device* device, const char* requested);
++
++    PairMetatensorData* mts_data;
++    NeighList *mts_list;
++
++    // mapping from LAMMPS types to metatensor types
++    int32_t *type_mapping;
++    // adaptor from LAMMPS system to metatensor's
++    std::unique_ptr<MetatensorSystemAdaptor> system_adaptor;
++};
++
++}    // namespace LAMMPS_NS
++
++#endif
++#endif
+diff --git a/src/ML-METATENSOR/patch-torch.sh b/src/ML-METATENSOR/patch-torch.sh
+new file mode 100755
+index 0000000000..8ec7cafac0
+--- /dev/null
++++ b/src/ML-METATENSOR/patch-torch.sh
+@@ -0,0 +1,45 @@
++#!/usr/bin/env bash
++
++# This pulls in the fix from https://github.com/pytorch/pytorch/pull/119945
++# until it is properly released
++
++set -eu
++
++TORCH_PREFIX=$1
++
++if [ -f "$TORCH_PREFIX/share/cmake/Caffe2/public/mkl.cmake" ]; then
++    MKL_CMAKE="$TORCH_PREFIX/share/cmake/Caffe2/public/mkl.cmake"
++elif [ -f "$TORCH_PREFIX/Caffe2/public/mkl.cmake" ]; then
++    MKL_CMAKE="$TORCH_PREFIX/Caffe2/public/mkl.cmake"
++else
++    echo "Failed to find mkl.cmake in '$TORCH_PREFIX'"
++    exit 1
++fi
++
++cat > "$MKL_CMAKE" << EOF
++
++find_package(MKL QUIET)
++
++if(TARGET caffe2::mkl)
++  return()
++endif()
++
++add_library(caffe2::mkl INTERFACE IMPORTED)
++target_include_directories(caffe2::mkl INTERFACE \${MKL_INCLUDE_DIR})
++target_link_libraries(caffe2::mkl INTERFACE \${MKL_LIBRARIES})
++foreach(MKL_LIB IN LISTS MKL_LIBRARIES)
++  if(EXISTS "\${MKL_LIB}")
++    get_filename_component(MKL_LINK_DIR "\${MKL_LIB}" DIRECTORY)
++    if(IS_DIRECTORY "\${MKL_LINK_DIR}")
++      target_link_directories(caffe2::mkl INTERFACE "\${MKL_LINK_DIR}")
++    endif()
++  endif()
++endforeach()
++
++# TODO: This is a hack, it will not pick up architecture dependent
++# MKL libraries correctly; see https://github.com/pytorch/pytorch/issues/73008
++set_property(
++  TARGET caffe2::mkl PROPERTY INTERFACE_LINK_DIRECTORIES
++  \${MKL_ROOT}/lib \${MKL_ROOT}/lib/intel64 \${MKL_ROOT}/lib/intel64_win \${MKL_ROOT}/lib/win-x64)
++
++EOF
+diff --git a/src/Makefile b/src/Makefile
+index 866c778aeb..42c4c80979 100644
+--- a/src/Makefile
++++ b/src/Makefile
+@@ -103,6 +103,7 @@ PACKAGE = \
+ 	ml-pace \
+ 	ml-pod \
+ 	ml-quip \
++	ml-metatensor \
+ 	ml-rann \
+ 	ml-snap \
+ 	ml-uf3 \
+@@ -234,6 +235,7 @@ PACKLIB = \
+ 	plumed \
+ 	qmmm \
+ 	ml-quip \
++	ml-metatensor \
+ 	rheo \
+ 	scafacos \
+ 	machdyn \
+@@ -252,6 +254,7 @@ PACKEXT = \
+ 	ml-hdnnp \
+ 	ml-pace \
+ 	ml-quip \
++	ml-metatensor \
+ 	molfile \
+ 	netcdf \
+ 	plumed \
+diff --git a/src/STUBS/mpi.cpp b/src/STUBS/mpi.cpp
+index 22cbc9af17..e431837f34 100644
+--- a/src/STUBS/mpi.cpp
++++ b/src/STUBS/mpi.cpp
+@@ -378,6 +378,13 @@ int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *comm_out)
+
+ /* ---------------------------------------------------------------------- */
+
++int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *comm_out) {
++  *comm_out = comm + 1;
++  return 0;
++}
++
++/* ---------------------------------------------------------------------- */
++
+ int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *comm_out)
+ {
+   *comm_out = comm + 1;
+diff --git a/src/STUBS/mpi.h b/src/STUBS/mpi.h
+index b89c098bad..e65199f6e9 100644
+--- a/src/STUBS/mpi.h
++++ b/src/STUBS/mpi.h
+@@ -58,6 +58,7 @@
+ #define MPI_STATUS_IGNORE NULL
+
+ #define MPI_Comm int
++#define MPI_Info int
+ #define MPI_Request int
+ #define MPI_Datatype int
+ #define MPI_Op int
+@@ -65,6 +66,11 @@
+ #define MPI_Group int
+ #define MPI_Offset long
+
++#define MPI_INFO_NULL 0
++
++// TODO: should all the COMM_TYPE be defined here?
++#define MPI_COMM_TYPE_SHARED 0xABCDEF01
++
+ #define MPI_IN_PLACE NULL
+
+ #define MPI_MAX_PROCESSOR_NAME 128
+@@ -115,6 +121,7 @@ int MPI_Sendrecv(const void *sbuf, int scount, MPI_Datatype sdatatype, int dest,
+ int MPI_Get_count(MPI_Status *status, MPI_Datatype datatype, int *count);
+
+ int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *comm_out);
++int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *comm_out);
+ int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *comm_out);
+ int MPI_Comm_free(MPI_Comm *comm);
+ MPI_Fint MPI_Comm_c2f(MPI_Comm comm);
diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
new file mode 100644
index 00000000000..2eb8b6ca5fb
--- /dev/null
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -0,0 +1,392 @@
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
+                         Filippo Bigi <filippo.bigi@epfl.ch>
+------------------------------------------------------------------------- */
+#include "metatomic_system_kokkos.h"
+
+#include "metatomic_timer.h"
+
+#include "domain.h"
+#include "error.h"
+
+#include "atom_kokkos.h"
+
+#include <torch/cuda.h>
+
+using namespace LAMMPS_NS;
+
+template<typename T, class DeviceType>
+using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
+
+template<class DeviceType>
+MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *lmp, MetatomicSystemOptions options):
+    MetatomicSystemAdaptor(lmp, options),
+    device_(KokkosDeviceToTorch<DeviceType>::convert())
+{
+    // MetatomicSystemAdaptor allocate on CPU, move to the right device
+    this->atomic_types_ = this->atomic_types_.to(this->device_);
+
+    auto tensor_options = torch::TensorOptions()
+        .dtype(torch::kFloat64)
+        .device(this->device_)
+        .requires_grad(true);
+
+    this->strain = torch::eye(3, tensor_options);
+}
+
+template<class DeviceType>
+void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list) {
+    auto _ = MetatomicTimer("converting kokkos neighbors with ghosts remapping");
+    auto dtype = system->positions().scalar_type();
+
+    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
+
+    {
+        auto _ = MetatomicTimer("identifying ghosts and real atoms");
+        /*-------------- this will be done on CPU for now ------------------------*/
+        // The hashmap in the following code is not easy to implement in either Kokkos or torch
+        // The cost of this section seems to be very low anyway
+
+        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
+        // atoms which are periodic images of local atoms back to the local atoms.
+        //
+        // Metatomic expects pairs corresponding to periodic atoms to be between
+        // the main atoms, but using the actual distance vector between the atom and
+        // the ghost.
+        original_atom_id_.clear();
+        original_atom_id_.reserve(total_n_atoms);
+
+        // identify all local atom by their LAMMPS atom tag.
+        local_atoms_tags_.clear();
+        for (int i=0; i<atom->nlocal; i++) {
+            original_atom_id_.emplace_back(i);
+            local_atoms_tags_.emplace(atom->tag[i], i);
+        }
+
+        // now loop over ghosts & map them back to the main cell if needed
+        ghost_atoms_tags_.clear();
+        for (int i=atom->nlocal; i<total_n_atoms; i++) {
+            auto tag = atom->tag[i];
+            auto it = local_atoms_tags_.find(tag);
+            if (it != local_atoms_tags_.end()) {
+                // this is the periodic image of an atom already owned by this domain
+                original_atom_id_.emplace_back(it->second);
+            } else {
+                // this can either be a periodic image of an atom owned by another
+                // domain, or directly an atom from another domain. Since we can not
+                // really distinguish between these, we take the first atom as the
+                // "main" one and remap all atoms with the same tag to the first one
+                auto it = ghost_atoms_tags_.find(tag);
+                if (it != ghost_atoms_tags_.end()) {
+                    // we already found this atom elsewhere in the system
+                    original_atom_id_.emplace_back(it->second);
+                } else {
+                    // this is the first time we are seeing this atom
+                    original_atom_id_.emplace_back(i);
+                    ghost_atoms_tags_.emplace(tag, i);
+                }
+            }
+        }
+    }
+    /*----------- end of "this will be done on CPU for now" --------------*/
+
+    auto original_id = torch::from_blob(
+        original_atom_id_.data(),
+        {total_n_atoms},
+        torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
+    ).to(this->device_);
+
+    auto neighbors_kk = list->d_neighbors_transpose;
+    auto max_number_of_neighbors = list->maxneighs;
+
+    auto neighbors = torch::zeros(
+        {total_n_atoms, max_number_of_neighbors},
+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    );
+    // mask neighbors_kk with NEIGHMASK. Torch doesn't have this functionality, we do it in Kokkos
+    auto neighbors_kk_masked = UnmanagedView<int32_t**, DeviceType>(
+        neighbors.template data_ptr<int32_t>(),
+        total_n_atoms,
+        max_number_of_neighbors
+    );
+    Kokkos::parallel_for(
+        Kokkos::MDRangePolicy({0, 0}, {total_n_atoms, max_number_of_neighbors}),
+        KOKKOS_LAMBDA(size_t i, size_t j) {
+            neighbors_kk_masked(i, j) = neighbors_kk(i, j) & NEIGHMASK;
+        }
+    );
+
+    // Convert NL-related data to torch tensors
+    auto numneigh = torch::from_blob(
+        list->d_numneigh.data(),
+        {total_n_atoms},
+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    );
+    auto ilist = torch::from_blob(
+        list->d_ilist.data(),
+        {total_n_atoms},
+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    );
+
+    auto x = system->positions().detach();
+    auto cell_inverse = system->cell().detach().inverse();
+
+    // convert from LAMMPS NL format to metatensor NL format
+    auto expanded_arange = torch::arange(
+        max_number_of_neighbors,
+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    ).unsqueeze(0).expand({total_n_atoms, -1});
+    auto neighbor_2d_mask = expanded_arange < numneigh.unsqueeze(1);
+
+    auto expanded_arange_other_dim = torch::arange(
+        total_n_atoms,
+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    ).unsqueeze(1).expand({-1, max_number_of_neighbors});
+    auto index_for_ilist = expanded_arange_other_dim.masked_select(neighbor_2d_mask);
+
+    auto centers_id = ilist.index_select(0, index_for_ilist);
+    auto neighbors_id = neighbors.masked_select(neighbor_2d_mask);
+
+    // change centers and neighbors to the original atom ids
+    auto centers_original_id = original_id.index_select(0, centers_id);
+    auto neighbors_original_id = original_id.index_select(0, neighbors_id);
+
+    // The following code is a direct translation of the code in the non-Kokkos
+    // version (MetaTensorSystemAdaptor::setup_neighbors_remap), but rewritten
+    // in torch to use the GPU
+    for (auto& cache: caches_) {
+        // current values of various tensors, these change depending on full/half setting
+        torch::Tensor centers_id_cur;
+        torch::Tensor neighbors_id_cur;
+        torch::Tensor centers_original_id_cur;
+        torch::Tensor neighbors_original_id_cur;
+
+        // filtered tensors, i.e. only containing pairs actually below the cutoff
+        torch::Tensor centers_original_id_filt_cur;
+        torch::Tensor neighbors_original_id_filt_cur;
+        torch::Tensor distances_filt_cur;
+        torch::Tensor cell_shifts_cur;
+
+        // other tensors that need to live across multiple timed sections
+        torch::Tensor samples_indices;
+        torch::Tensor samples_values;
+        {
+            auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
+            // half list mask, if necessary
+            auto full_list = cache.options->full_list();
+
+            if (full_list) {
+                centers_id_cur = centers_id;
+                neighbors_id_cur = neighbors_id;
+                centers_original_id_cur = centers_original_id;
+                neighbors_original_id_cur = neighbors_original_id;
+            } else {
+                auto half_list_mask = centers_original_id <= neighbors_original_id;
+                centers_id_cur = centers_id.masked_select(half_list_mask);
+                neighbors_id_cur = neighbors_id.masked_select(half_list_mask);
+                centers_original_id_cur = centers_original_id.masked_select(half_list_mask);
+                neighbors_original_id_cur = neighbors_original_id.masked_select(half_list_mask);
+            }
+
+            // distance mask
+            auto distances = x.index_select(0, neighbors_id_cur) - x.index_select(0, centers_id_cur);
+            auto cutoff_mask = torch::sum(distances.pow(2), 1) < cache.cutoff*cache.cutoff;
+
+            // index everything with the mask
+            auto centers_original_id_filt = centers_original_id_cur.masked_select(cutoff_mask);
+            auto neighbors_original_id_filt = neighbors_original_id_cur.masked_select(cutoff_mask);
+            auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
+
+            // find filtered interatomic vectors using the original atoms
+            auto original_distances_filtered =
+                x.index_select(0, neighbors_original_id_filt)
+                - x.index_select(0, centers_original_id_filt);
+
+            // cell shifts
+            auto pair_shifts = distances_filt - original_distances_filtered;
+            auto cell_shifts = pair_shifts.matmul(cell_inverse);
+            cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
+
+            if (full_list) {
+                centers_original_id_filt_cur = centers_original_id_filt;
+                neighbors_original_id_filt_cur = neighbors_original_id_filt;
+                distances_filt_cur = distances_filt;
+                cell_shifts_cur = cell_shifts;
+            } else {
+                auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
+                auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
+                auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
+                // reproduce this mask (from MetaTensorSystemAdaptor::setup_neighbors_remap) with torch:
+                // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
+                auto edge_mask = (
+                    (torch::sum(cell_shifts, 1) == 0) & (
+                        (cell_shifts.index({torch::indexing::Slice(), 2}) < 0) | (
+                            cell_shifts.index({torch::indexing::Slice(), 2}) == 0 &
+                            cell_shifts.index({torch::indexing::Slice(), 1}) < 0
+                        )
+                    )
+                );
+                auto final_mask = torch::logical_not(
+                    half_list_cell_mask | (
+                        pair_with_image_mask & (negative_half_space_mask | edge_mask)
+                    )
+                );
+                centers_original_id_filt_cur = centers_original_id_filt.masked_select(final_mask);
+                neighbors_original_id_filt_cur = neighbors_original_id_filt.masked_select(final_mask);
+                distances_filt_cur = distances_filt.index({final_mask, torch::indexing::Slice()});
+                cell_shifts_cur = cell_shifts.index({final_mask, torch::indexing::Slice()});
+            }
+
+            // make sure all the sample are unique
+            samples_values = torch::concatenate({
+                centers_original_id_filt_cur.unsqueeze(-1),
+                neighbors_original_id_filt_cur.unsqueeze(-1),
+                cell_shifts_cur
+            }, /*dim=*/1);
+
+            auto [samples_values_unique, samples_inverse, _counts] = torch::unique_dim(
+                samples_values, /*dim=*/0, /*sorted=*/true, /*return_inverse=*/true, /*return_counts=*/false
+            );
+            samples_values = samples_values_unique;
+
+            auto permutation = torch::arange(samples_inverse.size(0), samples_inverse.options());
+            samples_inverse = samples_inverse.flip({0});
+            permutation = permutation.flip({0});
+
+            samples_indices = torch::empty(samples_values.size(0), samples_inverse.options());
+            samples_indices.scatter_(0, samples_inverse, permutation);
+        }
+
+        // wrap into metatensor data structures
+        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
+        {
+            auto n_pairs = samples_values.size(0);
+            auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
+            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                samples_values
+            );
+        }
+
+        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
+        {
+            auto _ = MetatomicTimer("creating neighbors TensorBlock");
+
+            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+                distances_filt_cur.index_select(0, samples_indices).unsqueeze(-1),
+                samples,
+                std::vector<metatensor_torch::TorchLabels>{
+                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(this->device_),
+                },
+                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(this->device_)
+            );
+        }
+
+        metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
+        system->add_neighbor_list(cache.options, neighbors);
+    }
+}
+
+
+template<class DeviceType>
+metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lmp(
+    NeighList* list,
+    bool do_virial,
+    bool remap_pairs,
+    torch::ScalarType dtype,
+    torch::Device device
+) {
+    auto _ = MetatomicTimer("creating System from LAMMPS-kokkos data");
+    assert(device == this->device_);
+
+    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
+
+    atomic_types_.resize_({total_n_atoms});
+    auto atomic_types_kk = UnmanagedView<int32_t*, DeviceType>(atomic_types_.data_ptr<int32_t>(), total_n_atoms);
+    auto type_mapping_kk = UnmanagedView<int32_t*, DeviceType>(options_.types_mapping, atomKK->ntypes + 1);
+    auto types_kk = atomKK->k_type.view<DeviceType>();
+    Kokkos::parallel_for(total_n_atoms, KOKKOS_LAMBDA(int i) {
+        atomic_types_kk(i) = type_mapping_kk(types_kk(i));
+    });
+
+    // atomKK->k_x contains "real" and then ghost atoms, in that order
+    auto k_x = atomKK->k_x.view<DeviceType>();
+    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
+
+    this->positions = torch::from_blob(
+        k_x.data(), {total_n_atoms, 3},
+        // requires_grad=true since we always need gradients w.r.t. positions
+        tensor_options.requires_grad(true)
+    );
+
+    auto cell = torch::zeros({3, 3}, tensor_options);
+    cell[0][0] = domain->xprd;
+
+    cell[1][0] = domain->xy;
+    cell[1][1] = domain->yprd;
+
+    cell[2][0] = domain->xz;
+    cell[2][1] = domain->yz;
+    cell[2][2] = domain->zprd;
+
+    auto system_positions = this->positions.to(dtype);
+    cell = cell.to(dtype);
+
+    if (do_virial) {
+        auto model_strain = this->strain.to(dtype);
+
+        // pretend to scale positions/cell by the strain so that
+        // it enters the computational graph.
+        system_positions = system_positions.matmul(model_strain);
+        cell = cell.matmul(model_strain);
+    }
+
+    // Periodic boundary conditions handling.
+    //
+    // While Metatomic models can support mixed PBC settings, we currently
+    // assume that the system is fully periodic and we throw an error otherwise
+    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
+        error->all(FLERR, "metatensor/kk currently requires a fully periodic system");
+    }
+    auto pbc = torch::tensor(
+        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
+        torch::TensorOptions().dtype(torch::kBool).device(this->device_)
+    );
+
+    auto system = torch::make_intrusive<metatomic_torch::SystemHolder>(
+        atomic_types_,
+        system_positions,
+        cell,
+        pbc
+    );
+
+    if (remap_pairs) {
+        auto* kk_list = dynamic_cast<NeighListKokkos<DeviceType>*>(list);
+        assert(kk_list != nullptr);
+        this->setup_neighbors_remap_kk(system, kk_list);
+    } else {
+        error->all(FLERR, "the kokkos version of metatensor requires remap_pairs to be true");
+    }
+
+    return system;
+}
+
+namespace LAMMPS_NS {
+template class MetatomicSystemAdaptorKokkos<LMPDeviceType>;
+#ifdef LMP_KOKKOS_GPU
+template class MetatomicSystemAdaptorKokkos<LMPHostType>;
+#endif
+}
diff --git a/src/KOKKOS/metatomic_system_kokkos.h b/src/KOKKOS/metatomic_system_kokkos.h
new file mode 100644
index 00000000000..3c64f1f4299
--- /dev/null
+++ b/src/KOKKOS/metatomic_system_kokkos.h
@@ -0,0 +1,99 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifndef LMP_METATENSOR_SYSTEM_KOKKOS_H
+#define LMP_METATENSOR_SYSTEM_KOKKOS_H
+
+#include "metatomic_system.h"
+
+#include "neigh_list_kokkos.h"
+
+namespace LAMMPS_NS {
+
+/* ---------------------------------------------------------------------- */
+
+// See https://kokkos.org/kokkos-core-wiki/API/core/execution_spaces.html for a
+// list of execution spaces.
+template<class DeviceType>
+struct KokkosDeviceToTorch {};
+
+#if defined(KOKKOS_ENABLE_SERIAL)
+template<> struct KokkosDeviceToTorch<Kokkos::Serial> {
+    static torch::Device convert() {
+        return torch::Device(torch::kCPU);
+    }
+};
+#endif
+
+#if defined(KOKKOS_ENABLE_CUDA)
+template<> struct KokkosDeviceToTorch<Kokkos::Cuda> {
+    static torch::Device convert() {
+        return torch::Device(torch::kCUDA, Kokkos::device_id());
+    }
+};
+#endif
+
+#if defined(KOKKOS_ENABLE_HIP)
+template<> struct KokkosDeviceToTorch<Kokkos::HIP> {
+    static torch::Device convert() {
+        return torch::Device(torch::kHIP, Kokkos::device_id());
+    }
+};
+#endif
+
+#if defined(KOKKOS_ENABLE_OPENMP)
+template<> struct KokkosDeviceToTorch<Kokkos::OpenMP> {
+    static torch::Device convert() {
+        return torch::Device(torch::kCPU);
+    }
+};
+#endif
+
+#if defined(KOKKOS_ENABLE_THREADS)
+template<> struct KokkosDeviceToTorch<Kokkos::Threads> {
+    static torch::Device convert() {
+        return torch::Device(torch::kCPU);
+    }
+};
+#endif
+
+// Kokkos::SYCL, Kokkos::OpenMPTarget, Kokkos::HPX don't have a matching device
+// in torch.
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+class MetatomicSystemAdaptorKokkos : public MetatomicSystemAdaptor {
+public:
+    MetatomicSystemAdaptorKokkos(LAMMPS *lmp, MetatomicSystemOptions options);
+    ~MetatomicSystemAdaptorKokkos() override {}
+
+    // Create a metatensor system matching the LAMMPS-Kokkos system data
+    metatomic_torch::System system_from_lmp(
+        NeighList* list,
+        bool do_virial,
+        bool remap_pairs,
+        torch::ScalarType dtype,
+        torch::Device device
+    ) override;
+
+    void setup_neighbors_remap_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list);
+
+private:
+    /// Torch device corresponding to the kokkos `DeviceType`
+    torch::Device device_;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
new file mode 100644
index 00000000000..a2d8546c2f0
--- /dev/null
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -0,0 +1,283 @@
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
+                         Filippo Bigi <filippo.bigi@epfl.ch>
+------------------------------------------------------------------------- */
+#include "pair_metatomic_kokkos.h"
+
+#include "error.h"
+#include "kokkos.h"
+#include "neigh_request.h"
+#include "atom_masks.h"
+
+#include "atom_kokkos.h"
+
+#include "metatomic_system_kokkos.h"
+#include "metatomic_types.h"
+#include "metatomic_timer.h"
+
+#include <algorithm>
+#include <cctype>
+
+using namespace LAMMPS_NS;
+
+// LAMMPS uses `LAMMPS_NS::tagint` and `int` for tags and neighbor lists, respectively.
+// For the moment, we require both to be int32_t for this interface
+static_assert(std::is_same_v<LAMMPS_NS::tagint, int32_t>, "Error: LAMMPS_NS::tagint must be int32_t to compile metatensor/kk");
+static_assert(std::is_same_v<int, int32_t>, "Error: int must be int32_t to compile metatensor/kk");
+
+template<typename T, class DeviceType>
+using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
+
+template<class DeviceType>
+PairMetatomicKokkos<DeviceType>::PairMetatomicKokkos(LAMMPS* lmp): PairMetatomic(lmp) {
+    // this will allow us to receive the NL in a GPU-friendly format
+    this->lmp->kokkos->neigh_transpose = 1;
+}
+
+template<class DeviceType>
+PairMetatomicKokkos<DeviceType>::~PairMetatomicKokkos() {}
+
+template<class DeviceType>
+void PairMetatomicKokkos<DeviceType>::init_style() {
+    PairMetatomic::init_style();
+
+    auto request = neighbor->find_request(this);
+    request->set_kokkos_host(
+        std::is_same_v<DeviceType, LMPHostType> &&
+        !std::is_same_v<DeviceType, LMPDeviceType>
+    );
+    request->set_kokkos_device(std::is_same_v<DeviceType, LMPDeviceType>);
+
+    // copy type mapping from host to device, to be able to give a device pointer
+    // to MetatomicSystemAdaptorKokkos
+    auto type_mapping_kk_host = UnmanagedView<int32_t*, LMPHostType>(this->type_mapping, atom->ntypes + 1);
+    this->type_mapping_kk = Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType>("type_mapping_kk", atom->ntypes + 1);
+    Kokkos::deep_copy(this->type_mapping_kk, type_mapping_kk_host);
+
+    auto options = MetatomicSystemOptions{
+        this->type_mapping_kk.data(),
+        mta_data->max_cutoff,
+        mta_data->check_consistency,
+    };
+
+    // override the system adaptor with the kokkos version
+    this->system_adaptor = std::make_unique<MetatomicSystemAdaptorKokkos<DeviceType>>(lmp, options);
+
+    // request NL with the new adaptor
+    auto requested_nl = mta_data->model->run_method("requested_neighbor_lists");
+    for (const auto& ivalue: requested_nl.toList()) {
+        auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
+        auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
+        assert(cutoff <= mts_data->max_cutoff);
+
+        this->system_adaptor->add_nl_request(cutoff, options);
+    }
+}
+
+template<class DeviceType>
+void PairMetatomicKokkos<DeviceType>::pick_device(torch::Device* device, const char* requested) {
+    *device = KokkosDeviceToTorch<DeviceType>::convert();
+
+    if (requested != nullptr) {
+        auto requested_str = std::string(requested);
+        std::transform(requested_str.begin(), requested_str.end(), requested_str.begin(), ::tolower);
+        if (c10::DeviceTypeName(device->type(), /*lower_case=*/true) != requested_str) {
+            error->all(FLERR,
+                "requested device '{}' does not match the device being used by kokkos '{}', "
+                "use the non-kokkos version of this pair style to use a different "
+                "device for the model and LAMMPS",
+                requested, device->str()
+            );
+        }
+    }
+}
+
+template<class DeviceType>
+void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
+    if (std::getenv("LAMMPS_METATENSOR_PROFILE") != nullptr) {
+        MetatomicTimer::enable(true);
+    } else {
+        MetatomicTimer::enable(false);
+    }
+
+    auto _ = MetatomicTimer("PairMetatomicKokkos::compute");
+
+    /// Declare what we need to read from the atomKK object and what we will modify
+    this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, X_MASK | F_MASK | TAG_MASK | TYPE_MASK | ENERGY_MASK | VIRIAL_MASK);
+    this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, ENERGY_MASK | F_MASK | VIRIAL_MASK);
+
+    if (eflag || vflag) {
+        ev_setup(eflag, vflag);
+    } else {
+        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
+    }
+
+    if (eflag_atom) {
+        mta_data->evaluation_options->outputs.at("energy")->per_atom = true;
+    } else {
+        mta_data->evaluation_options->outputs.at("energy")->per_atom = false;
+    }
+
+    auto dtype = torch::kFloat64;
+    if (mta_data->capabilities->dtype() == "float64") {
+        dtype = torch::kFloat64;
+    } else if (mta_data->capabilities->dtype() == "float32") {
+        dtype = torch::kFloat32;
+    } else {
+        error->all(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
+    }
+
+    // transform from LAMMPS to metatensor System
+    auto system = this->system_adaptor->system_from_lmp(
+        mta_list,
+        static_cast<bool>(vflag_global),
+        mta_data->remap_pairs,
+        dtype,
+        mta_data->device
+    );
+
+    // only run the calculation for atoms actually in the current domain
+    mta_data->selected_atoms_values.resize_({atom->nlocal, 2});
+    mta_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
+    auto tensor_options = mta_data->selected_atoms_values.options();
+    mta_data->selected_atoms_values.index_put_(
+        {torch::indexing::Slice(), 1},
+        torch::arange(atom->nlocal, tensor_options)
+    );
+
+    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system", "atom"}, mta_data->selected_atoms_values
+    );
+    mta_data->evaluation_options->set_selected_atoms(selected_atoms);
+
+    torch::IValue result_ivalue;
+    try {
+        auto _ = MetatomicTimer("running Model::forward");
+        result_ivalue = mta_data->model->forward({
+            std::vector<metatomic_torch::System>{system},
+            mta_data->evaluation_options,
+            mta_data->check_consistency
+        });
+    } catch (const std::exception& e) {
+        error->all(FLERR, "error evaluating the torch model: {}", e.what());
+    }
+
+    auto result = result_ivalue.toGenericDict();
+    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
+    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
+    auto energy_tensor = energy_block->values();
+
+    // compute forces/virial on device with backward propagation
+    {
+        // reset gradients to zero before calling backward
+        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
+        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
+
+        auto _ = MetatomicTimer("running Model::backward");
+        energy_tensor.backward(-torch::ones_like(energy_tensor));
+    }
+
+    {
+        auto _ = MetatomicTimer("storing model output in LAMMPS data structures");
+
+        // move results to cpu for storing
+        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
+        auto energy_samples = energy_block->samples();
+
+        // store the energy returned by the model
+        torch::Tensor global_energy;
+        if (eflag_atom) {
+            assert(energy_samples->size() == 2);
+            assert(energy_samples->names()[0] == "system");
+            assert(energy_samples->names()[1] == "atom");
+
+            auto samples_values = energy_samples->values().to(torch::kCPU);
+            auto samples = samples_values.accessor<int32_t, 2>();
+
+            int64_t n_atoms = atom->nlocal + atom->nghost;
+            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
+
+            auto energies = energy_detached.accessor<double, 2>();
+            for (int64_t i=0; i<energy_samples->count(); i++) {
+                assert(samples[i][0] == 0);
+                // handle potentially out of order samples in
+                // the per-atom energy tensor
+                auto atom_i = samples[i][1];
+                assert(atom_i < n_atoms);
+                eatom[atom_i] += energies[i][0];
+            }
+
+            global_energy = energy_detached.sum(0);
+            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
+        } else {
+            assert(energy_samples->size() == 1);
+            assert(energy_samples->names()[0] == "system");
+
+            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
+            global_energy = energy_detached.reshape({1});
+        }
+
+        if (eflag_global) {
+            eng_vdwl += global_energy.item<double>();
+        }
+
+        // store forces/virial
+        auto forces_tensor = this->system_adaptor->positions.grad().contiguous();
+        assert(forces_tensor.scalar_type() == torch::kFloat64);
+
+        auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
+        auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
+            forces_tensor.template data_ptr<double>(),
+            forces_tensor.size(0), 3
+        );
+
+        Kokkos::parallel_for(
+            system->size(),
+            KOKKOS_LAMBDA(size_t i) {
+                forces_lammps_kk(i, 0) += forces_metatensor_kk(i, 0);
+                forces_lammps_kk(i, 1) += forces_metatensor_kk(i, 1);
+                forces_lammps_kk(i, 2) += forces_metatensor_kk(i, 2);
+            }
+        );
+
+        assert(!vflag_fdotr);
+
+        if (vflag_global) {
+            auto virial_tensor = this->system_adaptor->strain.grad().to(torch::kCPU);
+            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
+            auto predicted_virial = virial_tensor.template accessor<double, 2>();
+
+            virial[0] += predicted_virial[0][0];
+            virial[1] += predicted_virial[1][1];
+            virial[2] += predicted_virial[2][2];
+
+            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
+            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
+            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
+        }
+
+        if (vflag_atom) {
+            error->all(FLERR, "per atom virial is not implemented");
+        }
+    }
+}
+
+namespace LAMMPS_NS {
+template class PairMetatomicKokkos<LMPDeviceType>;
+#ifdef LMP_KOKKOS_GPU
+template class PairMetatomicKokkos<LMPHostType>;
+#endif
+}
diff --git a/src/KOKKOS/pair_metatomic_kokkos.h b/src/KOKKOS/pair_metatomic_kokkos.h
new file mode 100644
index 00000000000..c8e6496a14a
--- /dev/null
+++ b/src/KOKKOS/pair_metatomic_kokkos.h
@@ -0,0 +1,50 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+#ifdef PAIR_CLASS
+// clang-format off
+PairStyle(metatomic/kk, PairMetatomicKokkos<LMPDeviceType>);
+// clang-format on
+#else
+
+#ifndef LMP_PAIR_METATOMIC_KOKKOS_H
+#define LMP_PAIR_METATOMIC_KOKKOS_H
+
+#include "pair_kokkos.h"
+#include "pair_metatomic.h"
+
+namespace LAMMPS_NS {
+
+template<class DeviceType>
+class MetatomicSystemAdaptorKokkos;
+
+template<class DeviceType>
+struct PairMetatomicDataKokkos;
+
+template<class DeviceType>
+class PairMetatomicKokkos : public PairMetatomic {
+public:
+    PairMetatomicKokkos(class LAMMPS *);
+    ~PairMetatomicKokkos();
+
+    void init_style() override;
+    void compute(int eflag, int vflag) override;
+private:
+    void pick_device(c10::Device* device, const char* requested) override;
+
+    Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType> type_mapping_kk;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
+#endif
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
new file mode 100644
index 00000000000..a5c51cc8bf6
--- /dev/null
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -0,0 +1,561 @@
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
+------------------------------------------------------------------------- */
+#include "metatomic_system.h"
+#include "metatomic_timer.h"
+
+#include "atom.h"
+#include "domain.h"
+#include "error.h"
+
+#include "neigh_list.h"
+
+#include <metatensor/torch.hpp>
+
+using namespace LAMMPS_NS;
+
+MetatomicSystemAdaptor::MetatomicSystemAdaptor(LAMMPS *lmp, MetatomicSystemOptions options):
+    Pointers(lmp),
+    options_(std::move(options)),
+    caches_(),
+    atomic_types_(torch::zeros({0}, torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)))
+{
+    auto tensor_options = torch::TensorOptions()
+        .dtype(torch::kFloat64)
+        .device(torch::kCPU)
+        .requires_grad(true);
+
+    this->strain = torch::eye(3, tensor_options);
+}
+
+MetatomicSystemAdaptor::~MetatomicSystemAdaptor() {}
+
+void MetatomicSystemAdaptor::add_nl_request(double cutoff, metatomic_torch::NeighborListOptions request) {
+    if (cutoff > options_.interaction_range) {
+        error->all(FLERR,
+            "Invalid metatomic model: one of the requested neighbor lists "
+            "has a cutoff ({}) larger than the model interaction range ({})",
+            cutoff, options_.interaction_range
+        );
+    } else if (cutoff < 0 || !std::isfinite(cutoff)) {
+        error->all(FLERR,
+            "model requested an invalid cutoff for neighbors list: {} "
+            "(cutoff in model units is {})",
+            cutoff, request->cutoff()
+        );
+    }
+
+    caches_.push_back({
+        cutoff,
+        request,
+        /*known_samples = */ {},
+        /*samples = */ {},
+        /*distances_f64 = */ {},
+        /*distances_f32 = */ {},
+    });
+}
+
+
+static std::array<int32_t, 3> cell_shifts(
+    const std::array<std::array<double, 3>, 3>& cell_inv,
+    const std::array<double, 3>& pair_shift
+) {
+    auto shift_a = static_cast<int32_t>(std::round(
+        cell_inv[0][0] * pair_shift[0] +
+        cell_inv[0][1] * pair_shift[1] +
+        cell_inv[0][2] * pair_shift[2]
+    ));
+    auto shift_b = static_cast<int32_t>(std::round(
+        cell_inv[1][0] * pair_shift[0] +
+        cell_inv[1][1] * pair_shift[1] +
+        cell_inv[1][2] * pair_shift[2]
+    ));
+    auto shift_c = static_cast<int32_t>(std::round(
+        cell_inv[2][0] * pair_shift[0] +
+        cell_inv[2][1] * pair_shift[1] +
+        cell_inv[2][2] * pair_shift[2]
+    ));
+
+    return {shift_a, shift_b, shift_c};
+}
+
+
+void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& system, NeighList *list) {
+    auto _ = MetatomicTimer("converting neighbors with ghosts remapping");
+    auto dtype = system->positions().scalar_type();
+    auto device = system->positions().device();
+
+    double** x = atom->x;
+    auto total_n_atoms = atom->nlocal + atom->nghost;
+
+    auto cell_inv_tensor = system->cell().inverse().t().to(torch::kCPU).to(torch::kFloat64);
+    auto cell_inv_accessor = cell_inv_tensor.accessor<double, 2>();
+    auto cell_inv = std::array<std::array<double, 3>, 3>{{
+        {{cell_inv_accessor[0][0], cell_inv_accessor[0][1], cell_inv_accessor[0][2]}},
+        {{cell_inv_accessor[1][0], cell_inv_accessor[1][1], cell_inv_accessor[1][2]}},
+        {{cell_inv_accessor[2][0], cell_inv_accessor[2][1], cell_inv_accessor[2][2]}},
+    }};
+
+    {
+        auto _ = MetatomicTimer("identifying ghosts and real atoms");
+
+        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
+        // atoms which are periodic images of local atoms back to the local atoms.
+        //
+        // metatomic expects pairs corresponding to periodic atoms to be between
+        // the main atoms, but using the actual distance vector between the atom and
+        // the ghost.
+        original_atom_id_.clear();
+        original_atom_id_.reserve(total_n_atoms);
+
+        // identify all local atom by their LAMMPS atom tag.
+        local_atoms_tags_.clear();
+        for (int i=0; i<atom->nlocal; i++) {
+            original_atom_id_.emplace_back(i);
+            local_atoms_tags_.emplace(atom->tag[i], i);
+        }
+
+        // now loop over ghosts & map them back to the main cell if needed
+        ghost_atoms_tags_.clear();
+        for (int i=atom->nlocal; i<total_n_atoms; i++) {
+            auto tag = atom->tag[i];
+            auto it = local_atoms_tags_.find(tag);
+            if (it != local_atoms_tags_.end()) {
+                // this is the periodic image of an atom already owned by this domain
+                original_atom_id_.emplace_back(it->second);
+            } else {
+                // this can either be a periodic image of an atom owned by another
+                // domain, or directly an atom from another domain. Since we can not
+                // really distinguish between these, we take the first atom as the
+                // "main" one and remap all atoms with the same tag to the first one
+                auto it = ghost_atoms_tags_.find(tag);
+                if (it != ghost_atoms_tags_.end()) {
+                    // we already found this atom elsewhere in the system
+                    original_atom_id_.emplace_back(it->second);
+                } else {
+                    // this is the first time we are seeing this atom
+                    original_atom_id_.emplace_back(i);
+                    ghost_atoms_tags_.emplace(tag, i);
+                }
+            }
+        }
+    }
+
+    for (auto& cache: caches_) {
+        {
+            auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
+
+            auto cutoff2 = cache.cutoff * cache.cutoff;
+            auto full_list = cache.options->full_list();
+
+            // convert from LAMMPS neighbors list to metatomic format
+            cache.known_samples.clear();
+            cache.samples.clear();
+            cache.distances_f32.clear();
+            cache.distances_f64.clear();
+            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
+                auto atom_i = list->ilist[ii];
+                assert(atom_i < total_n_atoms);
+                auto original_atom_i = original_atom_id_[atom_i];
+
+                auto neighbors = list->firstneigh[ii];
+                for (int jj=0; jj<list->numneigh[ii]; jj++) {
+                    auto atom_j = neighbors[jj] & NEIGHMASK;
+                    assert(atom_j < total_n_atoms);
+                    auto original_atom_j = original_atom_id_[atom_j];
+
+                    if (!full_list && original_atom_i > original_atom_j) {
+                        // Remove extra pairs if the model requested half-lists
+                        continue;
+                    }
+
+                    auto distance = std::array<double, 3>{
+                        x[atom_j][0] - x[atom_i][0],
+                        x[atom_j][1] - x[atom_i][1],
+                        x[atom_j][2] - x[atom_i][2],
+                    };
+
+                    auto distance2 = (
+                        distance[0] * distance[0] +
+                        distance[1] * distance[1] +
+                        distance[2] * distance[2]
+                    );
+                    if (distance2 > cutoff2) {
+                        // LAMMPS neighbors list contains some pairs after the
+                        // cutoff, we filter them here
+                        continue;
+                    }
+
+                    // Compute the cell shift for the pair.
+                    auto shift_i = std::array<double, 3>{
+                        x[atom_i][0] - x[original_atom_i][0],
+                        x[atom_i][1] - x[original_atom_i][1],
+                        x[atom_i][2] - x[original_atom_i][2],
+                    };
+                    auto shift_j = std::array<double, 3>{
+                        x[atom_j][0] - x[original_atom_j][0],
+                        x[atom_j][1] - x[original_atom_j][1],
+                        x[atom_j][2] - x[original_atom_j][2],
+                    };
+                    auto pair_shift = std::array<double, 3>{
+                        shift_j[0] - shift_i[0],
+                        shift_j[1] - shift_i[1],
+                        shift_j[2] - shift_i[2],
+                    };
+
+                    auto shift = std::array<int32_t, 3>{0, 0, 0};
+                    if (pair_shift[0] != 0 || pair_shift[1] != 0 || pair_shift[2] != 0) {
+                        shift = cell_shifts(cell_inv, pair_shift);
+
+                        if (!full_list && original_atom_i == original_atom_j) {
+                            // If a half neighbors list has been requested, do
+                            // not include the same pair between an atom and
+                            // it's periodic image twice with opposite cell
+                            // shifts (e.g. [1, -1, 1] and [-1, 1, -1]).
+                            //
+                            // Instead we pick pairs in the positive plan of
+                            // shifts.
+                            if (shift[0] + shift[1] + shift[2] < 0) {
+                                // drop shifts on the negative half-space
+                                continue;
+                            }
+
+                            if ((shift[0] + shift[1] + shift[2] == 0)
+                                && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0))) {
+                                // drop shifts in the negative half plane or the
+                                // negative shift[1] axis.
+                                //
+                                // See below for a graphical representation: we are
+                                // keeping the shifts indicated with `O` and
+                                // dropping the ones indicated with `X`
+                                //
+                                //  O O O │ O O O
+                                //  O O O │ O O O
+                                //  O O O │ O O O
+                                // ─X─X─X─┼─O─O─O─
+                                //  X X X │ X X X
+                                //  X X X │ X X X
+                                //  X X X │ X X X
+                                continue;
+                            }
+                        }
+                    }
+
+                    auto sample = std::array<int32_t, 5>{
+                        original_atom_i,
+                        original_atom_j,
+                        shift[0],
+                        shift[1],
+                        shift[2],
+                    };
+
+                    // only add the pair if it is not already known. The same pair
+                    // can occur multiple time between two periodic ghosts shifted
+                    // around by the same amount, but we only want one of these pairs.
+                    if (cache.known_samples.insert(sample).second) {
+                        cache.samples.push_back(sample);
+
+                        if (dtype == torch::kFloat64) {
+                            cache.distances_f64.push_back(distance);
+                        } else if (dtype == torch::kFloat32) {
+                            cache.distances_f32.push_back({
+                                static_cast<float>(distance[0]),
+                                static_cast<float>(distance[1]),
+                                static_cast<float>(distance[2])
+                            });
+                        } else {
+                            // should be unreachable
+                            error->all(FLERR, "invalid dtype, this is a bug");
+                        }
+                    }
+                }
+            }
+        }
+
+        int64_t n_pairs = cache.samples.size();
+        auto samples_values = torch::from_blob(
+            reinterpret_cast<int32_t*>(cache.samples.data()),
+            {n_pairs, 5},
+            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
+        );
+
+        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
+        {
+            auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
+            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                samples_values
+            );
+        }
+
+        auto distances_vectors = torch::Tensor();
+        if (dtype == torch::kFloat64) {
+            distances_vectors = torch::from_blob(
+                cache.distances_f64.data(),
+                {n_pairs, 3, 1},
+                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
+            );
+        } else if (dtype == torch::kFloat32) {
+            distances_vectors = torch::from_blob(
+                cache.distances_f32.data(),
+                {n_pairs, 3, 1},
+                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
+            );
+        } else {
+            // should be unreachable
+            error->all(FLERR, "invalid dtype, this is a bug");
+        }
+
+        {
+            auto _ = MetatomicTimer("moving neighbor data to dtype/device");
+            distances_vectors = distances_vectors.to(dtype).to(device);
+            samples = samples->to(device);
+        }
+
+        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
+        {
+            auto _ = MetatomicTimer("creating neighbors TensorBlock");
+            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+                distances_vectors,
+                samples,
+                std::vector<metatensor_torch::TorchLabels>{
+                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
+                },
+                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
+            );
+        }
+
+        metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
+        system->add_neighbor_list(cache.options, neighbors);
+    }
+}
+
+void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& system, NeighList *list) {
+    auto _ = MetatomicTimer("converting neighbors without ghosts remapping");
+
+    auto dtype = system->positions().scalar_type();
+    auto device = system->positions().device();
+
+    double** x = atom->x;
+
+    for (auto& cache: caches_) {
+        {
+            auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
+
+            auto cutoff2 = cache.cutoff * cache.cutoff;
+            auto full_list = cache.options->full_list();
+
+            // convert from LAMMPS neighbors list to metatensor format
+            cache.known_samples.clear();
+            cache.samples.clear();
+            cache.distances_f32.clear();
+            cache.distances_f64.clear();
+            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
+                auto atom_i = list->ilist[ii];
+
+                auto neighbors = list->firstneigh[ii];
+                for (int jj=0; jj<list->numneigh[ii]; jj++) {
+                    auto atom_j = neighbors[jj];
+
+                    if (!full_list && atom_i > atom_j) {
+                        // Remove extra pairs if the model requested half-lists
+                        continue;
+                    }
+
+                    auto distance = std::array<double, 3>{
+                        x[atom_j][0] - x[atom_i][0],
+                        x[atom_j][1] - x[atom_i][1],
+                        x[atom_j][2] - x[atom_i][2],
+                    };
+
+                    auto distance2 = (
+                        distance[0] * distance[0] +
+                        distance[1] * distance[1] +
+                        distance[2] * distance[2]
+                    );
+                    if (distance2 > cutoff2) {
+                        // LAMMPS neighbors list contains some pairs after the
+                        // cutoff, we filter them here
+                        continue;
+                    }
+
+                    auto sample = std::array<int32_t, 5>{atom_i, atom_j, 0, 0, 0};
+
+
+                    cache.samples.push_back(sample);
+
+                    if (dtype == torch::kFloat64) {
+                        cache.distances_f64.push_back(distance);
+                    } else if (dtype == torch::kFloat32) {
+                        cache.distances_f32.push_back({
+                            static_cast<float>(distance[0]),
+                            static_cast<float>(distance[1]),
+                            static_cast<float>(distance[2])
+                        });
+                    } else {
+                        // should be unreachable
+                        error->all(FLERR, "invalid dtype, this is a bug");
+                    }
+                }
+            }
+        }
+
+        int64_t n_pairs = cache.samples.size();
+        auto samples_values = torch::from_blob(
+            reinterpret_cast<int32_t*>(cache.samples.data()),
+            {n_pairs, 5},
+            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
+        );
+
+        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
+        {
+            auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) +" pairs)");
+            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                samples_values
+            );
+        }
+
+        auto distances_vectors = torch::Tensor();
+        if (dtype == torch::kFloat64) {
+            distances_vectors = torch::from_blob(
+                cache.distances_f64.data(),
+                {n_pairs, 3, 1},
+                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
+            );
+        } else if (dtype == torch::kFloat32) {
+            distances_vectors = torch::from_blob(
+                cache.distances_f32.data(),
+                {n_pairs, 3, 1},
+                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
+            );
+        } else {
+            // should be unreachable
+            error->all(FLERR, "invalid dtype, this is a bug");
+        }
+
+        {
+            auto _ = MetatomicTimer("moving neighbor data to dtype/device");
+            distances_vectors = distances_vectors.to(dtype).to(device);
+            samples = samples->to(device);
+        }
+
+        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
+        {
+            auto _ = MetatomicTimer("creating neighbors TensorBlock");
+            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+                distances_vectors,
+                samples,
+                std::vector<metatensor_torch::TorchLabels>{
+                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
+                },
+                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
+            );
+        }
+
+        metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
+        system->add_neighbor_list(cache.options, neighbors);
+    }
+}
+
+
+metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
+    NeighList* list,
+    bool do_virial,
+    bool remap_pairs,
+    torch::ScalarType dtype,
+    torch::Device device
+) {
+    auto _ = MetatomicTimer("creating System from LAMMPS data");
+
+    double** x = atom->x;
+    auto total_n_atoms = atom->nlocal + atom->nghost;
+
+    atomic_types_.resize_({total_n_atoms});
+    for (int i=0; i<total_n_atoms; i++) {
+        atomic_types_[i] = options_.types_mapping[atom->type[i]];
+    }
+
+    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU);
+
+    // atom->x contains "real" and then ghost atoms, in that order
+    this->positions = torch::from_blob(
+        *x, {total_n_atoms, 3},
+        // requires_grad=true since we always need gradients w.r.t. positions
+        tensor_options.requires_grad(true)
+    );
+
+    auto cell = torch::zeros({3, 3}, tensor_options);
+    cell[0][0] = domain->xprd;
+
+    cell[1][0] = domain->xy;
+    cell[1][1] = domain->yprd;
+
+    cell[2][0] = domain->xz;
+    cell[2][1] = domain->yz;
+    cell[2][2] = domain->zprd;
+
+    auto system_positions = this->positions.to(dtype).to(device);
+    cell = cell.to(dtype).to(device);
+
+    if (do_virial) {
+        auto model_strain = this->strain.to(dtype).to(device);
+
+        // pretend to scale positions/cell by the strain so that
+        // it enters the computational graph.
+        system_positions = system_positions.matmul(model_strain);
+        cell = cell.matmul(model_strain);
+    }
+
+    // Periodic boundary conditions handling.
+    // While Metatensor atomistic models can support mixed PBC settings, we
+    // currently assume that the system is fully periodic and we throw an error
+    // otherwise
+    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
+        error->all(FLERR, "pair_metatensor requires a fully periodic system");
+    }
+    auto pbc = torch::tensor(
+        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
+        torch::TensorOptions().dtype(torch::kBool).device(device)
+    );
+
+    // Note that something like this:
+    //     cell.index_put_(
+    //         {torch::logical_not(pbc)},
+    //         torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(device))
+    //     );
+    //
+    // would allow creating System with non-periodic directions, but we're using
+    // the inverse of the cell matrix to filter the neighbor list, and the cell
+    // matrix becomes singular if any of its rows are zero. This requires some
+    // changes in the neighbor list filtering code to handle non-periodic
+    // directions.
+
+    auto system = torch::make_intrusive<metatomic_torch::SystemHolder>(
+        atomic_types_.to(device),
+        system_positions,
+        cell,
+        pbc
+    );
+
+    if (remap_pairs) {
+        this->setup_neighbors_remap(system, list);
+    } else {
+        this->setup_neighbors_no_remap(system, list);
+    }
+
+    return system;
+}
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
new file mode 100644
index 00000000000..2778cff8bfa
--- /dev/null
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -0,0 +1,143 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifndef LMP_METATOMIC_SYSTEM_H
+#define LMP_METATOMIC_SYSTEM_H
+
+#include <vector>
+#include <array>
+#include <unordered_set>
+
+#include "pointers.h"
+#include "pair.h"
+#include "neigh_list.h"
+
+#include <metatomic/torch.hpp>
+
+
+namespace LAMMPS_NS {
+
+struct MetatomicSystemOptions {
+    // Mapping from LAMMPS types to metatensor types.
+    // If used with kokkos, this should be a device pointer
+    int32_t* types_mapping;
+    // interaction range of the model, in LAMMPS units
+    double interaction_range;
+    // should we run extra checks on the neighbor lists?
+    bool check_consistency;
+};
+
+// data for metatensor neighbors lists
+struct MetatomicNeighborsData {
+    // single neighbors sample containing [i, j, S_a, S_b, S_c]
+    using sample_t = std::array<int32_t, 5>;
+
+    struct SampleHasher {
+        static void hash_combine(std::size_t& seed, const int32_t& v) {
+            seed ^= std::hash<int32_t>()(v) + 0x9e3779b9 + (seed<<6) + (seed>>2);
+        }
+
+        size_t operator()(const sample_t& s) const {
+            size_t hash = 0;
+            hash_combine(hash, s[0]);
+            hash_combine(hash, s[1]);
+            hash_combine(hash, s[2]);
+            hash_combine(hash, s[3]);
+            hash_combine(hash, s[4]);
+            return hash;
+        }
+    };
+
+    // cutoff for this NL in LAMMPS units
+    double cutoff;
+    // options of the NL as requested by the model
+    metatomic_torch::NeighborListOptions options;
+
+    // Below are cached allocations for the LAMMPS -> metatensor NL translation
+    // TODO: report memory usage for these?
+
+    // we keep the set of samples twice: once in `known_samples` to remove
+    // duplicated pairs, and once in `samples` in a format that can be
+    // used to create a torch::Tensor.
+    std::unordered_set<sample_t, SampleHasher> known_samples;
+    std::vector<sample_t> samples;
+    // pairs distances vectors
+    std::vector<std::array<double, 3>> distances_f64;
+    std::vector<std::array<float, 3>> distances_f32;
+};
+
+class MetatomicSystemAdaptor : public Pointers {
+public:
+    MetatomicSystemAdaptor(LAMMPS *lmp, MetatomicSystemOptions options);
+
+    virtual ~MetatomicSystemAdaptor();
+
+    void add_nl_request(double cutoff, metatomic_torch::NeighborListOptions request);
+
+    // Create a metatensor system matching the LAMMPS system data
+    virtual metatomic_torch::System system_from_lmp(
+        NeighList* list,
+        bool do_virial,
+        bool remap_pairs,
+        torch::ScalarType dtype,
+        torch::Device device
+    );
+
+    // Explicit strain for virial calculations. This uses the same dtype/device
+    // as LAMMPS data (positions, …)
+    torch::Tensor strain;
+    // keep the positions as coming from LAMMPS (before any dtype/device
+    // conversion) to access its gradient
+    torch::Tensor positions;
+
+ protected:
+    // setup the metatensor neighbors list from the internal LAMMPS one,
+    // remapping periodic ghosts to the corresponding local atom
+    void setup_neighbors_remap(metatomic_torch::System& system, NeighList* list);
+
+    // setup the metatensor neighbors list from the internal LAMMPS one,
+    // WITHOUT remapping periodic ghosts to the corresponding local atom.
+    //
+    // This produces a larger NL but skips the cost of the remapping
+    void setup_neighbors_no_remap(metatomic_torch::System& system, NeighList* list);
+
+    // options for this system adaptor
+    MetatomicSystemOptions options_;
+
+    // allocations caches for all the NL requested by the model
+    std::vector<MetatomicNeighborsData> caches_;
+    // allocation cache for the atomic types in the system
+    torch::Tensor atomic_types_;
+    // allocation cache holding the "original atom" id for all atoms in the
+    // system. This is the same as the atom id for all local atoms. For ghost
+    // atoms, this is either the id of the corresponding local atom if the ghost
+    // is a periodic image of a local atom, the id of the first ghost we found
+    // with a given atom tag if the ghost is a periodic image of another ghost;
+    // or the id of the ghost in all other cases.
+    std::vector<int> original_atom_id_;
+    // allocation cache holding the map from atom tag to atom id for local
+    // atoms.
+    std::unordered_map<tagint, int> local_atoms_tags_;
+    // allocation cache holding the map from atom tag to atom id for ghost
+    // atoms. When there are multiple periodic images of the same atom, only one
+    // will be included here.
+    std::unordered_map<tagint, int> ghost_atoms_tags_;
+
+    // TODO: should we use LAMMPS allocations/deallocation facilities for the
+    // allocation caches? If we don't, should we report memory usage from the
+    // allocations caches to LAMMPS one way or another?
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
diff --git a/src/ML-METATOMIC/metatomic_timer.cpp b/src/ML-METATOMIC/metatomic_timer.cpp
new file mode 100644
index 00000000000..ba33a6b8a6c
--- /dev/null
+++ b/src/ML-METATOMIC/metatomic_timer.cpp
@@ -0,0 +1,63 @@
+#include <mutex>
+#include <iostream>
+
+#include "metatomic_timer.h"
+
+using namespace LAMMPS_NS;
+
+// lock to protect the other static from concurrent modification
+static std::mutex METATOMIC_TIMER_MUTEX = {};
+// depth of the timer, i.e. how many different timers are alive right now
+static int64_t METATOMIC_TIMER_DEPTH = -1;
+// strictly increasing timer counter, to know if a new one was created inside
+// the scope of the current one.
+static uint64_t METATOMIC_TIMER_COUNTER = 0;
+// Is profiling enabled?
+static bool METATOMIC_TIMER_ENABLED = false;
+
+
+void MetatomicTimer::enable(bool toggle) {
+    auto guard_ = std::lock_guard(METATOMIC_TIMER_MUTEX);
+
+    METATOMIC_TIMER_ENABLED = toggle;
+}
+
+
+MetatomicTimer::MetatomicTimer(std::string name):
+    enabled_(false),
+    name_(std::move(name))
+{
+    auto guard_ = std::lock_guard(METATOMIC_TIMER_MUTEX);
+    if (METATOMIC_TIMER_ENABLED) {
+        METATOMIC_TIMER_DEPTH += 1;
+        METATOMIC_TIMER_COUNTER += 1;
+
+        this->enabled_ = true;
+        this->starting_counter_ = METATOMIC_TIMER_COUNTER;
+        this->start_ = std::chrono::high_resolution_clock::now();
+        auto indent = std::string(METATOMIC_TIMER_DEPTH * 3, ' ');
+
+        if (METATOMIC_TIMER_DEPTH == 0) {
+            std::cerr << "\n";
+        }
+
+        std::cerr << "\n" << indent << this->name_ << " ...";
+    }
+}
+
+MetatomicTimer::~MetatomicTimer() {
+    auto guard_ = std::lock_guard(METATOMIC_TIMER_MUTEX);
+
+    if (METATOMIC_TIMER_ENABLED && this->enabled_) {
+        auto stop = std::chrono::high_resolution_clock::now();
+        auto elapsed = std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start_).count();
+
+        if (METATOMIC_TIMER_COUNTER != starting_counter_) {
+            auto indent = std::string(METATOMIC_TIMER_DEPTH * 3, ' ');
+            std::cerr << "\n" << indent << this->name_;
+        }
+
+        std::cerr << " took " << elapsed / 1e6 << "ms" << std::flush;
+        METATOMIC_TIMER_DEPTH -= 1;
+    }
+}
diff --git a/src/ML-METATOMIC/metatomic_timer.h b/src/ML-METATOMIC/metatomic_timer.h
new file mode 100644
index 00000000000..4b3019aa1c4
--- /dev/null
+++ b/src/ML-METATOMIC/metatomic_timer.h
@@ -0,0 +1,42 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifndef LMP_METATOMIC_TIMER_H
+#define LMP_METATOMIC_TIMER_H
+
+#include <chrono>
+#include <string>
+
+namespace LAMMPS_NS {
+
+/// Simple timer for profiling the LAMMPS/Metatensor integration. This starts
+/// the timer when created, and print the elapsed time to stderr when going out
+/// of scope.
+class MetatomicTimer {
+public:
+    MetatomicTimer(std::string name);
+    ~MetatomicTimer();
+
+    // enable/disable profiling
+    static void enable(bool toggle);
+
+private:
+    bool enabled_;
+    std::string name_;
+    size_t starting_counter_;
+    std::chrono::time_point<std::chrono::high_resolution_clock> start_;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
new file mode 100644
index 00000000000..196ab1f464e
--- /dev/null
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -0,0 +1,97 @@
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
+------------------------------------------------------------------------- */
+#include "metatomic_types.h"
+
+#include "citeme.h"
+#include "comm.h"
+#include "error.h"
+
+using namespace LAMMPS_NS;
+
+PairMetatomicData::PairMetatomicData(std::string length_unit, std::string energy_unit):
+    device(torch::kCPU),
+    check_consistency(false),
+    remap_pairs(true),
+    max_cutoff(-1)
+{
+    auto options = torch::TensorOptions().dtype(torch::kInt32);
+    this->selected_atoms_values = torch::zeros({0, 2}, options);
+
+    // Initialize evaluation_options
+    this->evaluation_options = torch::make_intrusive<metatomic_torch::ModelEvaluationOptionsHolder>();
+    this->evaluation_options->set_length_unit(std::move(length_unit));
+
+    auto output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+    output->explicit_gradients = {};
+    output->set_quantity("energy");
+    output->set_unit(std::move(energy_unit));
+    output->per_atom = false;
+
+    this->evaluation_options->outputs.insert("energy", output);
+}
+
+void PairMetatomicData::load_model(
+   LAMMPS* lmp,
+   const char* path,
+   const char* extensions_directory
+) {
+   // TODO: seach for the model & extensions inside `$LAMMPS_POTENTIALS`?
+
+   if (this->model != nullptr) {
+       lmp->error->all(FLERR, "torch model is already loaded");
+   }
+
+   torch::optional<std::string> extensions = torch::nullopt;
+   if (extensions_directory != nullptr) {
+       extensions = std::string(extensions_directory);
+   }
+
+   try {
+       this->model = std::make_unique<torch::jit::Module>(
+           metatomic_torch::load_atomistic_model(path, extensions)
+       );
+   } catch (const c10::Error& e) {
+       lmp->error->all(FLERR, "failed to load metatensor model at '{}': {}", path, e.what());
+   }
+
+   auto capabilities_ivalue = this->model->run_method("capabilities");
+   this->capabilities = capabilities_ivalue.toCustomClass<metatomic_torch::ModelCapabilitiesHolder>();
+
+   if (!this->capabilities->outputs().contains("energy")) {
+       lmp->error->all(FLERR, "the model at '{}' does not have an \"energy\" output, we can not use it in pair_style metatensor", path);
+   }
+
+   if (lmp->comm->me == 0) {
+       auto metadata_ivalue = this->model->run_method("metadata");
+       auto metadata = metadata_ivalue.toCustomClass<metatomic_torch::ModelMetadataHolder>();
+       auto to_print = metadata->print();
+
+       if (lmp->screen) {
+           fprintf(lmp->screen, "\n%s\n", to_print.c_str());
+       }
+       if (lmp->logfile) {
+           fprintf(lmp->logfile,"\n%s\n", to_print.c_str());
+       }
+
+       // add the model references to LAMMPS citation handling mechanism
+       for (const auto& it: metadata->references) {
+           for (const auto& ref: it.value()) {
+               lmp->citeme->add(ref + "\n");
+           }
+       }
+   }
+}
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
new file mode 100644
index 00000000000..3304aabc858
--- /dev/null
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -0,0 +1,56 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#include "lammps.h"
+
+#include <string>
+
+#include <torch/torch.h>
+#include <metatensor/torch.hpp>
+#include <metatomic/torch.hpp>
+
+
+#ifndef LMP_METATOMIC_TYPES_H
+#define LMP_METATOMIC_TYPES_H
+
+namespace LAMMPS_NS {
+
+struct PairMetatomicData {
+   PairMetatomicData(std::string length_unit, std::string energy_unit);
+
+   void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
+
+   // torch model in metatensor format
+   std::unique_ptr<torch::jit::Module> model;
+   // device to use for the calculations
+   torch::Device device;
+   // model capabilities, declared by the model
+   metatomic_torch::ModelCapabilities capabilities;
+   // run-time evaluation options, decided by this class
+   metatomic_torch::ModelEvaluationOptions evaluation_options;
+   // should metatomic check the data LAMMPS send to the model
+   // and the data the model returns?
+   bool check_consistency;
+   // whether pairs should be remapped, removing pairs between ghosts if there
+   // is an equivalent pair involving at least one local atom.
+   bool remap_pairs;
+   // how far away the model needs to know about neighbors
+   double max_cutoff;
+
+   // allocation cache for the selected atoms
+   torch::Tensor selected_atoms_values;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
new file mode 100644
index 00000000000..483689f8f74
--- /dev/null
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -0,0 +1,564 @@
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
+------------------------------------------------------------------------- */
+#include "pair_metatomic.h"
+#include "metatomic_types.h"
+
+#include "atom.h"
+#include "error.h"
+#include "force.h"
+#include "memory.h"
+#include "neighbor.h"
+#include "update.h"
+#include "comm.h"
+
+#include "neigh_list.h"
+#include "neigh_request.h"
+
+#include <torch/version.h>
+#include <torch/script.h>
+#include <torch/cuda.h>
+
+#if TORCH_VERSION_MAJOR >= 2
+    #include <torch/mps.h>
+#endif
+
+#include <memory>
+
+#include <metatensor/torch.hpp>
+#include <metatomic/torch.hpp>
+
+#include "metatomic_system.h"
+#include "metatomic_timer.h"
+
+using namespace LAMMPS_NS;
+
+PairMetatomic::PairMetatomic(LAMMPS *lmp):
+    Pair(lmp),
+    type_mapping(nullptr),
+    system_adaptor(nullptr)
+{
+    std::string energy_unit;
+    std::string length_unit;
+    if (strcmp(update->unit_style, "real") == 0) {
+        length_unit = "angstrom";
+        energy_unit = "kcal/mol";
+    } else if (strcmp(update->unit_style, "metal") == 0) {
+        length_unit = "angstrom";
+        energy_unit = "eV";
+    } else if (strcmp(update->unit_style, "si") == 0) {
+        length_unit = "meter";
+        energy_unit = "joule";
+    } else if (strcmp(update->unit_style, "electron") == 0) {
+        length_unit = "Bohr";
+        energy_unit = "Hartree";
+    } else {
+        error->all(FLERR, "unsupported units '{}' for pair metatomic ", update->unit_style);
+    }
+
+    // we might not be running a pure pair potential,
+    // so we can not compute virial as fdotr
+    this->no_virial_fdotr_compute = 1;
+
+    this->mta_data = new PairMetatomicData(std::move(length_unit), std::move(energy_unit));
+
+    // settings for metatomic pair style
+    this->single_enable = 0;
+    this->restartinfo = 0;
+    this->one_coeff = 1;
+    this->manybody_flag = 1;
+}
+
+PairMetatomic::~PairMetatomic() {
+    delete this->mta_data;
+
+    if (allocated) {
+        memory->destroy(setflag);
+        memory->destroy(cutsq);
+        memory->destroy(type_mapping);
+    }
+}
+
+// called when finding `pair_style metatensor` in the input
+void PairMetatomic::settings(int argc, char ** argv) {
+    if (argc == 0) {
+        error->all(FLERR, "expected at least 1 argument to pair_style metatomic, got {}", argc);
+    }
+
+    const char* model_path = argv[0];
+    const char* extensions_directory = nullptr;
+    const char* requested_device = nullptr;
+    for (int i=1; i<argc; i++) {
+        if (strcmp(argv[i], "check_consistency") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got nothing");
+            } else if (strcmp(argv[i + 1], "on") == 0) {
+                mta_data->check_consistency = true;
+            } else if (strcmp(argv[i + 1], "off") == 0) {
+                mta_data->check_consistency = false;
+            } else {
+                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got '{}'", argv[i + 1]);
+            }
+
+            i += 1;
+        } else if (strcmp(argv[i], "remap_pairs") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got nothing");
+            } else if (strcmp(argv[i + 1], "on") == 0) {
+                mta_data->remap_pairs = true;
+            } else if (strcmp(argv[i + 1], "off") == 0) {
+                mta_data->remap_pairs = false;
+            } else {
+                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got '{}'", argv[i + 1]);
+            }
+
+            i += 1;
+        } else if (strcmp(argv[i], "extensions") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected <path> after 'extensions' in pair_style metatomic, got nothing");
+            }
+            extensions_directory = argv[i + 1];
+            i += 1;
+        } else if (strcmp(argv[i], "device") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected string after 'device' in pair_style metatomic, got nothing");
+            }
+            requested_device = argv[i + 1];
+            i += 1;
+        } else {
+            error->all(FLERR, "unexpected argument to pair_style metatomic: '{}'", argv[i]);
+        }
+    }
+
+    // load the model and get it's capabilities (including supported devices)
+    mta_data->load_model(this->lmp, model_path, extensions_directory);
+
+    // Select the device to use based on the model's preference, the user choice
+    // and what's available.
+    this->pick_device(&mta_data->device, requested_device);
+
+    // move all data to the correct device
+    mta_data->model->to(mta_data->device);
+    mta_data->selected_atoms_values = mta_data->selected_atoms_values.to(mta_data->device);
+
+    auto message = "Running simulation on " + mta_data->device.str() + " device with " + mta_data->capabilities->dtype() + " data";
+    if (screen) {
+        fprintf(screen, "%s\n", message.c_str());
+    }
+    if (logfile) {
+        fprintf(logfile,"%s\n", message.c_str());
+    }
+
+    if (!allocated) {
+        allocate();
+    }
+}
+
+std::vector<torch::DeviceType> PairMetatomic::available_devices() {
+    auto devices = std::vector<torch::DeviceType>();
+    for (const auto& supported: this->mta_data->capabilities->supported_devices) {
+        if (supported == "cpu") {
+            devices.push_back(torch::kCPU);
+        } else if (supported == "cuda" && torch::cuda::is_available()) {
+            devices.push_back(torch::kCUDA);
+        } else if (supported == "mps") {
+            #if TORCH_VERSION_MAJOR >= 2
+            if (torch::mps::is_available()) {
+                devices.push_back(torch::kMPS);
+            }
+            #endif
+        } else {
+            error->warning(FLERR,
+                "the model declared support for unknown device '{}', it will be ignored", supported
+            );
+        }
+    }
+
+    if (devices.empty()) {
+        error->all(FLERR,
+            "failed to find a valid device for this model: "
+            "the model supports {}, none of these where available",
+            torch::str(this->mta_data->capabilities->supported_devices)
+        );
+    }
+
+    return devices;
+}
+
+void PairMetatomic::pick_device(torch::Device* device, const char* requested) {
+    auto available_devices = this->available_devices();
+
+    auto picked_device_type = torch::kCPU;
+    if (requested == nullptr) {
+        // no user request, pick the device the model prefers
+        picked_device_type = available_devices[0];
+    } else {
+        bool found_requested_device = false;
+        for (const auto& device_type: available_devices) {
+            if (device_type == torch::kCPU && strcmp(requested, "cpu") == 0) {
+                picked_device_type = device_type;
+                found_requested_device = true;
+                break;
+            } else if (device_type == torch::kCUDA && strcmp(requested, "cuda") == 0) {
+                picked_device_type = device_type;
+                found_requested_device = true;
+                break;
+            } else if (device_type == torch::kMPS && strcmp(requested, "mps") == 0) {
+                picked_device_type = device_type;
+                found_requested_device = true;
+                break;
+            }
+        }
+
+        if (!found_requested_device) {
+            error->all(FLERR,
+                "failed to find requested device ({}): it is either "
+                "not supported by this model or not available on this machine",
+                requested
+            );
+        }
+    }
+
+    if (picked_device_type == torch::kCUDA) {
+        // distribute GPUs between multiple MPI processes on the same node
+
+        // (1) get a MPI communicator for all processes on the current node
+        MPI_Comm local;
+        MPI_Comm_split_type(world, MPI_COMM_TYPE_SHARED, 0, MPI_INFO_NULL, &local);
+        // (2) get the rank of this MPI process on the current node
+        int local_rank;
+        MPI_Comm_rank(local, &local_rank);
+
+        int size;
+        MPI_Comm_size(local, &size);
+        if (size < torch::cuda::device_count()) {
+            if (comm->me == 0) {
+                error->warning(FLERR,
+                    "found {} CUDA-capable GPUs, but only {} MPI processes on the current node; the remaining GPUs will not be used",
+                    torch::cuda::device_count(), size
+                );
+            }
+        }
+
+        // (3) split GPUs between node-local processes using round-robin allocation
+        int gpu_to_use = local_rank % torch::cuda::device_count();
+        *device = torch::Device(picked_device_type, gpu_to_use);
+    } else {
+        *device = torch::Device(picked_device_type);
+    }
+}
+
+
+void PairMetatomic::allocate() {
+    allocated = 1;
+
+    // setflags stores whether the coeff for a given pair of atom types are known
+    setflag = memory->create(
+        setflag,
+        atom->ntypes + 1,
+        atom->ntypes + 1,
+        "pair:setflag"
+    );
+
+    for (int i = 1; i <= atom->ntypes; i++) {
+        for (int j = i; j <= atom->ntypes; j++) {
+            setflag[i][j] = 0;
+        }
+    }
+
+    // cutsq stores the squared cutoff for each pair
+    cutsq = memory->create(
+        cutsq,
+        atom->ntypes + 1,
+        atom->ntypes + 1,
+        "pair:cutsq"
+    );
+
+    // lammps_types_to_species stores the mapping from lammps atom types to
+    // the metatomic model species
+    type_mapping = memory->create(
+        type_mapping,
+        atom->ntypes + 1,
+        "PairMetatomic:type_mapping"
+    );
+
+    for (int i = 1; i <= atom->ntypes; i++) {
+        type_mapping[i] = -1;
+    }
+}
+
+double PairMetatomic::init_one(int, int) {
+    return mta_data->max_cutoff;
+}
+
+
+// called on pair_coeff
+void PairMetatomic::coeff(int argc, char ** argv) {
+    if (argc < 3 || strcmp(argv[0], "*") != 0 || strcmp(argv[1], "*") != 0) {
+        error->all(FLERR, "invalid pair_coeff, expected `pair_coeff * * <list of types>`");
+    }
+
+    if (atom->ntypes != argc - 2) {
+        error->all(FLERR,
+            "invalid pair_coeff, expected `pair_coeff * * <list of types>` with {} types",
+            atom->ntypes
+        );
+    }
+
+    for (int lammps_type=1; lammps_type<argc - 1; lammps_type++) {
+        int type = utils::inumeric(FLERR, argv[lammps_type + 1], true, lmp);
+        type_mapping[lammps_type] = type;
+    }
+
+    // mark all pairs coeffs as known
+    for (int i = 1; i <= atom->ntypes; i++) {
+        for (int j = 1; j <= atom->ntypes; j++) {
+            setflag[i][j] = 1;
+            setflag[j][i] = 1;
+        }
+    }
+}
+
+
+// called when the run starts
+void PairMetatomic::init_style() {
+    // Require newton pair on since we need to communicate forces accumulated on
+    // ghost atoms to neighboring domains. These forces contributions come from
+    // gradient of a local descriptor w.r.t. domain ghosts (periodic images
+    // ghosts are handled separately).
+    if (force->newton_pair != 1) {
+        error->all(FLERR, "Pair style metatomic requires newton pair on");
+    }
+
+    // get the model's interaction range
+    auto range = mta_data->capabilities->engine_interaction_range(mta_data->evaluation_options->length_unit());
+    if (range < 0) {
+        error->all(FLERR, "interaction_range is negative for this model");
+    } else if (!std::isfinite(range)) {
+        if (comm->nprocs > 1) {
+            error->all(FLERR,
+                "interaction_range is infinite for this model, "
+                "using multiple MPI domains is not supported"
+            );
+        }
+
+        // determine the maximal cutoff in the NL
+        auto requested_nl = mta_data->model->run_method("requested_neighbor_lists");
+        for (const auto& ivalue: requested_nl.toList()) {
+            auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
+            auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
+
+            mta_data->max_cutoff = std::max(mta_data->max_cutoff, cutoff);
+        }
+    } else {
+        mta_data->max_cutoff = range;
+    }
+
+    if (!std::isfinite(mta_data->max_cutoff)) {
+        error->all(FLERR,
+            "the largest cutoff of this model is infinite, "
+            "we can't compute the corresponding neighbor list"
+        );
+    }
+
+    // create system adaptor
+    auto options = MetatomicSystemOptions{
+        this->type_mapping,
+        mta_data->max_cutoff,
+        mta_data->check_consistency,
+    };
+    this->system_adaptor = std::make_unique<MetatomicSystemAdaptor>(lmp, options);
+
+    // We ask LAMMPS for a full neighbor lists because we need to know about
+    // ALL pairs, even if options->full_list() is false. We will then filter
+    // the pairs to only include each pair once where needed.
+    auto request = neighbor->add_request(this, NeighConst::REQ_FULL | NeighConst::REQ_GHOST);
+    request->set_cutoff(mta_data->max_cutoff);
+
+    // Translate from the metatomic neighbor lists requests to LAMMPS neighbor
+    // lists requests.
+    auto requested_nl = mta_data->model->run_method("requested_neighbor_lists");
+    for (const auto& ivalue: requested_nl.toList()) {
+        auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
+        auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
+        assert(cutoff <= mts_data->max_cutoff);
+
+        this->system_adaptor->add_nl_request(cutoff, options);
+    }
+}
+
+
+void PairMetatomic::init_list(int id, NeighList *ptr) {
+    this->mta_list = ptr;
+}
+
+
+void PairMetatomic::compute(int eflag, int vflag) {
+    if (std::getenv("LAMMPS_METATOMIC_PROFILE") != nullptr) {
+        MetatomicTimer::enable(true);
+    } else {
+        MetatomicTimer::enable(false);
+    }
+
+    auto _ = MetatomicTimer("PairMetatomic::compute");
+
+    if (eflag || vflag) {
+        ev_setup(eflag, vflag);
+    } else {
+        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
+    }
+
+    if (eflag_atom) {
+        mta_data->evaluation_options->outputs.at("energy")->per_atom = true;
+    } else {
+        mta_data->evaluation_options->outputs.at("energy")->per_atom = false;
+    }
+
+    auto dtype = torch::kFloat64;
+    if (mta_data->capabilities->dtype() == "float64") {
+        dtype = torch::kFloat64;
+    } else if (mta_data->capabilities->dtype() == "float32") {
+        dtype = torch::kFloat32;
+    } else {
+        error->all(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
+    }
+
+    // transform from LAMMPS to metatomic System
+    auto system = this->system_adaptor->system_from_lmp(
+        mta_list,
+        static_cast<bool>(vflag_global),
+        mta_data->remap_pairs,
+        dtype,
+        mta_data->device
+    );
+
+    // only run the calculation for atoms actually in the current domain
+    mta_data->selected_atoms_values.resize_({atom->nlocal, 2});
+    mta_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
+    auto options = mta_data->selected_atoms_values.options();
+    mta_data->selected_atoms_values.index_put_(
+        {torch::indexing::Slice(), 1},
+        torch::arange(atom->nlocal, options)
+    );
+
+    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system", "atom"}, mta_data->selected_atoms_values
+    );
+    mta_data->evaluation_options->set_selected_atoms(selected_atoms);
+
+    torch::IValue result_ivalue;
+    try {
+        auto _ = MetatomicTimer("running Model::forward");
+        result_ivalue = mta_data->model->forward({
+            std::vector<metatomic_torch::System>{system},
+            mta_data->evaluation_options,
+            mta_data->check_consistency
+        });
+    } catch (const std::exception& e) {
+        error->all(FLERR, "error evaluating the torch model: {}", e.what());
+    }
+
+    auto result = result_ivalue.toGenericDict();
+    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
+    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
+    auto energy_tensor = energy_block->values();
+
+    // compute forces/virial on device with backward propagation
+    {
+        // reset gradients to zero before calling backward
+        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
+        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
+
+        auto _ = MetatomicTimer("running Model::backward");
+        energy_tensor.backward(-torch::ones_like(energy_tensor));
+    }
+
+    {
+        auto _ = MetatomicTimer("storing model output in LAMMPS data structures");
+
+        // move results to cpu for storing
+        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
+        auto energy_samples = energy_block->samples();
+
+        // store the energy returned by the model
+        torch::Tensor global_energy;
+        if (eflag_atom) {
+            assert(energy_samples->size() == 2);
+            assert(energy_samples->names()[0] == "system");
+            assert(energy_samples->names()[1] == "atom");
+
+            auto samples_values = energy_samples->values().to(torch::kCPU);
+            auto samples = samples_values.accessor<int32_t, 2>();
+
+            int64_t n_atoms = atom->nlocal + atom->nghost;
+            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
+
+            auto energies = energy_detached.accessor<double, 2>();
+            for (int64_t i=0; i<energy_samples->count(); i++) {
+                assert(samples[i][0] == 0);
+                // handle potentially out of order samples in
+                // the per-atom energy tensor
+                auto atom_i = samples[i][1];
+                assert(atom_i < n_atoms);
+                eatom[atom_i] += energies[i][0];
+            }
+
+            global_energy = energy_detached.sum(0);
+            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
+        } else {
+            assert(energy_samples->size() == 1);
+            assert(energy_samples->names()[0] == "system");
+
+            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
+            global_energy = energy_detached.reshape({1});
+        }
+
+        if (eflag_global) {
+            eng_vdwl += global_energy.item<double>();
+        }
+
+        // store forces/virial
+        auto forces_tensor = this->system_adaptor->positions.grad();
+        assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
+
+        auto forces = forces_tensor.accessor<double, 2>();
+        for (int i=0; i<atom->nlocal + atom->nghost; i++) {
+            atom->f[i][0] += forces[i][0];
+            atom->f[i][1] += forces[i][1];
+            atom->f[i][2] += forces[i][2];
+        }
+
+        assert(!vflag_fdotr);
+
+        if (vflag_global) {
+            auto virial_tensor = this->system_adaptor->strain.grad();
+            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
+            auto predicted_virial = virial_tensor.accessor<double, 2>();
+
+            virial[0] += predicted_virial[0][0];
+            virial[1] += predicted_virial[1][1];
+            virial[2] += predicted_virial[2][2];
+
+            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
+            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
+            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
+        }
+
+        if (vflag_atom) {
+            error->all(FLERR, "per atom virial is not implemented");
+        }
+    }
+}
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
new file mode 100644
index 00000000000..3539e35a0b5
--- /dev/null
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -0,0 +1,72 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS Development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+#ifdef PAIR_CLASS
+// clang-format off
+PairStyle(metatomic, PairMetatomic);
+// clang-format on
+#else
+
+#ifndef LMP_PAIR_METATOMIC_H
+#define LMP_PAIR_METATOMIC_H
+
+#include "pair.h"
+
+#include <vector>
+
+// this is the actual namespace where `torch::Device` is defined
+namespace c10 {
+    class Device;
+
+    enum class DeviceType: int8_t;
+}
+
+namespace LAMMPS_NS {
+class MetatomicSystemAdaptor;
+struct PairMetatomicData;
+
+class PairMetatomic : public Pair {
+public:
+    PairMetatomic(class LAMMPS *);
+    ~PairMetatomic();
+
+    void compute(int, int) override;
+    void settings(int, char **) override;
+    void coeff(int, char **) override;
+    void init_style() override;
+    double init_one(int, int) override;
+    void init_list(int id, NeighList *ptr) override;
+
+    void allocate();
+
+protected:
+    // get the set of devices both available on the current machine and supported
+    // by the model
+    std::vector<c10::DeviceType> available_devices();
+
+    // pick the correct device to use from the user request (or nullptr) in
+    // `pair_style metatomic`
+    virtual void pick_device(c10::Device* device, const char* requested);
+
+    PairMetatomicData* mta_data;
+    NeighList *mta_list;
+
+    // mapping from LAMMPS types to metatomic types
+    int32_t *type_mapping;
+    // adaptor from LAMMPS system to metatomic's
+    std::unique_ptr<MetatomicSystemAdaptor> system_adaptor;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
+#endif
diff --git a/src/ML-METATOMIC/patch-torch.sh b/src/ML-METATOMIC/patch-torch.sh
new file mode 100755
index 00000000000..8ec7cafac0e
--- /dev/null
+++ b/src/ML-METATOMIC/patch-torch.sh
@@ -0,0 +1,45 @@
+#!/usr/bin/env bash
+
+# This pulls in the fix from https://github.com/pytorch/pytorch/pull/119945
+# until it is properly released
+
+set -eu
+
+TORCH_PREFIX=$1
+
+if [ -f "$TORCH_PREFIX/share/cmake/Caffe2/public/mkl.cmake" ]; then
+    MKL_CMAKE="$TORCH_PREFIX/share/cmake/Caffe2/public/mkl.cmake"
+elif [ -f "$TORCH_PREFIX/Caffe2/public/mkl.cmake" ]; then
+    MKL_CMAKE="$TORCH_PREFIX/Caffe2/public/mkl.cmake"
+else
+    echo "Failed to find mkl.cmake in '$TORCH_PREFIX'"
+    exit 1
+fi
+
+cat > "$MKL_CMAKE" << EOF
+
+find_package(MKL QUIET)
+
+if(TARGET caffe2::mkl)
+  return()
+endif()
+
+add_library(caffe2::mkl INTERFACE IMPORTED)
+target_include_directories(caffe2::mkl INTERFACE \${MKL_INCLUDE_DIR})
+target_link_libraries(caffe2::mkl INTERFACE \${MKL_LIBRARIES})
+foreach(MKL_LIB IN LISTS MKL_LIBRARIES)
+  if(EXISTS "\${MKL_LIB}")
+    get_filename_component(MKL_LINK_DIR "\${MKL_LIB}" DIRECTORY)
+    if(IS_DIRECTORY "\${MKL_LINK_DIR}")
+      target_link_directories(caffe2::mkl INTERFACE "\${MKL_LINK_DIR}")
+    endif()
+  endif()
+endforeach()
+
+# TODO: This is a hack, it will not pick up architecture dependent
+# MKL libraries correctly; see https://github.com/pytorch/pytorch/issues/73008
+set_property(
+  TARGET caffe2::mkl PROPERTY INTERFACE_LINK_DIRECTORIES
+  \${MKL_ROOT}/lib \${MKL_ROOT}/lib/intel64 \${MKL_ROOT}/lib/intel64_win \${MKL_ROOT}/lib/win-x64)
+
+EOF
diff --git a/src/STUBS/mpi.cpp b/src/STUBS/mpi.cpp
index 22cbc9af171..e431837f344 100644
--- a/src/STUBS/mpi.cpp
+++ b/src/STUBS/mpi.cpp
@@ -378,6 +378,13 @@ int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *comm_out)
 
 /* ---------------------------------------------------------------------- */
 
+int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *comm_out) {
+  *comm_out = comm + 1;
+  return 0;
+}
+
+/* ---------------------------------------------------------------------- */
+
 int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *comm_out)
 {
   *comm_out = comm + 1;
diff --git a/src/STUBS/mpi.h b/src/STUBS/mpi.h
index b89c098bad4..e65199f6e97 100644
--- a/src/STUBS/mpi.h
+++ b/src/STUBS/mpi.h
@@ -58,6 +58,7 @@
 #define MPI_STATUS_IGNORE NULL
 
 #define MPI_Comm int
+#define MPI_Info int
 #define MPI_Request int
 #define MPI_Datatype int
 #define MPI_Op int
@@ -65,6 +66,11 @@
 #define MPI_Group int
 #define MPI_Offset long
 
+#define MPI_INFO_NULL 0
+
+// TODO: should all the COMM_TYPE be defined here?
+#define MPI_COMM_TYPE_SHARED 0xABCDEF01
+
 #define MPI_IN_PLACE NULL
 
 #define MPI_MAX_PROCESSOR_NAME 128
@@ -115,6 +121,7 @@ int MPI_Sendrecv(const void *sbuf, int scount, MPI_Datatype sdatatype, int dest,
 int MPI_Get_count(MPI_Status *status, MPI_Datatype datatype, int *count);
 
 int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *comm_out);
+int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *comm_out);
 int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *comm_out);
 int MPI_Comm_free(MPI_Comm *comm);
 MPI_Fint MPI_Comm_c2f(MPI_Comm comm);

From 45c279efe2bd6c5276c8a4a32237e8bb0a68b1a0 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 30 May 2025 16:09:15 +0200
Subject: [PATCH 02/37] Fix typos inside `assert`

---
 src/KOKKOS/pair_metatomic_kokkos.cpp | 4 ++--
 src/ML-METATOMIC/pair_metatomic.cpp  | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index a2d8546c2f0..a9c1f81fb11 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -81,7 +81,7 @@ void PairMetatomicKokkos<DeviceType>::init_style() {
     for (const auto& ivalue: requested_nl.toList()) {
         auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
         auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
-        assert(cutoff <= mts_data->max_cutoff);
+        assert(cutoff <= mta_data->max_cutoff);
 
         this->system_adaptor->add_nl_request(cutoff, options);
     }
@@ -208,7 +208,7 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
             auto samples = samples_values.accessor<int32_t, 2>();
 
             int64_t n_atoms = atom->nlocal + atom->nghost;
-            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
+            assert(samples_values.sizes() == mta_data->selected_atoms_values.sizes());
 
             auto energies = energy_detached.accessor<double, 2>();
             for (int64_t i=0; i<energy_samples->count(); i++) {
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 483689f8f74..5c16f096739 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -394,7 +394,7 @@ void PairMetatomic::init_style() {
     for (const auto& ivalue: requested_nl.toList()) {
         auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
         auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
-        assert(cutoff <= mts_data->max_cutoff);
+        assert(cutoff <= mta_data->max_cutoff);
 
         this->system_adaptor->add_nl_request(cutoff, options);
     }
@@ -504,7 +504,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
             auto samples = samples_values.accessor<int32_t, 2>();
 
             int64_t n_atoms = atom->nlocal + atom->nghost;
-            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
+            assert(samples_values.sizes() == mta_data->selected_atoms_values.sizes());
 
             auto energies = energy_detached.accessor<double, 2>();
             for (int64_t i=0; i<energy_samples->count(); i++) {

From 6be72131239b029fc061a5081064e51978307e7c Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 30 May 2025 16:18:03 +0200
Subject: [PATCH 03/37] Do not write to `lmp->citeme` if it does not exist

---
 src/ML-METATOMIC/metatomic_types.cpp | 10 ++++++----
 1 file changed, 6 insertions(+), 4 deletions(-)

diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 196ab1f464e..6ac27b2814c 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -88,10 +88,12 @@ void PairMetatomicData::load_model(
        }
 
        // add the model references to LAMMPS citation handling mechanism
-       for (const auto& it: metadata->references) {
-           for (const auto& ref: it.value()) {
-               lmp->citeme->add(ref + "\n");
-           }
+       if (lmp->citeme) {
+          for (const auto& it: metadata->references) {
+             for (const auto& ref: it.value()) {
+                lmp->citeme->add(ref + "\n");
+             }
+          }
        }
    }
 }

From 2cba1e9e2e15f1ab8d63b80f6eb297dfd5491e21 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Mon, 2 Jun 2025 17:49:46 +0200
Subject: [PATCH 04/37] Use the official metatomic 0.1.1 release

---
 cmake/Modules/Packages/ML-METATOMIC.cmake | 22 ++++++++--------------
 1 file changed, 8 insertions(+), 14 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index f187c7bc10a..f4fc7d1563c 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -47,11 +47,11 @@ set(METATENSOR_CORE_SHA1 "9e21c48d9059d8a37618958d9d253220dedf7562")
 set(METATENSOR_TORCH_VERSION "0.7.6")
 set(METATENSOR_TORCH_SHA1 "5668f5088a42507e9ca4a7b723b3baac0286035c")
 
-set(METATOMIC_TORCH_VERSION "0.1.0")
-set(METATOMIC_TORCH_SHA1 "a9d86ba4b9b6b8c367f9f21d3363e152b73833bf")
+set(METATOMIC_TORCH_VERSION "0.1.1")
+set(METATOMIC_TORCH_SHA1 "12b830c23674339fc185ce6e94e5a445416199ff")
 
 set(DOWNLOAD_METATENSOR_DEFAULT ON)
-find_package(metatensor_torch QUIET ${METATOMIC_TORCH_VERSION})
+find_package(metatensor_torch QUIET ${METATENSOR_TORCH_VERSION})
 if (metatensor_torch_FOUND)
     set(DOWNLOAD_METATENSOR_DEFAULT OFF)
 endif()
@@ -63,8 +63,8 @@ if (metatomic_torch_FOUND)
 endif()
 
 
-option(DOWNLOAD_METATOMIC "Download metatomic package instead of using an already installed one" ${DOWNLOAD_METATOMIC_DEFAULT})
 option(DOWNLOAD_METATENSOR "Download metatensor package instead of using an already installed one" ${DOWNLOAD_METATENSOR_DEFAULT})
+option(DOWNLOAD_METATOMIC "Download metatomic package instead of using an already installed one" ${DOWNLOAD_METATOMIC_DEFAULT})
 
 if (DOWNLOAD_METATENSOR)
     include(FetchContent)
@@ -93,22 +93,16 @@ endif()
 if (DOWNLOAD_METATOMIC)
     include(FetchContent)
 
-    # set(URL_BASE "https://github.com/metatensor/metatomic/releases/download")
-    # FetchContent_Declare(metatomic-torch
-    #     URL ${URL_BASE}/metatomic-torch-v${METATOMIC_TORCH_VERSION}/metatomic-torch-cxx-${METATOMIC_TORCH_VERSION}.tar.gz
-    #     URL_HASH SHA1=${METATOMIC_TORCH_SHA1}
-    # )
-
+    set(URL_BASE "https://github.com/metatensor/metatomic/releases/download")
     FetchContent_Declare(metatomic-torch
-        GIT_REPOSITORY https://github.com/Luthaf/metatomic
-        GIT_TAG c078c2ca8f9060f9a3a384b15ba464c416ff77d0
-        SOURCE_SUBDIR metatomic-torch
+        URL ${URL_BASE}/metatomic-torch-v${METATOMIC_TORCH_VERSION}/metatomic-torch-cxx-${METATOMIC_TORCH_VERSION}.tar.gz
+        URL_HASH SHA1=${METATOMIC_TORCH_SHA1}
     )
 
     message(STATUS "Fetching metatomic-torch v${METATOMIC_TORCH_VERSION} from github")
     FetchContent_MakeAvailable(metatomic-torch)
 else()
-    # make sure to fail the configuration if cmake can not find metatensor-torch
+    # make sure to fail the configuration if cmake can not find metatomic-torch
     find_package(metatomic_torch REQUIRED ${METATOMIC_TORCH_VERSION})
 endif()
 

From 4e2a98766a4fbb0610279a140cd6bbbfeddea6e4 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Mon, 2 Jun 2025 18:21:10 +0200
Subject: [PATCH 05/37] Fix remaining mentions of metatensor

---
 src/KOKKOS/metatomic_system_kokkos.cpp | 10 +++++-----
 1 file changed, 5 insertions(+), 5 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 2eb8b6ca5fb..9490ba24139 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -144,7 +144,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
     auto x = system->positions().detach();
     auto cell_inverse = system->cell().detach().inverse();
 
-    // convert from LAMMPS NL format to metatensor NL format
+    // convert from LAMMPS NL format to metatomic NL format
     auto expanded_arange = torch::arange(
         max_number_of_neighbors,
         torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
@@ -165,7 +165,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
     auto neighbors_original_id = original_id.index_select(0, neighbors_id);
 
     // The following code is a direct translation of the code in the non-Kokkos
-    // version (MetaTensorSystemAdaptor::setup_neighbors_remap), but rewritten
+    // version (MetatomicSystemAdaptor::setup_neighbors_remap), but rewritten
     // in torch to use the GPU
     for (auto& cache: caches_) {
         // current values of various tensors, these change depending on full/half setting
@@ -229,7 +229,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
                 auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
                 auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
                 auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
-                // reproduce this mask (from MetaTensorSystemAdaptor::setup_neighbors_remap) with torch:
+                // reproduce this mask (from MetatomicSystemAdaptor::setup_neighbors_remap) with torch:
                 // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
                 auto edge_mask = (
                     (torch::sum(cell_shifts, 1) == 0) & (
@@ -359,7 +359,7 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     // While Metatomic models can support mixed PBC settings, we currently
     // assume that the system is fully periodic and we throw an error otherwise
     if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-        error->all(FLERR, "metatensor/kk currently requires a fully periodic system");
+        error->all(FLERR, "metatomic/kk currently requires a fully periodic system");
     }
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
@@ -378,7 +378,7 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
         assert(kk_list != nullptr);
         this->setup_neighbors_remap_kk(system, kk_list);
     } else {
-        error->all(FLERR, "the kokkos version of metatensor requires remap_pairs to be true");
+        error->all(FLERR, "the kokkos version of metatomic requires remap_pairs to be true");
     }
 
     return system;

From 4014cda7822d29111861e084ecbd67bdc8fb0358 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Mon, 2 Jun 2025 18:27:57 +0200
Subject: [PATCH 06/37] =?UTF-8?q?Remove=20patch=20file,=20it=20should=20no?=
 =?UTF-8?q?t=20have=20been=20commited=20=E2=80=A6?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 metatensor.patch | 4127 ----------------------------------------------
 1 file changed, 4127 deletions(-)
 delete mode 100644 metatensor.patch

diff --git a/metatensor.patch b/metatensor.patch
deleted file mode 100644
index 193a49fe96e..00000000000
--- a/metatensor.patch
+++ /dev/null
@@ -1,4127 +0,0 @@
-diff --git a/cmake/CMakeLists.txt b/cmake/CMakeLists.txt
-index f22fa401a2..b87e45aa0b 100644
---- a/cmake/CMakeLists.txt
-+++ b/cmake/CMakeLists.txt
-@@ -162,7 +162,7 @@ endif()
- if(CMAKE_CXX_STANDARD LESS 17)
-   message(WARNING "Selecting C++17 standard is preferred over C++${CMAKE_CXX_STANDARD}")
- endif()
--if(PKG_KOKKOS AND (CMAKE_CXX_STANDARD LESS 17))
-+if((PKG_KOKKOS OR PKG_ML-METATENSOR) AND (CMAKE_CXX_STANDARD LESS 17))
-   set(CMAKE_CXX_STANDARD 17)
- endif()
- # turn off C++17 check in lmptype.h
-@@ -324,6 +324,7 @@ set(STANDARD_PACKAGES
-   MISC
-   ML-HDNNP
-   ML-IAP
-+  ML-METATENSOR
-   ML-PACE
-   ML-POD
-   ML-QUIP
-@@ -605,7 +606,7 @@ else()
- endif()
-
- foreach(PKG_WITH_INCL KSPACE PYTHON ML-IAP VORONOI COLVARS ML-HDNNP MDI MOLFILE NETCDF
--        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE LEPTON EXTRA-COMMAND)
-+        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE ML-METATENSOR LEPTON EXTRA-COMMAND)
-   if(PKG_${PKG_WITH_INCL})
-     include(Packages/${PKG_WITH_INCL})
-   endif()
-diff --git a/cmake/Modules/Packages/KOKKOS.cmake b/cmake/Modules/Packages/KOKKOS.cmake
-index f878db654c..c638a49398 100644
---- a/cmake/Modules/Packages/KOKKOS.cmake
-+++ b/cmake/Modules/Packages/KOKKOS.cmake
-@@ -203,6 +203,10 @@ if(PKG_ML-IAP)
-   endif()
- endif()
-
-+if(PKG_ML-METATENSOR)
-+  list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/metatensor_system_kokkos.cpp)
-+endif()
-+
- if(PKG_PHONON)
-   list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/dynamical_matrix_kokkos.cpp)
-   list(APPEND KOKKOS_PKG_SOURCES ${KOKKOS_PKG_SOURCES_DIR}/third_order_kokkos.cpp)
-diff --git a/cmake/Modules/Packages/ML-METATENSOR.cmake b/cmake/Modules/Packages/ML-METATENSOR.cmake
-new file mode 100644
-index 0000000000..dedc940894
---- /dev/null
-+++ b/cmake/Modules/Packages/ML-METATENSOR.cmake
-@@ -0,0 +1,84 @@
-+# metatensor requires C++17 due to Torch requiring C++17
-+if(CMAKE_CXX_STANDARD LESS 17)
-+  message(FATAL_ERROR "The ML-METATENSOR package requires the C++ standard to
-+be set to at least C++17")
-+endif()
-+
-+if (BUILD_OMP AND APPLE)
-+    message(FATAL_ERROR
-+        "Can not enable both BUILD_OMP and PGK_ML-METATENSOR on Apple systems, "
-+        "since this results in two different versions of the OpenMP library (one "
-+        "from the system and one from Torch) being linked to the final "
-+        "executable, which then crashes"
-+    )
-+endif()
-+
-+# Bring the `torch` target in scope to allow evaluation
-+# of cmake generator expression from `metatensor_torch`
-+find_package(Torch REQUIRED)
-+
-+# The caffe2::mkl target contains MKL_INCLUDE_DIR in it's
-+# INTERFACE_INCLUDE_DIRECTORIES even if MKL was not found, causing a build
-+# failure with "Imported target "torch" includes non-existent path" down the
-+# line. This code removes the missing path from INTERFACE_INCLUDE_DIRECTORIES,
-+# allowing the build to continue further.
-+if (TARGET caffe2::mkl)
-+    get_target_property(CAFFE2_MKL_INCLUDE_DIRECTORIES caffe2::mkl INTERFACE_INCLUDE_DIRECTORIES)
-+    set(MKL_INCLUDE_DIR_NOTFOUND "")
-+    foreach(_include_dir_ ${CAFFE2_MKL_INCLUDE_DIRECTORIES})
-+        if ("${_include_dir_}" MATCHES "MKL_INCLUDE_DIR-NOTFOUND")
-+            set(MKL_INCLUDE_DIR_NOTFOUND "${_include_dir_}")
-+        endif()
-+    endforeach()
-+
-+    if (NOT "${MKL_INCLUDE_DIR_NOTFOUND}" STREQUAL "")
-+        list(REMOVE_ITEM CAFFE2_MKL_INCLUDE_DIRECTORIES "${MKL_INCLUDE_DIR_NOTFOUND}")
-+    endif()
-+    set_target_properties(caffe2::mkl PROPERTIES
-+        INTERFACE_INCLUDE_DIRECTORIES "${CAFFE2_MKL_INCLUDE_DIRECTORIES}"
-+    )
-+endif()
-+
-+########### definition of metatensor and metatensor-torch targets ###########
-+
-+set(METATENSOR_CORE_VERSION "0.1.12")
-+set(METATENSOR_TORCH_VERSION "0.7.3")
-+
-+set(DOWNLOAD_METATENSOR_DEFAULT ON)
-+find_package(metatensor_torch QUIET ${METATENSOR_TORCH_VERSION})
-+if (metatensor_torch_FOUND)
-+    set(DOWNLOAD_METATENSOR_DEFAULT OFF)
-+endif()
-+
-+
-+option(DOWNLOAD_METATENSOR "Download metatensor package instead of using an already installed one" ${DOWNLOAD_METATENSOR_DEFAULT})
-+
-+if (DOWNLOAD_METATENSOR)
-+    include(FetchContent)
-+
-+    set(URL_BASE "https://github.com/lab-cosmo/metatensor/releases/download")
-+
-+    FetchContent_Declare(metatensor
-+        URL ${URL_BASE}/metatensor-core-v${METATENSOR_CORE_VERSION}/metatensor-core-cxx-${METATENSOR_CORE_VERSION}.tar.gz
-+        URL_HASH SHA1=aec0963624f7fcd470e71471eb22b8912aec912e
-+    )
-+
-+    message(STATUS "Fetching metatensor v${METATENSOR_CORE_VERSION} from github")
-+    FetchContent_MakeAvailable(metatensor)
-+
-+    FetchContent_Declare(metatensor-torch
-+        URL ${URL_BASE}/metatensor-torch-v${METATENSOR_TORCH_VERSION}/metatensor-torch-cxx-${METATENSOR_TORCH_VERSION}.tar.gz
-+        URL_HASH SHA1=26f989650d29008ab640aa6bdea706f88adc4fba
-+    )
-+
-+    message(STATUS "Fetching metatensor-torch v${METATENSOR_TORCH_VERSION} from github")
-+    FetchContent_MakeAvailable(metatensor-torch)
-+else()
-+    # make sure to fail the configuration if cmake can not find metatensor-torch
-+    find_package(metatensor_torch REQUIRED ${METATENSOR_TORCH_VERSION})
-+endif()
-+
-+
-+################ lammps target modifications ################
-+
-+target_link_libraries(lammps PRIVATE metatensor_torch)
-diff --git a/cmake/presets/all_off.cmake b/cmake/presets/all_off.cmake
-index f2f5782480..7ad382b94f 100644
---- a/cmake/presets/all_off.cmake
-+++ b/cmake/presets/all_off.cmake
-@@ -56,6 +56,7 @@ set(ALL_PACKAGES
-   MISC
-   ML-HDNNP
-   ML-IAP
-+  ML-METATENSOR
-   ML-PACE
-   ML-POD
-   ML-QUIP
-diff --git a/cmake/presets/all_on.cmake b/cmake/presets/all_on.cmake
-index 8dc4632138..b09f8bbf68 100644
---- a/cmake/presets/all_on.cmake
-+++ b/cmake/presets/all_on.cmake
-@@ -58,6 +58,7 @@ set(ALL_PACKAGES
-   MISC
-   ML-HDNNP
-   ML-IAP
-+  ML-METATENSOR
-   ML-PACE
-   ML-POD
-   ML-QUIP
-diff --git a/cmake/presets/nolib.cmake b/cmake/presets/nolib.cmake
-index 4a4a557505..4ebfd9568f 100644
---- a/cmake/presets/nolib.cmake
-+++ b/cmake/presets/nolib.cmake
-@@ -16,6 +16,7 @@ set(PACKAGES_WITH_LIB
-   MACHDYN
-   MDI
-   ML-HDNNP
-+  ML-METATENSOR
-   ML-PACE
-   ML-QUIP
-   MOLFILE
-diff --git a/doc/src/Build_extras.rst b/doc/src/Build_extras.rst
-index 26cf776f4d..ce32ad4253 100644
---- a/doc/src/Build_extras.rst
-+++ b/doc/src/Build_extras.rst
-@@ -51,6 +51,7 @@ This is the list of packages that may require additional steps.
-    * :ref:`MISC <misc>`
-    * :ref:`ML-HDNNP <ml-hdnnp>`
-    * :ref:`ML-IAP <mliap>`
-+   * :ref:`ML-METATENSOR <metatensor>`
-    * :ref:`ML-PACE <ml-pace>`
-    * :ref:`ML-POD <ml-pod>`
-    * :ref:`ML-QUIP <ml-quip>`
-@@ -1071,6 +1072,99 @@ Python version 3.6 or later.
-
- ----------
-
-+.. _metatensor:
-+
-+ML-METATENSOR package
-+---------------------
-+
-+Building the ML-METATENSOR package requires three external dependencies: the C++
-+version of ``libtorch``, the core ``metatensor`` library, and the
-+``metatensor-torch`` library. You'll need to install ``libtorch`` manually,
-+either by installing PyTorch with a Python package manager (``pip`` or
-+``conda``), or by downloading the right prebuilt version of the code from
-+https://pytorch.org/get-started/locally/.
-+
-+.. TODO: We should allow users to build the code with a different
-+.. installation of metatensor/metatensor-torch, in particular pre-built
-+.. versions from pip or conda.
-+
-+
-+.. tabs::
-+
-+   .. tab:: CMake build
-+
-+      If you use the CMake build system of LAMMPS, ``metatensor`` and
-+      ``metatensor-torch`` will automatically be downloaded and built for you,
-+      using a compatible version for the current code. Building the core
-+      ``metatensor`` library this way requires a `Rust <https://rust-lang.org>`_
-+      compiler (version 1.65 or higher), which you can get using `rustup
-+      <https://rustup.rs/>`_.
-+
-+      First, you should run the following code in a bash (or bash-compatible)
-+      shell to tell CMake where to find ``libtorch``:
-+
-+      .. code-block:: bash
-+
-+         # point this to the path where you extracted the C++ libtorch
-+         TORCH_PREFIX=<path/to/torch/installation>
-+         # if you used Python to install torch, you can do this:
-+         TORCH_PREFIX=$(python -c "import torch; print(torch.utils.cmake_prefix_path)")
-+
-+         # patch a bug from torch's MKL detection
-+         cd <path/to/LAMMPS/sources>
-+         ./src/ML-METATENSOR/patch-torch.sh "$TORCH_PREFIX"
-+
-+
-+      Once PyTorch has been installed and patched, you'll need to use the
-+      following CMake options:
-+
-+      .. code-block:: bash
-+
-+         -DPKG_ML-METATENSOR=ON
-+         -DCMAKE_PREFIX_PATH="$TORCH_PREFIX"
-+         -DLAMMPS_INSTALL_RPATH=ON
-+
-+      By default, this code will try to find the metatensor libraries on your
-+      system and use them. If cmake can not find the libraries, it will download
-+      and build them as part of the main LAMMPS build. If you want, you can
-+      control this behavior using `-DDOWNLOAD_METATENSOR=ON` to always force a
-+      download and `-DDOWNLOAD_METATENSOR=OFF` to prevent any download.
-+
-+   .. tab:: Traditional make
-+
-+      You can either download and build metatensor (and it's dependencies)
-+      inside the `lib/metatensor` folder or use previously installed libraries
-+      and point LAMMPS to their location.
-+
-+      All the dependencies can be automatically downloaded and built from the
-+      `src` folder with the followig make arguments:
-+
-+      .. code-block:: bash
-+
-+         make lib-metatensor           # print help message
-+         make lib-metatensor args="-b" # download dependencies in lib/metatensor, and create the corresponding Makefile.lammps
-+
-+      Once this is done, you can install the metatensor package and compile
-+      LAMMPS in the usual manner:
-+
-+      .. code-block:: bash
-+
-+         make yes-metatensor
-+         make <machine>
-+
-+   .. tab:: Metatensor and Kokkos
-+
-+      The metatensor-kokkos interface should be compiled as
-+
-+      .. code-block:: bash
-+
-+         cmake ../cmake/ -DPKG_KOKKOS=ON -DKokkos_ENABLE_CUDA=ON -DPKG_ML-METATENSOR=ON -DCMAKE_PREFIX_PATH=/.../libtorch/share/cmake/
-+
-+      where ``/.../libtorch/`` is the path to a libtorch C++11 ABI distribution (which can be downloaded from https://pytorch.org/get-started/locally/).
-+      The OpenMP version (as opposed to the CUDA version) can be enabled with -DKokkos_ENABLE_OPENMP=ON instead of -DKokkos_ENABLE_CUDA=ON
-+
-+----------
-+
- .. _opt:
-
- OPT package
-diff --git a/doc/src/Commands_pair.rst b/doc/src/Commands_pair.rst
-index 048a54ed37..da5a661a1d 100644
---- a/doc/src/Commands_pair.rst
-+++ b/doc/src/Commands_pair.rst
-@@ -201,6 +201,7 @@ OPT.
-    * :doc:`meam/sw/spline <pair_meam_sw_spline>`
-    * :doc:`mesocnt <pair_mesocnt>`
-    * :doc:`mesocnt/viscous <pair_mesocnt>`
-+   * :doc:`metatensor <pair_metatensor>`
-    * :doc:`mgpt <pair_mgpt>`
-    * :doc:`mie/cut (g) <pair_mie>`
-    * :doc:`mliap (k) <pair_mliap>`
-diff --git a/doc/src/Packages_details.rst b/doc/src/Packages_details.rst
-index 870dc8fbf7..173d58def9 100644
---- a/doc/src/Packages_details.rst
-+++ b/doc/src/Packages_details.rst
-@@ -80,6 +80,7 @@ gives those details.
-    * :ref:`MISC <PKG-MISC>`
-    * :ref:`ML-HDNNP <PKG-ML-HDNNP>`
-    * :ref:`ML-IAP <PKG-ML-IAP>`
-+   * :ref:`ML-METATENSOR <PKG-ML-METATENSOR>`
-    * :ref:`ML-PACE <PKG-ML-PACE>`
-    * :ref:`ML-POD <PKG-ML-POD>`
-    * :ref:`ML-QUIP <PKG-ML-QUIP>`
-@@ -1791,6 +1792,37 @@ therefore also needs to be installed to run those examples.
-
- ----------
-
-+.. _PKG-ML-METATENSOR:
-+
-+ML-METATENSOR package
-+---------------------
-+
-+**Contents:**
-+
-+This package provides a pair style which allow using arbitrary machine learning
-+models that follow the `metatensor interface`_. These models are based on
-+`PyTorch`_ and can predict the energy of a system using a variety of machine
-+learning technics. Users can defined and train their own models with fully
-+custom Python code, use separate packages such as `metatensor-models`_ to train
-+existing architectures with their own dataset; or use pre-trained models
-+provided by others.
-+
-+.. _metatensor interface: https://docs.metatensor.org/latest/atomistic/index.html
-+.. _PyTorch: https://pytorch.org/
-+.. _metatensor-models: https://github.com/lab-cosmo/metatensor-models/
-+
-+**Author:** Guillaume Fraux (EPFL)
-+
-+.. versionadded:: TBD
-+
-+**Supporting info:**
-+
-+* src/ML-METATENSOR: filenames -> commands
-+* :doc:`pair_style metatensor <pair_metatensor>`
-+* examples/metatensor
-+
-+----------
-+
- .. _PKG-ML-PACE:
-
- ML-PACE package
-diff --git a/doc/src/Packages_list.rst b/doc/src/Packages_list.rst
-index e1b4af694c..8094db114f 100644
---- a/doc/src/Packages_list.rst
-+++ b/doc/src/Packages_list.rst
-@@ -298,6 +298,11 @@ whether an extra library is needed to build and use the package:
-      - :doc:`pair_style mliap <pair_mliap>`
-      - mliap
-      - no
-+   * - :ref:`ML-METATENSOR <PKG-ML-METATENSOR>`
-+     - interface to metatensor powered machine-learning potentials
-+     - :doc:`pair_style metatensor <pair_metatensor>`
-+     - metatensor
-+     - ext
-    * - :ref:`ML-PACE <PKG-ML-PACE>`
-      - Atomic Cluster Expansion potential
-      - :doc:`pair pace <pair_pace>`
-diff --git a/doc/src/pair_metatensor.rst b/doc/src/pair_metatensor.rst
-new file mode 100644
-index 0000000000..fa89291796
---- /dev/null
-+++ b/doc/src/pair_metatensor.rst
-@@ -0,0 +1,105 @@
-+.. index:: pair_style metatensor
-+
-+pair_style metatensor command
-+=============================
-+
-+Accelerator Variants: *metatensor/kk*
-+
-+Syntax
-+""""""
-+
-+.. code-block:: LAMMPS
-+
-+   pair_style metatensor model_path ... keyword values ...
-+
-+* model_path = path to the file containing the exported metatensor model
-+* keyword = *device* or *extensions* or *check_consistency*
-+
-+  .. parsed-literal::
-+
-+       *device* values = device_name
-+         device_name = name of the Torch device to use for the calculations
-+       *extensions* values = directory
-+         directory = path to a directory containing TorchScript extensions as
-+         shared libraries. If the model uses extensions, we will try to load
-+         them from this directory first
-+       *check_consistency* values = on or off
-+         set this to on/off to enable/disable internal consistency checks,
-+         verifying both the data passed by LAMMPS to the model, and the data
-+         returned by the model to LAMMPS.
-+
-+Examples
-+""""""""
-+
-+.. code-block:: LAMMPS
-+
-+   pair_style metatensor exported-model.pt device cuda extensions /home/user/torch-extensions/
-+   pair_style metatensor soap-gap.pt check_consistency on
-+   pair_coeff * * 6 8 1
-+
-+Description
-+"""""""""""
-+
-+Pair style *metatensor* provides access to models following `metatensor's
-+atomistic models <https://docs.metatensor.org/latest/atomistic/index.html>`
-+interface; and enable using such models as interatomic potentials to drive a
-+LAMMPS simulation. The models can be fully defined and trained by the user using
-+Python code, or be existing pre-trained models. The interface can be used with
-+any type of machine learning model, as long as the implementation of the model
-+is compatible with TorchScript.
-+
-+The only required argument for *pair_style metatensor* is the path to the model
-+file, which should be an exported metatensor model.
-+
-+Optionally, users can define which torch *device* (e.g. cpu, cuda, cuda:0,
-+*etc.*) should be used to run the model. If this is not given, the code will run
-+on the best available device. If the model uses custom TorchScript operators
-+defined in a TorchScript extension, the shared library defining these extensions
-+will be searched in the *extensions* path, and loaded before trying to load the
-+model itself. Finally, *check_consistency* can be set to *on* or *off* to enable
-+(respectively disable) additional internal consistency checks in the data being
-+passed from LAMMPS to the model and back.
-+
-+A single *pair_coeff* command should be used with the *metatensor* style,
-+specifying the mapping from LAMMPS types to the atomic types the model can
-+handle. The first 2 arguments must be \* \* so as to span all LAMMPS atom types.
-+This is followed by a list of N arguments that specify the mapping of metatensor
-+atomic types to LAMMPS types, where N is the number of LAMMPS atom types.
-+
-+.. See the :doc:`pair_coeff <pair_coeff>` page for alternate ways
-+.. to specify the path for the *model* and *extensions*.
-+
-+
-+Mixing, shift, table, tail correction, restart, rRESPA info
-+"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
-+
-+This pair style does not support the :doc:`pair_modify <pair_modify>` shift,
-+table, and tail options.
-+
-+This pair style does not write its information to :doc:`binary restart files
-+<restart>`, since it is stored in model files.  Thus, you need to re-specify the
-+pair_style and pair_coeff commands in an input script that reads a restart file.
-+
-+This pair style can only be used via the *pair* keyword of the :doc:`run_style
-+respa <run_style>` command.  It does not support the *inner*, *middle*, *outer*
-+keywords.
-+
-+----------
-+
-+Restrictions
-+""""""""""""
-+
-+This pair style is part of the ML-METATENSOR package.  It is only enabled if
-+LAMMPS was built with that package. See the :doc:`Build package <Build_package>`
-+page for more info.
-+
-+
-+Related commands
-+""""""""""""""""
-+
-+:doc:`pair_coeff <pair_coeff>`
-+
-+Default
-+"""""""
-+
-+none
-diff --git a/doc/src/pair_style.rst b/doc/src/pair_style.rst
-index bdf06d6b66..546367abe5 100644
---- a/doc/src/pair_style.rst
-+++ b/doc/src/pair_style.rst
-@@ -294,6 +294,7 @@ accelerated styles exist.
- * :doc:`meam/sw/spline <pair_meam_sw_spline>` - Splined version of MEAM with a Stillinger-Weber term
- * :doc:`mesocnt <pair_mesocnt>` - Mesoscopic vdW potential for (carbon) nanotubes
- * :doc:`mesocnt/viscous <pair_mesocnt>` - Mesoscopic vdW potential for (carbon) nanotubes with friction
-+* :doc:`metatensor <pair_metatensor>` - interface to metatensor powered machine-learning potentials
- * :doc:`mgpt <pair_mgpt>` - Simplified model generalized pseudopotential theory (MGPT) potential
- * :doc:`mie/cut <pair_mie>` - Mie potential
- * :doc:`mliap <pair_mliap>` - Multiple styles of machine-learning potential
-diff --git a/examples/PACKAGES/metatensor/.gitignore b/examples/PACKAGES/metatensor/.gitignore
-new file mode 100644
-index 0000000000..d848bd9194
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/.gitignore
-@@ -0,0 +1,2 @@
-+collected-extensions/
-+nickel-lj-extensions.pt
-diff --git a/examples/PACKAGES/metatensor/create-lj-nickel.py b/examples/PACKAGES/metatensor/create-lj-nickel.py
-new file mode 100644
-index 0000000000..08752dd705
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/create-lj-nickel.py
-@@ -0,0 +1,27 @@
-+# https://github.com/Luthaf/metatensor-lj-test/
-+import metatensor_lj_test
-+
-+
-+model = metatensor_lj_test.lennard_jones_model(
-+    atomic_type=28,
-+    cutoff=6.5,
-+    sigma=1.5808,
-+    epsilon=0.1729,
-+    length_unit="Angstrom",
-+    energy_unit="eV",
-+    with_extension=False,
-+)
-+
-+model.save("nickel-lj.pt")
-+
-+
-+model = metatensor_lj_test.lennard_jones_model(
-+    atomic_type=28,
-+    cutoff=6.5,
-+    sigma=1.5808,
-+    epsilon=0.1729,
-+    length_unit="Angstrom",
-+    energy_unit="eV",
-+    with_extension=True,
-+)
-+model.save("nickel-lj-extensions.pt", collect_extensions="collected-extensions/")
-diff --git a/examples/PACKAGES/metatensor/in.kokkos.metatensor b/examples/PACKAGES/metatensor/in.kokkos.metatensor
-new file mode 100644
-index 0000000000..2ca2abf127
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/in.kokkos.metatensor
-@@ -0,0 +1,31 @@
-+# Use the correct kokkos settings. `neigh half` does not imply the use of a half
-+# neighbor list, only a change in how contributions are summed together.
-+# cf https://github.com/lammps/lammps/pull/4412
-+package kokkos newton on neigh half
-+
-+units metal
-+boundary p p p
-+
-+atom_style atomic/kk
-+lattice fcc 3.6
-+region box block 0 2 0 2 0 2
-+create_box 1 box
-+create_atoms 1 box
-+
-+mass 1 58.693
-+
-+velocity all create 123 42
-+
-+pair_style metatensor/kk nickel-lj.pt
-+pair_coeff * * 28
-+
-+timestep 0.001
-+run_style verlet/kk
-+fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
-+
-+thermo 10
-+thermo_style custom step temp pe etotal press vol
-+
-+# dump 1 all atom 10 dump.metatensor
-+
-+run 100
-diff --git a/examples/PACKAGES/metatensor/in.metatensor b/examples/PACKAGES/metatensor/in.metatensor
-new file mode 100644
-index 0000000000..59a32c89e4
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/in.metatensor
-@@ -0,0 +1,27 @@
-+units metal
-+boundary p p p
-+
-+atom_style atomic
-+lattice fcc 3.6
-+region box block 0 2 0 2 0 2
-+create_box 1 box
-+create_atoms 1 box
-+
-+labelmap atom 1 Ni
-+mass Ni 58.693
-+
-+velocity all create 123 42
-+
-+pair_style metatensor nickel-lj.pt
-+# pair_style metatensor nickel-lj-extensions.pt extensions collected-extensions/
-+pair_coeff * * 28
-+
-+timestep 0.001
-+fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
-+
-+thermo 10
-+thermo_style custom step temp pe etotal press vol
-+
-+# dump 1 all atom 10 dump.metatensor
-+
-+run 100
-diff --git a/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.1 b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.1
-new file mode 100644
-index 0000000000..e400bfa088
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.1
-@@ -0,0 +1,135 @@
-+LAMMPS (17 Apr 2024 - Development - patch_17Apr2024-557-gef1630afd2)
-+  using 1 OpenMP thread(s) per MPI task
-+units metal
-+boundary p p p
-+
-+atom_style atomic
-+lattice fcc 3.6
-+Lattice spacing in x,y,z = 3.6 3.6 3.6
-+region box block 0 2 0 2 0 2
-+create_box 1 box
-+Created orthogonal box = (0 0 0) to (7.2 7.2 7.2)
-+  1 by 1 by 1 MPI processor grid
-+create_atoms 1 box
-+Created 32 atoms
-+  using lattice units in orthogonal box = (0 0 0) to (7.2 7.2 7.2)
-+  create_atoms CPU = 0.000 seconds
-+
-+labelmap atom 1 Ni
-+mass Ni 58.693
-+
-+velocity all create 123 42
-+
-+pair_style metatensor nickel-lj.pt
-+
-+This is the Test Lennard-Jones model
-+====================================
-+
-+Minimal shifted Lennard-Jones potential, to be used when testing the
-+integration of metatensor atomistic models with various simulation engines.
-+
-+Model authors
-+-------------
-+
-+- Guillaume Fraux <guillaume.fraux@epfl.ch>
-+
-+Model references
-+----------------
-+
-+Please cite the following references when using this model:
-+- about this specific model:
-+  * https://github.com/luthaf/metatensor-lj-test
-+- about the implementation of this model:
-+  * https://github.com/lab-cosmo/metatensor
-+
-+Running simulation on cpu device with float64 data
-+# pair_style metatensor nickel-lj-extensions.pt extensions collected-extensions/
-+pair_coeff * * 28
-+
-+timestep 0.001
-+fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
-+fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 $(1000 * dt) drag 1.0
-+fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 1 drag 1.0
-+
-+thermo 10
-+thermo_style custom step temp pe etotal press vol
-+
-+# dump 1 all atom 10 dump.metatensor
-+
-+run 100
-+
-+CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
-+
-+Your simulation uses code contributions which should be cited:
-+
-+- Type Label Framework: https://doi.org/10.1021/acs.jpcb.3c08419
-+
-+@Article{Gissinger24,
-+ author = {Jacob R. Gissinger, Ilia Nikiforov, Yaser Afshar, Brendon Waters, Moon-ki Choi, Daniel S. Karls, Alexander Stukowski, Wonpil Im, Hendrik Heinz, Axel Kohlmeyer, and Ellad B. Tadmor},
-+ title = {Type Label Framework for Bonded Force Fields in LAMMPS},
-+ journal = {J. Phys. Chem. B},
-+ year =    2024,
-+ volume =  128,
-+ number =  13,
-+ pages =   {3282–-3297}
-+}
-+
-+- https://github.com/lab-cosmo/metatensor
-+- https://github.com/luthaf/metatensor-lj-test
-+CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
-+
-+Generated 0 of 0 mixed pair_coeff terms from geometric mixing rule
-+Neighbor list info ...
-+  update: every = 1 steps, delay = 0 steps, check = yes
-+  max neighbors/atom: 2000, page size: 100000
-+  master list distance cutoff = 8.5
-+  ghost atom cutoff = 8.5
-+  binsize = 4.25, bins = 2 2 2
-+  1 neighbor lists, perpetual/occasional/extra = 1 0 0
-+  (1) pair metatensor, perpetual
-+      attributes: full, newton on, ghost
-+      pair build: full/bin/ghost
-+      stencil: full/ghost/bin/3d
-+      bin: standard
-+Per MPI rank memory allocation (min/avg/max) = 3.377 | 3.377 | 3.377 Mbytes
-+   Step          Temp          PotEng         TotEng         Press          Volume
-+         0   123           -8.2814195     -7.7885506     -67585.536      373.248
-+        10   124.8498      -8.395127      -7.8948458     -68884.117      370.7507
-+        20   130.60229     -8.7447028     -8.221371      -72913.372      363.3685
-+        30   140.95014     -9.3595663     -8.79477       -80162.936      351.36119
-+        40   157.33663     -10.29346      -9.6630017     -91879.643      335.18851
-+        50   181.74279     -11.619487     -10.891232     -108735.54      315.60425
-+        60   216.75162     -13.405317     -12.536779     -131438.83      293.736
-+        70   264.39963     -15.685874     -14.626408     -160402.97      270.99304
-+        80   319.4713      -18.40371      -17.123568     -192237.03      248.74525
-+        90   350.37789     -21.272294     -19.868307     -215596.99      227.98439
-+       100   298.01005     -23.674365     -22.48022      -206922.9       209.26415
-+Loop time of 4.01198 on 1 procs for 100 steps with 32 atoms
-+
-+Performance: 2.154 ns/day, 11.144 hours/ns, 24.925 timesteps/s, 797.611 atom-step/s
-+99.4% CPU use with 1 MPI tasks x 1 OpenMP threads
-+
-+MPI task timing breakdown:
-+Section |  min time  |  avg time  |  max time  |%varavg| %total
-+---------------------------------------------------------------
-+Pair    | 3.9962     | 3.9962     | 3.9962     |   0.0 | 99.61
-+Neigh   | 0.01366    | 0.01366    | 0.01366    |   0.0 |  0.34
-+Comm    | 0.00055756 | 0.00055756 | 0.00055756 |   0.0 |  0.01
-+Output  | 0.00016915 | 0.00016915 | 0.00016915 |   0.0 |  0.00
-+Modify  | 0.001224   | 0.001224   | 0.001224   |   0.0 |  0.03
-+Other   |            | 0.00021    |            |       |  0.01
-+
-+Nlocal:             32 ave          32 max          32 min
-+Histogram: 1 0 0 0 0 0 0 0 0 0
-+Nghost:           1655 ave        1655 max        1655 min
-+Histogram: 1 0 0 0 0 0 0 0 0 0
-+Neighs:              0 ave           0 max           0 min
-+Histogram: 1 0 0 0 0 0 0 0 0 0
-+FullNghs:        11490 ave       11490 max       11490 min
-+Histogram: 1 0 0 0 0 0 0 0 0 0
-+
-+Total # of neighbors = 11490
-+Ave neighs/atom = 359.0625
-+Neighbor list builds = 2
-+Dangerous builds = 0
-+Total wall time: 0:00:04
-diff --git a/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.4 b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.4
-new file mode 100644
-index 0000000000..d6dbff0d78
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/log.26Jun2024.metatensor.g++.4
-@@ -0,0 +1,135 @@
-+LAMMPS (17 Apr 2024 - Development - patch_17Apr2024-557-gef1630afd2)
-+  using 1 OpenMP thread(s) per MPI task
-+units metal
-+boundary p p p
-+
-+atom_style atomic
-+lattice fcc 3.6
-+Lattice spacing in x,y,z = 3.6 3.6 3.6
-+region box block 0 2 0 2 0 2
-+create_box 1 box
-+Created orthogonal box = (0 0 0) to (7.2 7.2 7.2)
-+  1 by 2 by 2 MPI processor grid
-+create_atoms 1 box
-+Created 32 atoms
-+  using lattice units in orthogonal box = (0 0 0) to (7.2 7.2 7.2)
-+  create_atoms CPU = 0.001 seconds
-+
-+labelmap atom 1 Ni
-+mass Ni 58.693
-+
-+velocity all create 123 42
-+
-+pair_style metatensor nickel-lj.pt
-+
-+This is the Test Lennard-Jones model
-+====================================
-+
-+Minimal shifted Lennard-Jones potential, to be used when testing the
-+integration of metatensor atomistic models with various simulation engines.
-+
-+Model authors
-+-------------
-+
-+- Guillaume Fraux <guillaume.fraux@epfl.ch>
-+
-+Model references
-+----------------
-+
-+Please cite the following references when using this model:
-+- about this specific model:
-+  * https://github.com/luthaf/metatensor-lj-test
-+- about the implementation of this model:
-+  * https://github.com/lab-cosmo/metatensor
-+
-+Running simulation on cpu device with float64 data
-+# pair_style metatensor nickel-lj-extensions.pt extensions collected-extensions/
-+pair_coeff * * 28
-+
-+timestep 0.001
-+fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
-+fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 $(1000 * dt) drag 1.0
-+fix 1 all npt temp 123 123 0.10000000000000000555 iso 0 0 1 drag 1.0
-+
-+thermo 10
-+thermo_style custom step temp pe etotal press vol
-+
-+# dump 1 all atom 10 dump.metatensor
-+
-+run 100
-+
-+CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
-+
-+Your simulation uses code contributions which should be cited:
-+
-+- Type Label Framework: https://doi.org/10.1021/acs.jpcb.3c08419
-+
-+@Article{Gissinger24,
-+ author = {Jacob R. Gissinger, Ilia Nikiforov, Yaser Afshar, Brendon Waters, Moon-ki Choi, Daniel S. Karls, Alexander Stukowski, Wonpil Im, Hendrik Heinz, Axel Kohlmeyer, and Ellad B. Tadmor},
-+ title = {Type Label Framework for Bonded Force Fields in LAMMPS},
-+ journal = {J. Phys. Chem. B},
-+ year =    2024,
-+ volume =  128,
-+ number =  13,
-+ pages =   {3282–-3297}
-+}
-+
-+- https://github.com/lab-cosmo/metatensor
-+- https://github.com/luthaf/metatensor-lj-test
-+CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE
-+
-+Generated 0 of 0 mixed pair_coeff terms from geometric mixing rule
-+Neighbor list info ...
-+  update: every = 1 steps, delay = 0 steps, check = yes
-+  max neighbors/atom: 2000, page size: 100000
-+  master list distance cutoff = 8.5
-+  ghost atom cutoff = 8.5
-+  binsize = 4.25, bins = 2 2 2
-+  1 neighbor lists, perpetual/occasional/extra = 1 0 0
-+  (1) pair metatensor, perpetual
-+      attributes: full, newton on, ghost
-+      pair build: full/bin/ghost
-+      stencil: full/ghost/bin/3d
-+      bin: standard
-+Per MPI rank memory allocation (min/avg/max) = 3.359 | 3.359 | 3.359 Mbytes
-+   Step          Temp          PotEng         TotEng         Press          Volume
-+         0   123           -8.2814195     -7.7885506     -67585.536      373.248
-+        10   124.79957     -8.3949245     -7.8948446     -68883.161      370.7507
-+        20   130.37558     -8.7437731     -8.2213497     -72909.223      363.36859
-+        30   140.35202     -9.3570472     -8.7946476     -80147.272      351.36165
-+        40   156.04321     -10.287834     -9.6625589     -91867.312      335.19011
-+        50   179.24129     -11.608375     -10.890143     -108707.41      315.60758
-+        60   212.26895     -13.385134     -12.534558     -131437.18      293.74143
-+        70   257.12553     -15.653741     -14.623422     -160605.1       270.99882
-+        80   309.97318     -18.367667     -17.125584     -193391.56      248.74226
-+        90   345.50571     -21.286382     -19.901918     -220089.9       227.94171
-+       100   318.19414     -23.90463      -22.629605     -220782.88      209.09539
-+Loop time of 4.16296 on 4 procs for 100 steps with 32 atoms
-+
-+Performance: 2.075 ns/day, 11.564 hours/ns, 24.021 timesteps/s, 768.684 atom-step/s
-+97.4% CPU use with 4 MPI tasks x 1 OpenMP threads
-+
-+MPI task timing breakdown:
-+Section |  min time  |  avg time  |  max time  |%varavg| %total
-+---------------------------------------------------------------
-+Pair    | 3.8847     | 3.9666     | 4.0708     |   3.8 | 95.28
-+Neigh   | 0.008984   | 0.0098269  | 0.012274   |   1.4 |  0.24
-+Comm    | 0.060256   | 0.16685    | 0.24951    |  18.7 |  4.01
-+Output  | 0.00014112 | 0.0021948  | 0.0083534  |   7.6 |  0.05
-+Modify  | 0.010689   | 0.016268   | 0.018145   |   2.5 |  0.39
-+Other   |            | 0.001203   |            |       |  0.03
-+
-+Nlocal:              8 ave          10 max           6 min
-+Histogram: 2 0 0 0 0 0 0 0 0 2
-+Nghost:           1259 ave        1261 max        1257 min
-+Histogram: 2 0 0 0 0 0 0 0 0 2
-+Neighs:              0 ave           0 max           0 min
-+Histogram: 4 0 0 0 0 0 0 0 0 0
-+FullNghs:         2891 ave        3614 max        2167 min
-+Histogram: 2 0 0 0 0 0 0 0 0 2
-+
-+Total # of neighbors = 11564
-+Ave neighs/atom = 361.375
-+Neighbor list builds = 2
-+Dangerous builds = 0
-+Total wall time: 0:00:04
-diff --git a/examples/PACKAGES/metatensor/readme.txt b/examples/PACKAGES/metatensor/readme.txt
-new file mode 100644
-index 0000000000..87b15be34c
---- /dev/null
-+++ b/examples/PACKAGES/metatensor/readme.txt
-@@ -0,0 +1,16 @@
-+The base package can be compiled as cmake ../cmake -DPKG_ML-METATENSOR=ON
-+-DCMAKE_PREFIX_PATH=/.../site-packages/torch/share/cmake/ where
-+/.../site-packages/torch/ is the path to a pip installation of torch
-+
-+The kokkos version should be compiled as cmake ../cmake/ -DPKG_KOKKOS=ON
-+-DKokkos_ENABLE_CUDA=ON -DPKG_ML-METATENSOR=ON
-+-DCMAKE_PREFIX_PATH=/.../libtorch/share/cmake/ where /.../libtorch/ is the path
-+to a libtorch C++11 ABI distribution (which can be downloaded from
-+https://pytorch.org/get-started/locally/). The OpenMP version (as opposed to the
-+CUDA version) can be enabled with -DKokkos_ENABLE_OPENMP=ON instead of
-+-DKokkos_ENABLE_CUDA=ON
-+
-+The consistency between the two interfaces can be checked with
-+../../../build/lmp -k on g 1 -in in.kokkos.metatensor (or `t Nt` instead of `g
-+1` for an OpenMP run with Nt threads) and the output can be compared with that
-+of the plain metatensor interface ../../../build/lmp -in in.metatensor
-diff --git a/lib/metatensor/.gitignore b/lib/metatensor/.gitignore
-new file mode 100644
-index 0000000000..a2d7b3571a
---- /dev/null
-+++ b/lib/metatensor/.gitignore
-@@ -0,0 +1,6 @@
-+virtualenv/
-+*.tar.gz
-+metatensor-core/
-+metatensor-torch/
-+
-+usr/
-diff --git a/lib/metatensor/Install.py b/lib/metatensor/Install.py
-new file mode 100644
-index 0000000000..7f8f853c69
---- /dev/null
-+++ b/lib/metatensor/Install.py
-@@ -0,0 +1,453 @@
-+#!/usr/bin/env python
-+"""
-+Install.py tool to download, compile, and setup the ml-metatensor LAMMPS package.
-+This automates the steps described in the README file in this dir.
-+"""
-+
-+import glob
-+import os
-+import shutil
-+import subprocess
-+import sys
-+from argparse import ArgumentParser
-+
-+sys.path.append("..")
-+from install_helpers import checkmd5sum, fullpath, geturl  # noqa F401
-+
-+if sys.version_info < (3, 6):
-+    sys.exit("this script requires at least Python 3.6")
-+
-+# settings
-+
-+HERE = fullpath(".")
-+METATENSOR_CORE_VERSION_DEFAULT = "0.1.7"
-+METATENSOR_TORCH_VERSION_DEFAULT = "0.5.1"
-+LIBTORCH_VERSION_DEFAULT = "2.2.2"
-+
-+# known checksums for different versions. used to validate the download.
-+METATENSOR_CORE_CHECKSUMS = {
-+    "0.1.6": "3edaf5ffd1af8892965f1f618c04083d",
-+    "0.1.7": "43aeb651e6d040fbc82d4b5191e2f6cb",
-+    "0.1.8": "22ae27fb3b26f356ca6e477326be6470",
-+}
-+METATENSOR_TORCH_CHECKSUMS = {
-+    "0.5.0": "8ef9e235bbd5db22520f3abdc110f904",
-+    "0.5.1": "a4c535faae3a811784679a55b32d9dce",
-+}
-+
-+GITHUB_RELEASES = "https://github.com/lab-cosmo/metatensor/releases/download"
-+
-+CMAKE_EXE = os.environ.get("CMAKE", "cmake")
-+
-+
-+def download_unpack(url, unpacked_dir, checksum=None, verbose=False):
-+    file_name = os.path.basename(url)
-+    print(f"===> Downloading {file_name}")
-+
-+    geturl(url, os.path.basename(url))
-+    if checksum is not None:
-+        if not checkmd5sum(checksum, file_name):
-+            sys.exit(f"ERROR: checksum for {file_name} does not match!")
-+
-+    print(f"===> Unpacking to {unpacked_dir}")
-+    if verbose:
-+        stdout = sys.stdout
-+        stderr = sys.stderr
-+    else:
-+        stdout = subprocess.PIPE
-+        stderr = subprocess.PIPE
-+
-+    shutil.rmtree(unpacked_dir, ignore_errors=True)
-+    subprocess.run(
-+        [CMAKE_EXE, "-E", "tar", "xf", file_name],
-+        stdout=stdout,
-+        stderr=stderr,
-+        check=True,
-+    )
-+    extracted = file_name[:-7]
-+    shutil.move(extracted, unpacked_dir)
-+
-+
-+def install_with_pip(python, package, verbose=False):
-+    print(f"===> Installing {package} with pip")
-+    if verbose:
-+        stdout = sys.stdout
-+        stderr = sys.stderr
-+    else:
-+        stdout = subprocess.PIPE
-+        stderr = subprocess.PIPE
-+
-+    subprocess.run(
-+        [
-+            python,
-+            "-m",
-+            "pip",
-+            "install",
-+            "--disable-pip-version-check",
-+            package,
-+        ],
-+        stdout=stdout,
-+        stderr=stderr,
-+        check=True,
-+    )
-+
-+
-+def copy_from_pip(python, package, paths, install_dir, verbose=False):
-+    print(f"===> Copying files for {package} from Python installation")
-+    prefix = subprocess.check_output(
-+        [python, "-c", f"import {package}; print({package}.__file__)"],
-+        encoding="utf8",
-+    )
-+    prefix = os.path.dirname(prefix.strip())
-+
-+    for src, dst in paths:
-+        shutil.copytree(
-+            os.path.join(prefix, src),
-+            os.path.join(install_dir, dst),
-+            dirs_exist_ok=True,
-+        )
-+
-+
-+def build_cmake(source_dir, install_dir, cmake_opts, verbose=False):
-+    print(f"===> Building {source_dir} with cmake")
-+    if verbose:
-+        stdout = sys.stdout
-+        stderr = sys.stderr
-+    else:
-+        stdout = subprocess.PIPE
-+        stderr = subprocess.PIPE
-+
-+    build_dir = os.path.join(source_dir, "build")
-+
-+    subprocess.run(
-+        [
-+            CMAKE_EXE,
-+            "-S",
-+            source_dir,
-+            "-B",
-+            build_dir,
-+            *cmake_opts,
-+            f"-DCMAKE_INSTALL_PREFIX={install_dir}",
-+            "-DCMAKE_BUILD_TYPE=Release",
-+        ],
-+        stdout=stdout,
-+        stderr=stderr,
-+        check=True,
-+    )
-+
-+    subprocess.run(
-+        [
-+            CMAKE_EXE,
-+            "--build",
-+            build_dir,
-+            "--config",
-+            "Release",
-+            "--target",
-+            "install",
-+        ],
-+        stdout=stdout,
-+        stderr=stderr,
-+        check=True,
-+    )
-+
-+
-+if __name__ == "__main__":
-+
-+    parser = ArgumentParser(
-+        prog="Install.py", description="LAMMPS library build wrapper script"
-+    )
-+
-+    # help message
-+
-+    HELP = """
-+This script tries to install all the dependencies of the ml-metatensor package. This
-+includes libtorch, metatensor and metatensor-torch. Different options are available for
-+the different dependencies:
-+
-+- libtorch can be downloaded from pip, or taken from another installation on your
-+  system.
-+    - If downloaded by pip, we will create a virtual environment and install it there,
-+      unless `--python` is given as an option, in which case we will try to install it
-+      using the provided python executable.
-+    - If you want to use another installation of libtorch, please use the `--no-torch`
-+      option and export the TORCH_PREFIX environment variable containing the path of the
-+      installation.
-+- metatensor and metatensor-torch can be downloaded from pip or built from sources
-+    - if downloaded by pip, the same options as torch applies. This is triggered by the
-+      `--metatensor-use-pip` option.
-+    - if building from sources, you will need to install cmake and a rust compiler on
-+      your system (we suggest https://rustup.rs/ to install a rust compiler).
-+
-+
-+Syntax from src dir: make lib-metatensor args="-b ..."
-+Syntax from lib dir: python Install.py -b ...
-+
-+Examples:
-+
-+# install with default versions and settings
-+make lib-metatensor args="-b"
-+
-+# install specified version of libtorch
-+make lib-metatensor args="-b --torch-version <version>"
-+
-+# install using python3 in the PATH
-+make lib-metatensor args="-b --python $(which python3)"
-+
-+# build metatensor from sources
-+make lib-metatensor args="-b --metatensor-from-sources"
-+    """
-+
-+    parser.add_argument(
-+        "-b",
-+        "--build",
-+        action="store_true",
-+        help="download and build metatensor and metatensor-torch libraries",
-+    )
-+    parser.add_argument(
-+        "--torch-version",
-+        default=LIBTORCH_VERSION_DEFAULT,
-+        help=f"version of libtorch to download (default: {LIBTORCH_VERSION_DEFAULT})",
-+    )
-+    parser.add_argument(
-+        "--python",
-+        help="path to a Python executable to use, this bypass the use of venv",
-+    )
-+
-+    parser.add_argument(
-+        "--no-torch",
-+        action="store_true",
-+        default=False,
-+        help="disabled download of libtorch",
-+    )
-+    parser.add_argument(
-+        "--metatensor-from-sources",
-+        action="store_true",
-+        help="build metatensor and metatensor-torch from sources",
-+    )
-+
-+    parser.add_argument(
-+        "--metatensor-version",
-+        default=METATENSOR_CORE_VERSION_DEFAULT,
-+        choices=METATENSOR_CORE_CHECKSUMS.keys(),
-+        help=(
-+            "version of metatensor-core to download and build "
-+            f"(default: {METATENSOR_CORE_VERSION_DEFAULT})"
-+        ),
-+    )
-+    parser.add_argument(
-+        "--metatensor-torch-version",
-+        default=METATENSOR_TORCH_VERSION_DEFAULT,
-+        choices=METATENSOR_TORCH_CHECKSUMS.keys(),
-+        help=(
-+            "version of metatensor-torch to download and build "
-+            f"(default: {METATENSOR_TORCH_VERSION_DEFAULT})"
-+        ),
-+    )
-+    parser.add_argument(
-+        "-vv",
-+        "--verbose",
-+        action="store_true",
-+        help="be more verbose about is happening while this script runs",
-+    )
-+
-+    args = parser.parse_args()
-+
-+    # print help message and exit, if build option is not given
-+    if not args.build:
-+        parser.print_help()
-+        sys.exit(HELP)
-+
-+    do_build = args.build
-+    verbose = args.verbose
-+
-+    metatensor_core_version = args.metatensor_version
-+    metatensor_torch_version = args.metatensor_torch_version
-+    metatensor_from_sources = args.metatensor_from_sources
-+
-+    do_torch = not args.no_torch
-+    torch_version = args.torch_version
-+
-+    # If we don't know the version of torch, we need to build metatensor-torch from
-+    # sources.
-+    if args.no_torch and not metatensor_from_sources:
-+        raise Exception("--no-torch requires --metatensor-from-sources")
-+
-+    python = args.python
-+
-+    if python is None:
-+        python = sys.executable
-+        do_venv = do_torch or not metatensor_from_sources
-+    else:
-+        do_venv = False
-+
-+    if verbose:
-+        stdout = sys.stdout
-+        stderr = sys.stderr
-+    else:
-+        stdout = subprocess.PIPE
-+        stderr = subprocess.PIPE
-+
-+    if do_venv:
-+        venv_path = os.path.join(HERE, "virtualenv")
-+        print(f"===> Creating virtual environment at {venv_path}")
-+
-+        try:
-+            import venv
-+        except ImportError:
-+            sys.exit(
-+                "could not import 'venv', make sure 'python-venv' package is installed"
-+            )
-+
-+        builder = venv.EnvBuilder(
-+            with_pip=True,
-+            symlinks=not sys.platform.startswith("win"),
-+        )
-+        builder.create(venv_path)
-+
-+        if sys.platform.startswith("win"):
-+            python = os.path.join(venv_path, "Scripts", "python.exe")
-+        else:
-+            python = os.path.join(venv_path, "bin", "python")
-+
-+        if verbose:
-+            print("===> Upgrading pip in virtualenv")
-+
-+        subprocess.run(
-+            [python, "-m", "pip", "install", "--upgrade", "pip"],
-+            stdout=stdout,
-+            stderr=stderr,
-+            check=True,
-+        )
-+
-+    install_dir = os.path.join(HERE, "usr")
-+    os.makedirs(os.path.join(install_dir, "lib"), exist_ok=True)
-+    os.makedirs(os.path.join(install_dir, "include"), exist_ok=True)
-+    os.makedirs(os.path.join(install_dir, "share"), exist_ok=True)
-+
-+    cmake_prefix_path = []
-+    # Torch needs C++17 to compile
-+    extra_cxx_flags = ["-std=c++17"]
-+
-+    torch_extra_include = os.path.join("torch", "csrc", "api", "include")
-+    if do_torch:
-+        install_with_pip(python, f"torch=={torch_version}", verbose=verbose)
-+        install_with_pip(python, "numpy", verbose=verbose)
-+
-+        torch_prefix = subprocess.check_output(
-+            [python, "-c", "import torch; print(torch.__file__)"],
-+            encoding="utf8",
-+        )
-+        torch_prefix = os.path.dirname(torch_prefix.strip())
-+
-+        if sys.platform.startswith("linux"):
-+            # the pip version of torch uses the pre-cxx11 ABI
-+            extra_cxx_flags.append("-D_GLIBCXX_USE_CXX11_ABI=0")
-+
-+    else:
-+        torch_prefix = os.environ.get("TORCH_PREFIX")
-+
-+    if torch_prefix is not None:
-+        cmake_prefix_path.append(torch_prefix)
-+
-+        if os.path.exists(os.path.join(torch_prefix, "include")):
-+            extra_cxx_flags.append(f"-I{os.path.join(torch_prefix, 'include')}")
-+            extra_cxx_flags.append(
-+                f"-I{os.path.join(torch_prefix, 'include', torch_extra_include)}"
-+            )
-+
-+    if metatensor_from_sources:
-+        # Download and build metatensor-core from source
-+        download_unpack(
-+            url=f"{GITHUB_RELEASES}/metatensor-core-v{metatensor_core_version}/metatensor-core-cxx-{metatensor_core_version}.tar.gz",  # noqa: E501
-+            unpacked_dir="metatensor-core",
-+            checksum=METATENSOR_CORE_CHECKSUMS.get(metatensor_core_version),
-+            verbose=verbose,
-+        )
-+
-+        build_cmake(
-+            source_dir="metatensor-core",
-+            install_dir=install_dir,
-+            cmake_opts=[
-+                "-DBUILD_SHARED_LIBS=ON",
-+                "-DMETATENSOR_INSTALL_BOTH_STATIC_SHARED=OFF",
-+            ],
-+            verbose=verbose,
-+        )
-+
-+        # Download and build metatensor-torch from source
-+        cmake_prefix_path.append(f"{install_dir}/lib/")
-+        download_unpack(
-+            url=f"{GITHUB_RELEASES}/metatensor-torch-v{metatensor_torch_version}/metatensor-torch-cxx-{metatensor_torch_version}.tar.gz",  # noqa: E501
-+            unpacked_dir="metatensor-torch",
-+            checksum=METATENSOR_TORCH_CHECKSUMS.get(metatensor_torch_version),
-+            verbose=verbose,
-+        )
-+
-+        build_cmake(
-+            source_dir="metatensor-torch",
-+            install_dir=install_dir,
-+            cmake_opts=[
-+                "-DBUILD_SHARED_LIBS=ON",
-+                f"-DCMAKE_PREFIX_PATH={';'.join(cmake_prefix_path)}",
-+            ],
-+            verbose=verbose,
-+        )
-+    else:
-+        install_with_pip(
-+            python,
-+            f"metatensor-core=={metatensor_core_version}",
-+            verbose=verbose,
-+        )
-+        copy_from_pip(
-+            python,
-+            "metatensor",
-+            [("lib", "lib"), ("include", "include")],
-+            install_dir=install_dir,
-+            verbose=verbose,
-+        )
-+
-+        install_with_pip(
-+            python,
-+            f"metatensor-torch=={metatensor_torch_version}",
-+            verbose=verbose,
-+        )
-+        torch_version_prefix = "torch-" + ".".join(torch_version.split(".")[:2])
-+        copy_from_pip(
-+            python,
-+            "metatensor.torch",
-+            [
-+                (os.path.join(torch_version_prefix, "lib"), "lib"),
-+                (os.path.join(torch_version_prefix, "include"), "include"),
-+            ],
-+            install_dir=install_dir,
-+            verbose=verbose,
-+        )
-+
-+    print("===> Creating Makefile.lammps")
-+    with open("Makefile.lammps", "w") as fd:
-+        fd.write("# autogenerated file\n\n\n")
-+
-+        fd.write(f"metatensor_SYSINC = -I{os.path.join(install_dir, 'include')}")
-+        fd.write(f" {' '.join(extra_cxx_flags)}")
-+        fd.write("\n\n")
-+
-+        fd.write("metatensor_SYSLIB = -lmetatensor -lmetatensor_torch")
-+        fd.write(" -ltorch -lc10 -ltorch_cpu")
-+        if len(glob.glob(os.path.join(torch_prefix, "lib", "*torch_cuda*"))) != 0:
-+            fd.write(" -ltorch_cuda -lc10_cuda")
-+        fd.write("\n\n")
-+
-+        fd.write(f"metatensor_SYSPATH = -L{os.path.join(install_dir, 'lib')}")
-+        fd.write(f" -L{os.path.join(torch_prefix, 'lib')}")
-+
-+        # set the rpath on the final binary
-+        fd.write(f" -Wl,-rpath,{os.path.join(install_dir, 'lib')}")
-+        fd.write(f" -Wl,-rpath,{os.path.join(torch_prefix, 'lib')}")
-+
-+        if sys.platform.startswith("linux"):
-+            # force the use of rpath instead of runpath
-+            fd.write(" -Wl,--disable-new-dtags")
-+
-+        fd.write("\n\n")
-+
-+    print("===> All done!")
-diff --git a/lib/metatensor/Makefile.lammps.empty b/lib/metatensor/Makefile.lammps.empty
-new file mode 100644
-index 0000000000..5d44a9aca4
---- /dev/null
-+++ b/lib/metatensor/Makefile.lammps.empty
-@@ -0,0 +1,6 @@
-+# Settings that the LAMMPS build will import when metatensor is used. Rename
-+# this file to `Makefile.lammps` and edit the flags below as required
-+
-+metatensor_SYSINC =
-+metatensor_SYSLIB =
-+metatensor_SYSPATH =
-diff --git a/lib/metatensor/README b/lib/metatensor/README
-new file mode 100644
-index 0000000000..ec96c3f2dc
---- /dev/null
-+++ b/lib/metatensor/README
-@@ -0,0 +1,23 @@
-+# ML-METATENSOR
-+
-+The files in this directory are helpers to install all the dependencies of the
-+ML-METATENSOR package:
-+
-+- the C++ version of libtorch;
-+- the core metatensor library;
-+- the metatensor_torch library;
-+
-+You can type "make lib-metatensor" from the src directory to see help on how to
-+download and build this library via make commands, or you can do the same thing
-+by typing "python Install.py" from within this directory. There are many options
-+you can set to choose where to install the libraries and whether to download
-+pre-built versions or compile your own.
-+
-+Alternatively, you can download and build the above dependencies (see
-+https://docs.metatensor.org/latest/installation.html for information on how to
-+do this) somewhere on your system; and then make a copy of
-+`Makefile.lammps.empty` named `Makefile.lammps`, and edit it to add the right
-+flags for your compiler. You'll need to add the three libraries above to the
-+include search path, library search path; and you'll need to link LAMMPS with
-+the `torch`, `c10`, (optionally `torch_cuda` and `c10_cuda` for GPU support),
-+`metatensor` and `metatensor_torch` libraries.
-diff --git a/src/.gitignore b/src/.gitignore
-index 5debdebc50..d910a66902 100644
---- a/src/.gitignore
-+++ b/src/.gitignore
-@@ -1434,6 +1434,10 @@
- /pair_peri_ves.h
- /pair_quip.cpp
- /pair_quip.h
-+/pair_metatensor.cpp
-+/pair_metatensor.h
-+/metatensor_system.cpp
-+/metatensor_system.h
- /pair_reaxff.cpp
- /pair_reaxff.h
- /pair_rebo.cpp
-@@ -1801,4 +1805,3 @@
- /pair_smtbq.h
- /pair_vashishta*.cpp
- /pair_vashishta*.h
--
-diff --git a/src/KOKKOS/metatensor_system_kokkos.cpp b/src/KOKKOS/metatensor_system_kokkos.cpp
-new file mode 100644
-index 0000000000..b8e68b8f00
---- /dev/null
-+++ b/src/KOKKOS/metatensor_system_kokkos.cpp
-@@ -0,0 +1,392 @@
-+/* ----------------------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+/* ----------------------------------------------------------------------
-+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
-+                         Filippo Bigi <filippo.bigi@epfl.ch>
-+------------------------------------------------------------------------- */
-+#include "metatensor_system_kokkos.h"
-+
-+#include "metatensor_timer.h"
-+
-+#include "domain.h"
-+#include "error.h"
-+
-+#include "atom_kokkos.h"
-+
-+#include <torch/cuda.h>
-+
-+using namespace LAMMPS_NS;
-+
-+template<typename T, class DeviceType>
-+using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
-+
-+template<class DeviceType>
-+MetatensorSystemAdaptorKokkos<DeviceType>::MetatensorSystemAdaptorKokkos(LAMMPS *lmp, MetatensorSystemOptions options):
-+    MetatensorSystemAdaptor(lmp, options),
-+    device_(KokkosDeviceToTorch<DeviceType>::convert())
-+{
-+    // MetatensorSystemAdaptor allocate on CPU, move to the right device
-+    this->atomic_types_ = this->atomic_types_.to(this->device_);
-+
-+    auto tensor_options = torch::TensorOptions()
-+        .dtype(torch::kFloat64)
-+        .device(this->device_)
-+        .requires_grad(true);
-+
-+    this->strain = torch::eye(3, tensor_options);
-+}
-+
-+template<class DeviceType>
-+void MetatensorSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatensor_torch::System& system, NeighListKokkos<DeviceType>* list) {
-+    auto _ = MetatensorTimer("converting kokkos neighbors with ghosts remapping");
-+    auto dtype = system->positions().scalar_type();
-+
-+    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
-+
-+    {
-+        auto _ = MetatensorTimer("identifying ghosts and real atoms");
-+        /*-------------- this will be done on CPU for now ------------------------*/
-+        // The hashmap in the following code is not easy to implement in either Kokkos or torch
-+        // The cost of this section seems to be very low anyway
-+
-+        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
-+        // atoms which are periodic images of local atoms back to the local atoms.
-+        //
-+        // Metatensor expects pairs corresponding to periodic atoms to be between
-+        // the main atoms, but using the actual distance vector between the atom and
-+        // the ghost.
-+        original_atom_id_.clear();
-+        original_atom_id_.reserve(total_n_atoms);
-+
-+        // identify all local atom by their LAMMPS atom tag.
-+        local_atoms_tags_.clear();
-+        for (int i=0; i<atom->nlocal; i++) {
-+            original_atom_id_.emplace_back(i);
-+            local_atoms_tags_.emplace(atom->tag[i], i);
-+        }
-+
-+        // now loop over ghosts & map them back to the main cell if needed
-+        ghost_atoms_tags_.clear();
-+        for (int i=atom->nlocal; i<total_n_atoms; i++) {
-+            auto tag = atom->tag[i];
-+            auto it = local_atoms_tags_.find(tag);
-+            if (it != local_atoms_tags_.end()) {
-+                // this is the periodic image of an atom already owned by this domain
-+                original_atom_id_.emplace_back(it->second);
-+            } else {
-+                // this can either be a periodic image of an atom owned by another
-+                // domain, or directly an atom from another domain. Since we can not
-+                // really distinguish between these, we take the first atom as the
-+                // "main" one and remap all atoms with the same tag to the first one
-+                auto it = ghost_atoms_tags_.find(tag);
-+                if (it != ghost_atoms_tags_.end()) {
-+                    // we already found this atom elsewhere in the system
-+                    original_atom_id_.emplace_back(it->second);
-+                } else {
-+                    // this is the first time we are seeing this atom
-+                    original_atom_id_.emplace_back(i);
-+                    ghost_atoms_tags_.emplace(tag, i);
-+                }
-+            }
-+        }
-+    }
-+    /*----------- end of "this will be done on CPU for now" --------------*/
-+
-+    auto original_id = torch::from_blob(
-+        original_atom_id_.data(),
-+        {total_n_atoms},
-+        torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-+    ).to(this->device_);
-+
-+    auto neighbors_kk = list->d_neighbors_transpose;
-+    auto max_number_of_neighbors = list->maxneighs;
-+
-+    auto neighbors = torch::zeros(
-+        {total_n_atoms, max_number_of_neighbors},
-+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-+    );
-+    // mask neighbors_kk with NEIGHMASK. Torch doesn't have this functionality, we do it in Kokkos
-+    auto neighbors_kk_masked = UnmanagedView<int32_t**, DeviceType>(
-+        neighbors.template data_ptr<int32_t>(),
-+        total_n_atoms,
-+        max_number_of_neighbors
-+    );
-+    Kokkos::parallel_for(
-+        Kokkos::MDRangePolicy({0, 0}, {total_n_atoms, max_number_of_neighbors}),
-+        KOKKOS_LAMBDA(size_t i, size_t j) {
-+            neighbors_kk_masked(i, j) = neighbors_kk(i, j) & NEIGHMASK;
-+        }
-+    );
-+
-+    // Convert NL-related data to torch tensors
-+    auto numneigh = torch::from_blob(
-+        list->d_numneigh.data(),
-+        {total_n_atoms},
-+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-+    );
-+    auto ilist = torch::from_blob(
-+        list->d_ilist.data(),
-+        {total_n_atoms},
-+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-+    );
-+
-+    auto x = system->positions().detach();
-+    auto cell_inverse = system->cell().detach().inverse();
-+
-+    // convert from LAMMPS NL format to metatensor NL format
-+    auto expanded_arange = torch::arange(
-+        max_number_of_neighbors,
-+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-+    ).unsqueeze(0).expand({total_n_atoms, -1});
-+    auto neighbor_2d_mask = expanded_arange < numneigh.unsqueeze(1);
-+
-+    auto expanded_arange_other_dim = torch::arange(
-+        total_n_atoms,
-+        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-+    ).unsqueeze(1).expand({-1, max_number_of_neighbors});
-+    auto index_for_ilist = expanded_arange_other_dim.masked_select(neighbor_2d_mask);
-+
-+    auto centers_id = ilist.index_select(0, index_for_ilist);
-+    auto neighbors_id = neighbors.masked_select(neighbor_2d_mask);
-+
-+    // change centers and neighbors to the original atom ids
-+    auto centers_original_id = original_id.index_select(0, centers_id);
-+    auto neighbors_original_id = original_id.index_select(0, neighbors_id);
-+
-+    // The following code is a direct translation of the code in the non-Kokkos
-+    // version (MetaTensorSystemAdaptor::setup_neighbors_remap), but rewritten
-+    // in torch to use the GPU
-+    for (auto& cache: caches_) {
-+        // current values of various tensors, these change depending on full/half setting
-+        torch::Tensor centers_id_cur;
-+        torch::Tensor neighbors_id_cur;
-+        torch::Tensor centers_original_id_cur;
-+        torch::Tensor neighbors_original_id_cur;
-+
-+        // filtered tensors, i.e. only containing pairs actually below the cutoff
-+        torch::Tensor centers_original_id_filt_cur;
-+        torch::Tensor neighbors_original_id_filt_cur;
-+        torch::Tensor distances_filt_cur;
-+        torch::Tensor cell_shifts_cur;
-+
-+        // other tensors that need to live across multiple timed sections
-+        torch::Tensor samples_indices;
-+        torch::Tensor samples_values;
-+        {
-+            auto _ = MetatensorTimer("filtering LAMMPS neighbor list");
-+            // half list mask, if necessary
-+            auto full_list = cache.options->full_list();
-+
-+            if (full_list) {
-+                centers_id_cur = centers_id;
-+                neighbors_id_cur = neighbors_id;
-+                centers_original_id_cur = centers_original_id;
-+                neighbors_original_id_cur = neighbors_original_id;
-+            } else {
-+                auto half_list_mask = centers_original_id <= neighbors_original_id;
-+                centers_id_cur = centers_id.masked_select(half_list_mask);
-+                neighbors_id_cur = neighbors_id.masked_select(half_list_mask);
-+                centers_original_id_cur = centers_original_id.masked_select(half_list_mask);
-+                neighbors_original_id_cur = neighbors_original_id.masked_select(half_list_mask);
-+            }
-+
-+            // distance mask
-+            auto distances = x.index_select(0, neighbors_id_cur) - x.index_select(0, centers_id_cur);
-+            auto cutoff_mask = torch::sum(distances.pow(2), 1) < cache.cutoff*cache.cutoff;
-+
-+            // index everything with the mask
-+            auto centers_original_id_filt = centers_original_id_cur.masked_select(cutoff_mask);
-+            auto neighbors_original_id_filt = neighbors_original_id_cur.masked_select(cutoff_mask);
-+            auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
-+
-+            // find filtered interatomic vectors using the original atoms
-+            auto original_distances_filtered =
-+                x.index_select(0, neighbors_original_id_filt)
-+                - x.index_select(0, centers_original_id_filt);
-+
-+            // cell shifts
-+            auto pair_shifts = distances_filt - original_distances_filtered;
-+            auto cell_shifts = pair_shifts.matmul(cell_inverse);
-+            cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
-+
-+            if (full_list) {
-+                centers_original_id_filt_cur = centers_original_id_filt;
-+                neighbors_original_id_filt_cur = neighbors_original_id_filt;
-+                distances_filt_cur = distances_filt;
-+                cell_shifts_cur = cell_shifts;
-+            } else {
-+                auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
-+                auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
-+                auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
-+                // reproduce this mask (from MetaTensorSystemAdaptor::setup_neighbors_remap) with torch:
-+                // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
-+                auto edge_mask = (
-+                    (torch::sum(cell_shifts, 1) == 0) & (
-+                        (cell_shifts.index({torch::indexing::Slice(), 2}) < 0) | (
-+                            cell_shifts.index({torch::indexing::Slice(), 2}) == 0 &
-+                            cell_shifts.index({torch::indexing::Slice(), 1}) < 0
-+                        )
-+                    )
-+                );
-+                auto final_mask = torch::logical_not(
-+                    half_list_cell_mask | (
-+                        pair_with_image_mask & (negative_half_space_mask | edge_mask)
-+                    )
-+                );
-+                centers_original_id_filt_cur = centers_original_id_filt.masked_select(final_mask);
-+                neighbors_original_id_filt_cur = neighbors_original_id_filt.masked_select(final_mask);
-+                distances_filt_cur = distances_filt.index({final_mask, torch::indexing::Slice()});
-+                cell_shifts_cur = cell_shifts.index({final_mask, torch::indexing::Slice()});
-+            }
-+
-+            // make sure all the sample are unique
-+            samples_values = torch::concatenate({
-+                centers_original_id_filt_cur.unsqueeze(-1),
-+                neighbors_original_id_filt_cur.unsqueeze(-1),
-+                cell_shifts_cur
-+            }, /*dim=*/1);
-+
-+            auto [samples_values_unique, samples_inverse, _counts] = torch::unique_dim(
-+                samples_values, /*dim=*/0, /*sorted=*/true, /*return_inverse=*/true, /*return_counts=*/false
-+            );
-+            samples_values = samples_values_unique;
-+
-+            auto permutation = torch::arange(samples_inverse.size(0), samples_inverse.options());
-+            samples_inverse = samples_inverse.flip({0});
-+            permutation = permutation.flip({0});
-+
-+            samples_indices = torch::empty(samples_values.size(0), samples_inverse.options());
-+            samples_indices.scatter_(0, samples_inverse, permutation);
-+        }
-+
-+        // wrap into metatensor data structures
-+        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
-+        {
-+            auto n_pairs = samples_values.size(0);
-+            auto _ = MetatensorTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
-+            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-+                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-+                samples_values
-+            );
-+        }
-+
-+        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
-+        {
-+            auto _ = MetatensorTimer("creating neighbors TensorBlock");
-+
-+            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
-+                distances_filt_cur.index_select(0, samples_indices).unsqueeze(-1),
-+                samples,
-+                std::vector<metatensor_torch::TorchLabels>{
-+                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(this->device_),
-+                },
-+                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(this->device_)
-+            );
-+        }
-+
-+        metatensor_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-+        system->add_neighbor_list(cache.options, neighbors);
-+    }
-+}
-+
-+
-+template<class DeviceType>
-+metatensor_torch::System MetatensorSystemAdaptorKokkos<DeviceType>::system_from_lmp(
-+    NeighList* list,
-+    bool do_virial,
-+    bool remap_pairs,
-+    torch::ScalarType dtype,
-+    torch::Device device
-+) {
-+    auto _ = MetatensorTimer("creating System from LAMMPS-kokkos data");
-+    assert(device == this->device_);
-+
-+    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
-+
-+    atomic_types_.resize_({total_n_atoms});
-+    auto atomic_types_kk = UnmanagedView<int32_t*, DeviceType>(atomic_types_.data_ptr<int32_t>(), total_n_atoms);
-+    auto type_mapping_kk = UnmanagedView<int32_t*, DeviceType>(options_.types_mapping, atomKK->ntypes + 1);
-+    auto types_kk = atomKK->k_type.view<DeviceType>();
-+    Kokkos::parallel_for(total_n_atoms, KOKKOS_LAMBDA(int i) {
-+        atomic_types_kk(i) = type_mapping_kk(types_kk(i));
-+    });
-+
-+    // atomKK->k_x contains "real" and then ghost atoms, in that order
-+    auto k_x = atomKK->k_x.view<DeviceType>();
-+    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
-+
-+    this->positions = torch::from_blob(
-+        k_x.data(), {total_n_atoms, 3},
-+        // requires_grad=true since we always need gradients w.r.t. positions
-+        tensor_options.requires_grad(true)
-+    );
-+
-+    auto cell = torch::zeros({3, 3}, tensor_options);
-+    cell[0][0] = domain->xprd;
-+
-+    cell[1][0] = domain->xy;
-+    cell[1][1] = domain->yprd;
-+
-+    cell[2][0] = domain->xz;
-+    cell[2][1] = domain->yz;
-+    cell[2][2] = domain->zprd;
-+
-+    auto system_positions = this->positions.to(dtype);
-+    cell = cell.to(dtype);
-+
-+    if (do_virial) {
-+        auto model_strain = this->strain.to(dtype);
-+
-+        // pretend to scale positions/cell by the strain so that
-+        // it enters the computational graph.
-+        system_positions = system_positions.matmul(model_strain);
-+        cell = cell.matmul(model_strain);
-+    }
-+
-+    // Periodic boundary conditions handling.
-+    // While Metatensor atomistic models can support mixed PBC settings, we
-+    // currently assume that the system is fully periodic and we throw an error
-+    // otherwise
-+    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-+        error->all(FLERR, "metatensor/kk currently requires a fully periodic system");
-+    }
-+    auto pbc = torch::tensor(
-+        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
-+        torch::TensorOptions().dtype(torch::kBool).device(this->device_)
-+    );
-+
-+    auto system = torch::make_intrusive<metatensor_torch::SystemHolder>(
-+        atomic_types_,
-+        system_positions,
-+        cell,
-+        pbc
-+    );
-+
-+    if (remap_pairs) {
-+        auto* kk_list = dynamic_cast<NeighListKokkos<DeviceType>*>(list);
-+        assert(kk_list != nullptr);
-+        this->setup_neighbors_remap_kk(system, kk_list);
-+    } else {
-+        error->all(FLERR, "the kokkos version of metatensor requires remap_pairs to be true");
-+    }
-+
-+    return system;
-+}
-+
-+namespace LAMMPS_NS {
-+template class MetatensorSystemAdaptorKokkos<LMPDeviceType>;
-+#ifdef LMP_KOKKOS_GPU
-+template class MetatensorSystemAdaptorKokkos<LMPHostType>;
-+#endif
-+}
-diff --git a/src/KOKKOS/metatensor_system_kokkos.h b/src/KOKKOS/metatensor_system_kokkos.h
-new file mode 100644
-index 0000000000..372a8b3a5b
---- /dev/null
-+++ b/src/KOKKOS/metatensor_system_kokkos.h
-@@ -0,0 +1,98 @@
-+/* -*- c++ -*- ----------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+#ifndef LMP_METATENSOR_SYSTEM_KOKKOS_H
-+#define LMP_METATENSOR_SYSTEM_KOKKOS_H
-+
-+#include "metatensor_system.h"
-+#include "neigh_list_kokkos.h"
-+
-+namespace LAMMPS_NS {
-+
-+/* ---------------------------------------------------------------------- */
-+
-+// See https://kokkos.org/kokkos-core-wiki/API/core/execution_spaces.html for a
-+// list of execution spaces.
-+template<class DeviceType>
-+struct KokkosDeviceToTorch {};
-+
-+#if defined(KOKKOS_ENABLE_SERIAL)
-+template<> struct KokkosDeviceToTorch<Kokkos::Serial> {
-+    static torch::Device convert() {
-+        return torch::Device(torch::kCPU);
-+    }
-+};
-+#endif
-+
-+#if defined(KOKKOS_ENABLE_CUDA)
-+template<> struct KokkosDeviceToTorch<Kokkos::Cuda> {
-+    static torch::Device convert() {
-+        return torch::Device(torch::kCUDA, Kokkos::device_id());
-+    }
-+};
-+#endif
-+
-+#if defined(KOKKOS_ENABLE_HIP)
-+template<> struct KokkosDeviceToTorch<Kokkos::HIP> {
-+    static torch::Device convert() {
-+        return torch::Device(torch::kHIP, Kokkos::device_id());
-+    }
-+};
-+#endif
-+
-+#if defined(KOKKOS_ENABLE_OPENMP)
-+template<> struct KokkosDeviceToTorch<Kokkos::OpenMP> {
-+    static torch::Device convert() {
-+        return torch::Device(torch::kCPU);
-+    }
-+};
-+#endif
-+
-+#if defined(KOKKOS_ENABLE_THREADS)
-+template<> struct KokkosDeviceToTorch<Kokkos::Threads> {
-+    static torch::Device convert() {
-+        return torch::Device(torch::kCPU);
-+    }
-+};
-+#endif
-+
-+// Kokkos::SYCL, Kokkos::OpenMPTarget, Kokkos::HPX don't have a matching device
-+// in torch.
-+
-+/* ---------------------------------------------------------------------- */
-+
-+template<class DeviceType>
-+class MetatensorSystemAdaptorKokkos : public MetatensorSystemAdaptor {
-+public:
-+    MetatensorSystemAdaptorKokkos(LAMMPS *lmp, MetatensorSystemOptions options);
-+    ~MetatensorSystemAdaptorKokkos() override {}
-+
-+    // Create a metatensor system matching the LAMMPS-Kokkos system data
-+    metatensor_torch::System system_from_lmp(
-+        NeighList* list,
-+        bool do_virial,
-+        bool remap_pairs,
-+        torch::ScalarType dtype,
-+        torch::Device device
-+    ) override;
-+
-+    void setup_neighbors_remap_kk(metatensor_torch::System& system, NeighListKokkos<DeviceType>* list);
-+
-+private:
-+    /// Torch device corresponding to the kokkos `DeviceType`
-+    torch::Device device_;
-+};
-+
-+}    // namespace LAMMPS_NS
-+
-+#endif
-diff --git a/src/KOKKOS/pair_metatensor_kokkos.cpp b/src/KOKKOS/pair_metatensor_kokkos.cpp
-new file mode 100644
-index 0000000000..902b2ce82f
---- /dev/null
-+++ b/src/KOKKOS/pair_metatensor_kokkos.cpp
-@@ -0,0 +1,283 @@
-+/* ----------------------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+/* ----------------------------------------------------------------------
-+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
-+                         Filippo Bigi <filippo.bigi@epfl.ch>
-+------------------------------------------------------------------------- */
-+#include "pair_metatensor_kokkos.h"
-+
-+#include "error.h"
-+#include "kokkos.h"
-+#include "neigh_request.h"
-+#include "atom_masks.h"
-+
-+#include "atom_kokkos.h"
-+
-+#include "metatensor_system_kokkos.h"
-+#include "metatensor_types.h"
-+#include "metatensor_timer.h"
-+
-+#include <algorithm>
-+#include <cctype>
-+
-+using namespace LAMMPS_NS;
-+
-+// LAMMPS uses `LAMMPS_NS::tagint` and `int` for tags and neighbor lists, respectively.
-+// For the moment, we require both to be int32_t for this interface
-+static_assert(std::is_same_v<LAMMPS_NS::tagint, int32_t>, "Error: LAMMPS_NS::tagint must be int32_t to compile metatensor/kk");
-+static_assert(std::is_same_v<int, int32_t>, "Error: int must be int32_t to compile metatensor/kk");
-+
-+template<typename T, class DeviceType>
-+using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
-+
-+template<class DeviceType>
-+PairMetatensorKokkos<DeviceType>::PairMetatensorKokkos(LAMMPS* lmp): PairMetatensor(lmp) {
-+    // this will allow us to receive the NL in a GPU-friendly format
-+    this->lmp->kokkos->neigh_transpose = 1;
-+}
-+
-+template<class DeviceType>
-+PairMetatensorKokkos<DeviceType>::~PairMetatensorKokkos() {}
-+
-+template<class DeviceType>
-+void PairMetatensorKokkos<DeviceType>::init_style() {
-+    PairMetatensor::init_style();
-+
-+    auto request = neighbor->find_request(this);
-+    request->set_kokkos_host(
-+        std::is_same_v<DeviceType, LMPHostType> &&
-+        !std::is_same_v<DeviceType, LMPDeviceType>
-+    );
-+    request->set_kokkos_device(std::is_same_v<DeviceType, LMPDeviceType>);
-+
-+    // copy type mapping from host to device, to be able to give a device pointer
-+    // to MetatensorSystemAdaptorKokkos
-+    auto type_mapping_kk_host = UnmanagedView<int32_t*, LMPHostType>(this->type_mapping, atom->ntypes + 1);
-+    this->type_mapping_kk = Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType>("type_mapping_kk", atom->ntypes + 1);
-+    Kokkos::deep_copy(this->type_mapping_kk, type_mapping_kk_host);
-+
-+    auto options = MetatensorSystemOptions{
-+        this->type_mapping_kk.data(),
-+        mts_data->max_cutoff,
-+        mts_data->check_consistency,
-+    };
-+
-+    // override the system adaptor with the kokkos version
-+    this->system_adaptor = std::make_unique<MetatensorSystemAdaptorKokkos<DeviceType>>(lmp, options);
-+
-+    // request NL with the new adaptor
-+    auto requested_nl = mts_data->model->run_method("requested_neighbor_lists");
-+    for (const auto& ivalue: requested_nl.toList()) {
-+        auto options = ivalue.get().toCustomClass<metatensor_torch::NeighborListOptionsHolder>();
-+        auto cutoff = options->engine_cutoff(mts_data->evaluation_options->length_unit());
-+        assert(cutoff <= mts_data->max_cutoff);
-+
-+        this->system_adaptor->add_nl_request(cutoff, options);
-+    }
-+}
-+
-+template<class DeviceType>
-+void PairMetatensorKokkos<DeviceType>::pick_device(torch::Device* device, const char* requested) {
-+    *device = KokkosDeviceToTorch<DeviceType>::convert();
-+
-+    if (requested != nullptr) {
-+        auto requested_str = std::string(requested);
-+        std::transform(requested_str.begin(), requested_str.end(), requested_str.begin(), ::tolower);
-+        if (c10::DeviceTypeName(device->type(), /*lower_case=*/true) != requested_str) {
-+            error->all(FLERR,
-+                "requested device '{}' does not match the device being used by kokkos '{}', "
-+                "use the non-kokkos version of this pair style to use a different "
-+                "device for the model and LAMMPS",
-+                requested, device->str()
-+            );
-+        }
-+    }
-+}
-+
-+template<class DeviceType>
-+void PairMetatensorKokkos<DeviceType>::compute(int eflag, int vflag) {
-+    if (std::getenv("LAMMPS_METATENSOR_PROFILE") != nullptr) {
-+        MetatensorTimer::enable(true);
-+    } else {
-+        MetatensorTimer::enable(false);
-+    }
-+
-+    auto _ = MetatensorTimer("PairMetatensorKokkos::compute");
-+
-+    /// Declare what we need to read from the atomKK object and what we will modify
-+    this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, X_MASK | F_MASK | TAG_MASK | TYPE_MASK | ENERGY_MASK | VIRIAL_MASK);
-+    this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, ENERGY_MASK | F_MASK | VIRIAL_MASK);
-+
-+    if (eflag || vflag) {
-+        ev_setup(eflag, vflag);
-+    } else {
-+        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
-+    }
-+
-+    if (eflag_atom) {
-+        mts_data->evaluation_options->outputs.at("energy")->per_atom = true;
-+    } else {
-+        mts_data->evaluation_options->outputs.at("energy")->per_atom = false;
-+    }
-+
-+    auto dtype = torch::kFloat64;
-+    if (mts_data->capabilities->dtype() == "float64") {
-+        dtype = torch::kFloat64;
-+    } else if (mts_data->capabilities->dtype() == "float32") {
-+        dtype = torch::kFloat32;
-+    } else {
-+        error->all(FLERR, "the model requested an unsupported dtype '{}'", mts_data->capabilities->dtype());
-+    }
-+
-+    // transform from LAMMPS to metatensor System
-+    auto system = this->system_adaptor->system_from_lmp(
-+        mts_list,
-+        static_cast<bool>(vflag_global),
-+        mts_data->remap_pairs,
-+        dtype,
-+        this->mts_data->device
-+    );
-+
-+    // only run the calculation for atoms actually in the current domain
-+    mts_data->selected_atoms_values.resize_({atom->nlocal, 2});
-+    mts_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
-+    auto options = mts_data->selected_atoms_values.options();
-+    mts_data->selected_atoms_values.index_put_(
-+        {torch::indexing::Slice(), 1},
-+        torch::arange(atom->nlocal, options)
-+    );
-+
-+    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-+        std::vector<std::string>{"system", "atom"}, mts_data->selected_atoms_values
-+    );
-+    mts_data->evaluation_options->set_selected_atoms(selected_atoms);
-+
-+    torch::IValue result_ivalue;
-+    try {
-+        auto _ = MetatensorTimer("running Model::forward");
-+        result_ivalue = mts_data->model->forward({
-+            std::vector<metatensor_torch::System>{system},
-+            mts_data->evaluation_options,
-+            mts_data->check_consistency
-+        });
-+    } catch (const std::exception& e) {
-+        error->all(FLERR, "error evaluating the torch model: {}", e.what());
-+    }
-+
-+    auto result = result_ivalue.toGenericDict();
-+    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
-+    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
-+    auto energy_tensor = energy_block->values();
-+
-+    // compute forces/virial on device with backward propagation
-+    {
-+        // reset gradients to zero before calling backward
-+        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
-+        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
-+
-+        auto _ = MetatensorTimer("running Model::backward");
-+        energy_tensor.backward(-torch::ones_like(energy_tensor));
-+    }
-+
-+    {
-+        auto _ = MetatensorTimer("storing model output in LAMMPS data structures");
-+
-+        // move results to cpu for storing
-+        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
-+        auto energy_samples = energy_block->samples();
-+
-+        // store the energy returned by the model
-+        torch::Tensor global_energy;
-+        if (eflag_atom) {
-+            assert(energy_samples->size() == 2);
-+            assert(energy_samples->names()[0] == "system");
-+            assert(energy_samples->names()[1] == "atom");
-+
-+            auto samples_values = energy_samples->values().to(torch::kCPU);
-+            auto samples = samples_values.accessor<int32_t, 2>();
-+
-+            int64_t n_atoms = atom->nlocal + atom->nghost;
-+            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
-+
-+            auto energies = energy_detached.accessor<double, 2>();
-+            for (int64_t i=0; i<energy_samples->count(); i++) {
-+                assert(samples[i][0] == 0);
-+                // handle potentially out of order samples in
-+                // the per-atom energy tensor
-+                auto atom_i = samples[i][1];
-+                assert(atom_i < n_atoms);
-+                eatom[atom_i] += energies[i][0];
-+            }
-+
-+            global_energy = energy_detached.sum(0);
-+            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
-+        } else {
-+            assert(energy_samples->size() == 1);
-+            assert(energy_samples->names()[0] == "system");
-+
-+            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
-+            global_energy = energy_detached.reshape({1});
-+        }
-+
-+        if (eflag_global) {
-+            eng_vdwl += global_energy.item<double>();
-+        }
-+
-+        // store forces/virial
-+        auto forces_tensor = this->system_adaptor->positions.grad().contiguous();
-+        assert(forces_tensor.scalar_type() == torch::kFloat64);
-+
-+        auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
-+        auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
-+            forces_tensor.template data_ptr<double>(),
-+            forces_tensor.size(0), 3
-+        );
-+
-+        Kokkos::parallel_for(
-+            system->size(),
-+            KOKKOS_LAMBDA(size_t i) {
-+                forces_lammps_kk(i, 0) += forces_metatensor_kk(i, 0);
-+                forces_lammps_kk(i, 1) += forces_metatensor_kk(i, 1);
-+                forces_lammps_kk(i, 2) += forces_metatensor_kk(i, 2);
-+            }
-+        );
-+
-+        assert(!vflag_fdotr);
-+
-+        if (vflag_global) {
-+            auto virial_tensor = this->system_adaptor->strain.grad().to(torch::kCPU);
-+            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
-+            auto predicted_virial = virial_tensor.template accessor<double, 2>();
-+
-+            virial[0] += predicted_virial[0][0];
-+            virial[1] += predicted_virial[1][1];
-+            virial[2] += predicted_virial[2][2];
-+
-+            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
-+            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
-+            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
-+        }
-+
-+        if (vflag_atom) {
-+            error->all(FLERR, "per atom virial is not implemented");
-+        }
-+    }
-+}
-+
-+namespace LAMMPS_NS {
-+template class PairMetatensorKokkos<LMPDeviceType>;
-+#ifdef LMP_KOKKOS_GPU
-+template class PairMetatensorKokkos<LMPHostType>;
-+#endif
-+}
-diff --git a/src/KOKKOS/pair_metatensor_kokkos.h b/src/KOKKOS/pair_metatensor_kokkos.h
-new file mode 100644
-index 0000000000..1463574f9d
---- /dev/null
-+++ b/src/KOKKOS/pair_metatensor_kokkos.h
-@@ -0,0 +1,53 @@
-+/* -*- c++ -*- ----------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+#ifdef PAIR_CLASS
-+// clang-format off
-+PairStyle(metatensor/kk, PairMetatensorKokkos<LMPDeviceType>);
-+// clang-format on
-+#else
-+
-+#ifndef LMP_PAIR_METATENSOR_KOKKOS_H
-+#define LMP_PAIR_METATENSOR_KOKKOS_H
-+
-+#include "pair_kokkos.h"
-+#include "pair_metatensor.h"
-+
-+namespace LAMMPS_NS {
-+
-+template<class DeviceType>
-+class MetatensorSystemAdaptorKokkos;
-+
-+template<class DeviceType>
-+struct PairMetatensorDataKokkos;
-+
-+/// I noticed that most other kokkos packages inherit from their non-kokkos
-+/// counterparts. It doesn't look like a good idea to me because
-+/// they end up overriding everything... Not doing it here for now.
-+template<class DeviceType>
-+class PairMetatensorKokkos : public PairMetatensor {
-+public:
-+    PairMetatensorKokkos(class LAMMPS *);
-+    ~PairMetatensorKokkos();
-+
-+    void init_style() override;
-+    void compute(int eflag, int vflag) override;
-+private:
-+    void pick_device(c10::Device* device, const char* requested) override;
-+
-+    Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType> type_mapping_kk;
-+};
-+
-+}    // namespace LAMMPS_NS
-+
-+#endif
-+#endif
-diff --git a/src/ML-METATENSOR/Install.sh b/src/ML-METATENSOR/Install.sh
-new file mode 100755
-index 0000000000..e590c689d7
---- /dev/null
-+++ b/src/ML-METATENSOR/Install.sh
-@@ -0,0 +1,64 @@
-+# Install/unInstall package files in LAMMPS
-+# mode = 0/1/2 for uninstall/install/update
-+
-+mode=$1
-+
-+# enforce using portable C locale
-+LC_ALL=C
-+export LC_ALL
-+
-+# arg1 = file, arg2 = file it depends on
-+
-+action () {
-+  if (test $mode = 0) then
-+    rm -f ../$1
-+  elif (! cmp -s $1 ../$1) then
-+    if (test -z "$2" || test -e ../$2) then
-+      cp $1 ..
-+      if (test $mode = 2) then
-+        echo "  updating src/$1"
-+      fi
-+    fi
-+  elif (test -n "$2") then
-+    if (test ! -e ../$2) then
-+      rm -f ../$1
-+    fi
-+  fi
-+}
-+
-+# all package files with no dependencies
-+
-+for file in *.cpp *.h; do
-+  test -f ${file} && action $file
-+done
-+
-+# edit 2 Makefile.package files to include/exclude package info
-+
-+if (test $1 = 1) then
-+
-+  if (test -e ../Makefile.package) then
-+    sed -i -e 's/[^ \t]*metatensor[^ \t]* //' ../Makefile.package
-+    sed -i -e 's|^PKG_SYSINC =[ \t]*|&$(metatensor_SYSINC) |' ../Makefile.package
-+    sed -i -e 's|^PKG_SYSLIB =[ \t]*|&$(metatensor_SYSLIB) |' ../Makefile.package
-+    sed -i -e 's|^PKG_SYSPATH =[ \t]*|&$(metatensor_SYSPATH) |' ../Makefile.package
-+  fi
-+
-+  if (test -e ../Makefile.package.settings) then
-+    sed -i -e '/^[ \t]*include.*metatensor.*$/d' ../Makefile.package.settings
-+    # multiline form needed for BSD sed on Macs
-+    sed -i -e '4 i \
-+include ..\/..\/lib\/metatensor\/Makefile.lammps\
-+' ../Makefile.package.settings
-+  fi
-+
-+elif (test $1 = 0) then
-+
-+  if (test -e ../Makefile.package) then
-+    sed -i -e 's/[^ \t]*metatensor[^ \t]* //' ../Makefile.package
-+  fi
-+
-+  if (test -e ../Makefile.package.settings) then
-+    sed -i -e '/^[ \t]*include.*metatensor.*$/d' ../Makefile.package.settings
-+  fi
-+
-+fi
-diff --git a/src/ML-METATENSOR/metatensor_system.cpp b/src/ML-METATENSOR/metatensor_system.cpp
-new file mode 100644
-index 0000000000..3c8ed68caa
---- /dev/null
-+++ b/src/ML-METATENSOR/metatensor_system.cpp
-@@ -0,0 +1,560 @@
-+/* ----------------------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+/* ----------------------------------------------------------------------
-+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
-+------------------------------------------------------------------------- */
-+#include "metatensor_system.h"
-+
-+#include "atom.h"
-+#include "domain.h"
-+#include "error.h"
-+
-+#include "neigh_list.h"
-+
-+#include "./metatensor_timer.h"
-+
-+using namespace LAMMPS_NS;
-+
-+MetatensorSystemAdaptor::MetatensorSystemAdaptor(LAMMPS *lmp, MetatensorSystemOptions options):
-+    Pointers(lmp),
-+    options_(std::move(options)),
-+    caches_(),
-+    atomic_types_(torch::zeros({0}, torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)))
-+{
-+    auto tensor_options = torch::TensorOptions()
-+        .dtype(torch::kFloat64)
-+        .device(torch::kCPU)
-+        .requires_grad(true);
-+
-+    this->strain = torch::eye(3, tensor_options);
-+}
-+
-+MetatensorSystemAdaptor::~MetatensorSystemAdaptor() {}
-+
-+void MetatensorSystemAdaptor::add_nl_request(double cutoff, metatensor_torch::NeighborListOptions request) {
-+    if (cutoff > options_.interaction_range) {
-+        error->all(FLERR,
-+            "Invalid metatensor model: one of the requested neighbor lists "
-+            "has a cutoff ({}) larger than the model interaction range ({})",
-+            cutoff, options_.interaction_range
-+        );
-+    } else if (cutoff < 0 || !std::isfinite(cutoff)) {
-+        error->all(FLERR,
-+            "model requested an invalid cutoff for neighbors list: {} "
-+            "(cutoff in model units is {})",
-+            cutoff, request->cutoff()
-+        );
-+    }
-+
-+    caches_.push_back({
-+        cutoff,
-+        request,
-+        /*known_samples = */ {},
-+        /*samples = */ {},
-+        /*distances_f64 = */ {},
-+        /*distances_f32 = */ {},
-+    });
-+}
-+
-+
-+static std::array<int32_t, 3> cell_shifts(
-+    const std::array<std::array<double, 3>, 3>& cell_inv,
-+    const std::array<double, 3>& pair_shift
-+) {
-+    auto shift_a = static_cast<int32_t>(std::round(
-+        cell_inv[0][0] * pair_shift[0] +
-+        cell_inv[0][1] * pair_shift[1] +
-+        cell_inv[0][2] * pair_shift[2]
-+    ));
-+    auto shift_b = static_cast<int32_t>(std::round(
-+        cell_inv[1][0] * pair_shift[0] +
-+        cell_inv[1][1] * pair_shift[1] +
-+        cell_inv[1][2] * pair_shift[2]
-+    ));
-+    auto shift_c = static_cast<int32_t>(std::round(
-+        cell_inv[2][0] * pair_shift[0] +
-+        cell_inv[2][1] * pair_shift[1] +
-+        cell_inv[2][2] * pair_shift[2]
-+    ));
-+
-+    return {shift_a, shift_b, shift_c};
-+}
-+
-+
-+void MetatensorSystemAdaptor::setup_neighbors_remap(metatensor_torch::System& system, NeighList *list) {
-+    auto _ = MetatensorTimer("converting neighbors with ghosts remapping");
-+    auto dtype = system->positions().scalar_type();
-+    auto device = system->positions().device();
-+
-+    double** x = atom->x;
-+    auto total_n_atoms = atom->nlocal + atom->nghost;
-+
-+    auto cell_inv_tensor = system->cell().inverse().t().to(torch::kCPU).to(torch::kFloat64);
-+    auto cell_inv_accessor = cell_inv_tensor.accessor<double, 2>();
-+    auto cell_inv = std::array<std::array<double, 3>, 3>{{
-+        {{cell_inv_accessor[0][0], cell_inv_accessor[0][1], cell_inv_accessor[0][2]}},
-+        {{cell_inv_accessor[1][0], cell_inv_accessor[1][1], cell_inv_accessor[1][2]}},
-+        {{cell_inv_accessor[2][0], cell_inv_accessor[2][1], cell_inv_accessor[2][2]}},
-+    }};
-+
-+    {
-+        auto _ = MetatensorTimer("identifying ghosts and real atoms");
-+
-+        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
-+        // atoms which are periodic images of local atoms back to the local atoms.
-+        //
-+        // Metatensor expects pairs corresponding to periodic atoms to be between
-+        // the main atoms, but using the actual distance vector between the atom and
-+        // the ghost.
-+        original_atom_id_.clear();
-+        original_atom_id_.reserve(total_n_atoms);
-+
-+        // identify all local atom by their LAMMPS atom tag.
-+        local_atoms_tags_.clear();
-+        for (int i=0; i<atom->nlocal; i++) {
-+            original_atom_id_.emplace_back(i);
-+            local_atoms_tags_.emplace(atom->tag[i], i);
-+        }
-+
-+        // now loop over ghosts & map them back to the main cell if needed
-+        ghost_atoms_tags_.clear();
-+        for (int i=atom->nlocal; i<total_n_atoms; i++) {
-+            auto tag = atom->tag[i];
-+            auto it = local_atoms_tags_.find(tag);
-+            if (it != local_atoms_tags_.end()) {
-+                // this is the periodic image of an atom already owned by this domain
-+                original_atom_id_.emplace_back(it->second);
-+            } else {
-+                // this can either be a periodic image of an atom owned by another
-+                // domain, or directly an atom from another domain. Since we can not
-+                // really distinguish between these, we take the first atom as the
-+                // "main" one and remap all atoms with the same tag to the first one
-+                auto it = ghost_atoms_tags_.find(tag);
-+                if (it != ghost_atoms_tags_.end()) {
-+                    // we already found this atom elsewhere in the system
-+                    original_atom_id_.emplace_back(it->second);
-+                } else {
-+                    // this is the first time we are seeing this atom
-+                    original_atom_id_.emplace_back(i);
-+                    ghost_atoms_tags_.emplace(tag, i);
-+                }
-+            }
-+        }
-+    }
-+
-+    for (auto& cache: caches_) {
-+        {
-+            auto _ = MetatensorTimer("filtering LAMMPS neighbor list");
-+
-+            auto cutoff2 = cache.cutoff * cache.cutoff;
-+            auto full_list = cache.options->full_list();
-+
-+            // convert from LAMMPS neighbors list to metatensor format
-+            cache.known_samples.clear();
-+            cache.samples.clear();
-+            cache.distances_f32.clear();
-+            cache.distances_f64.clear();
-+            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
-+                auto atom_i = list->ilist[ii];
-+                assert(atom_i < total_n_atoms);
-+                auto original_atom_i = original_atom_id_[atom_i];
-+
-+                auto neighbors = list->firstneigh[ii];
-+                for (int jj=0; jj<list->numneigh[ii]; jj++) {
-+                    auto atom_j = neighbors[jj] & NEIGHMASK;
-+                    assert(atom_j < total_n_atoms);
-+                    auto original_atom_j = original_atom_id_[atom_j];
-+
-+                    if (!full_list && original_atom_i > original_atom_j) {
-+                        // Remove extra pairs if the model requested half-lists
-+                        continue;
-+                    }
-+
-+                    auto distance = std::array<double, 3>{
-+                        x[atom_j][0] - x[atom_i][0],
-+                        x[atom_j][1] - x[atom_i][1],
-+                        x[atom_j][2] - x[atom_i][2],
-+                    };
-+
-+                    auto distance2 = (
-+                        distance[0] * distance[0] +
-+                        distance[1] * distance[1] +
-+                        distance[2] * distance[2]
-+                    );
-+                    if (distance2 > cutoff2) {
-+                        // LAMMPS neighbors list contains some pairs after the
-+                        // cutoff, we filter them here
-+                        continue;
-+                    }
-+
-+                    // Compute the cell shift for the pair.
-+                    auto shift_i = std::array<double, 3>{
-+                        x[atom_i][0] - x[original_atom_i][0],
-+                        x[atom_i][1] - x[original_atom_i][1],
-+                        x[atom_i][2] - x[original_atom_i][2],
-+                    };
-+                    auto shift_j = std::array<double, 3>{
-+                        x[atom_j][0] - x[original_atom_j][0],
-+                        x[atom_j][1] - x[original_atom_j][1],
-+                        x[atom_j][2] - x[original_atom_j][2],
-+                    };
-+                    auto pair_shift = std::array<double, 3>{
-+                        shift_j[0] - shift_i[0],
-+                        shift_j[1] - shift_i[1],
-+                        shift_j[2] - shift_i[2],
-+                    };
-+
-+                    auto shift = std::array<int32_t, 3>{0, 0, 0};
-+                    if (pair_shift[0] != 0 || pair_shift[1] != 0 || pair_shift[2] != 0) {
-+                        shift = cell_shifts(cell_inv, pair_shift);
-+
-+                        if (!full_list && original_atom_i == original_atom_j) {
-+                            // If a half neighbors list has been requested, do
-+                            // not include the same pair between an atom and
-+                            // it's periodic image twice with opposite cell
-+                            // shifts (e.g. [1, -1, 1] and [-1, 1, -1]).
-+                            //
-+                            // Instead we pick pairs in the positive plan of
-+                            // shifts.
-+                            if (shift[0] + shift[1] + shift[2] < 0) {
-+                                // drop shifts on the negative half-space
-+                                continue;
-+                            }
-+
-+                            if ((shift[0] + shift[1] + shift[2] == 0)
-+                                && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0))) {
-+                                // drop shifts in the negative half plane or the
-+                                // negative shift[1] axis.
-+                                //
-+                                // See below for a graphical representation: we are
-+                                // keeping the shifts indicated with `O` and
-+                                // dropping the ones indicated with `X`
-+                                //
-+                                //  O O O │ O O O
-+                                //  O O O │ O O O
-+                                //  O O O │ O O O
-+                                // ─X─X─X─┼─O─O─O─
-+                                //  X X X │ X X X
-+                                //  X X X │ X X X
-+                                //  X X X │ X X X
-+                                continue;
-+                            }
-+                        }
-+                    }
-+
-+                    auto sample = std::array<int32_t, 5>{
-+                        original_atom_i,
-+                        original_atom_j,
-+                        shift[0],
-+                        shift[1],
-+                        shift[2],
-+                    };
-+
-+                    // only add the pair if it is not already known. The same pair
-+                    // can occur multiple time between two periodic ghosts shifted
-+                    // around by the same amount, but we only want one of these pairs.
-+                    if (cache.known_samples.insert(sample).second) {
-+                        cache.samples.push_back(sample);
-+
-+                        if (dtype == torch::kFloat64) {
-+                            cache.distances_f64.push_back(distance);
-+                        } else if (dtype == torch::kFloat32) {
-+                            cache.distances_f32.push_back({
-+                                static_cast<float>(distance[0]),
-+                                static_cast<float>(distance[1]),
-+                                static_cast<float>(distance[2])
-+                            });
-+                        } else {
-+                            // should be unreachable
-+                            error->all(FLERR, "invalid dtype, this is a bug");
-+                        }
-+                    }
-+                }
-+            }
-+        }
-+
-+        int64_t n_pairs = cache.samples.size();
-+        auto samples_values = torch::from_blob(
-+            reinterpret_cast<int32_t*>(cache.samples.data()),
-+            {n_pairs, 5},
-+            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-+        );
-+
-+        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
-+        {
-+            auto _ = MetatensorTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
-+            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-+                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-+                samples_values
-+            );
-+        }
-+
-+        auto distances_vectors = torch::Tensor();
-+        if (dtype == torch::kFloat64) {
-+            distances_vectors = torch::from_blob(
-+                cache.distances_f64.data(),
-+                {n_pairs, 3, 1},
-+                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
-+            );
-+        } else if (dtype == torch::kFloat32) {
-+            distances_vectors = torch::from_blob(
-+                cache.distances_f32.data(),
-+                {n_pairs, 3, 1},
-+                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
-+            );
-+        } else {
-+            // should be unreachable
-+            error->all(FLERR, "invalid dtype, this is a bug");
-+        }
-+
-+        {
-+            auto _ = MetatensorTimer("moving neighbor data to dtype/device");
-+            distances_vectors = distances_vectors.to(dtype).to(device);
-+            samples = samples->to(device);
-+        }
-+
-+        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
-+        {
-+            auto _ = MetatensorTimer("creating neighbors TensorBlock");
-+            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
-+                distances_vectors,
-+                samples,
-+                std::vector<metatensor_torch::TorchLabels>{
-+                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
-+                },
-+                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
-+            );
-+        }
-+
-+        metatensor_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-+        system->add_neighbor_list(cache.options, neighbors);
-+    }
-+}
-+
-+void MetatensorSystemAdaptor::setup_neighbors_no_remap(metatensor_torch::System& system, NeighList *list) {
-+    auto _ = MetatensorTimer("converting neighbors without ghosts remapping");
-+
-+    auto dtype = system->positions().scalar_type();
-+    auto device = system->positions().device();
-+
-+    double** x = atom->x;
-+
-+    for (auto& cache: caches_) {
-+        {
-+            auto _ = MetatensorTimer("filtering LAMMPS neighbor list");
-+
-+            auto cutoff2 = cache.cutoff * cache.cutoff;
-+            auto full_list = cache.options->full_list();
-+
-+            // convert from LAMMPS neighbors list to metatensor format
-+            cache.known_samples.clear();
-+            cache.samples.clear();
-+            cache.distances_f32.clear();
-+            cache.distances_f64.clear();
-+            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
-+                auto atom_i = list->ilist[ii];
-+
-+                auto neighbors = list->firstneigh[ii];
-+                for (int jj=0; jj<list->numneigh[ii]; jj++) {
-+                    auto atom_j = neighbors[jj];
-+
-+                    if (!full_list && atom_i > atom_j) {
-+                        // Remove extra pairs if the model requested half-lists
-+                        continue;
-+                    }
-+
-+                    auto distance = std::array<double, 3>{
-+                        x[atom_j][0] - x[atom_i][0],
-+                        x[atom_j][1] - x[atom_i][1],
-+                        x[atom_j][2] - x[atom_i][2],
-+                    };
-+
-+                    auto distance2 = (
-+                        distance[0] * distance[0] +
-+                        distance[1] * distance[1] +
-+                        distance[2] * distance[2]
-+                    );
-+                    if (distance2 > cutoff2) {
-+                        // LAMMPS neighbors list contains some pairs after the
-+                        // cutoff, we filter them here
-+                        continue;
-+                    }
-+
-+                    auto sample = std::array<int32_t, 5>{atom_i, atom_j, 0, 0, 0};
-+
-+
-+                    cache.samples.push_back(sample);
-+
-+                    if (dtype == torch::kFloat64) {
-+                        cache.distances_f64.push_back(distance);
-+                    } else if (dtype == torch::kFloat32) {
-+                        cache.distances_f32.push_back({
-+                            static_cast<float>(distance[0]),
-+                            static_cast<float>(distance[1]),
-+                            static_cast<float>(distance[2])
-+                        });
-+                    } else {
-+                        // should be unreachable
-+                        error->all(FLERR, "invalid dtype, this is a bug");
-+                    }
-+                }
-+            }
-+        }
-+
-+        int64_t n_pairs = cache.samples.size();
-+        auto samples_values = torch::from_blob(
-+            reinterpret_cast<int32_t*>(cache.samples.data()),
-+            {n_pairs, 5},
-+            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-+        );
-+
-+        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
-+        {
-+            auto _ = MetatensorTimer("creating samples Labels (" +  std::to_string(n_pairs) +" pairs)");
-+            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-+                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-+                samples_values
-+            );
-+        }
-+
-+        auto distances_vectors = torch::Tensor();
-+        if (dtype == torch::kFloat64) {
-+            distances_vectors = torch::from_blob(
-+                cache.distances_f64.data(),
-+                {n_pairs, 3, 1},
-+                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
-+            );
-+        } else if (dtype == torch::kFloat32) {
-+            distances_vectors = torch::from_blob(
-+                cache.distances_f32.data(),
-+                {n_pairs, 3, 1},
-+                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
-+            );
-+        } else {
-+            // should be unreachable
-+            error->all(FLERR, "invalid dtype, this is a bug");
-+        }
-+
-+        {
-+            auto _ = MetatensorTimer("moving neighbor data to dtype/device");
-+            distances_vectors = distances_vectors.to(dtype).to(device);
-+            samples = samples->to(device);
-+        }
-+
-+        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
-+        {
-+            auto _ = MetatensorTimer("creating neighbors TensorBlock");
-+            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
-+                distances_vectors,
-+                samples,
-+                std::vector<metatensor_torch::TorchLabels>{
-+                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
-+                },
-+                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
-+            );
-+        }
-+
-+        metatensor_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-+        system->add_neighbor_list(cache.options, neighbors);
-+    }
-+}
-+
-+
-+metatensor_torch::System MetatensorSystemAdaptor::system_from_lmp(
-+    NeighList* list,
-+    bool do_virial,
-+    bool remap_pairs,
-+    torch::ScalarType dtype,
-+    torch::Device device
-+) {
-+    auto _ = MetatensorTimer("creating System from LAMMPS data");
-+
-+    double** x = atom->x;
-+    auto total_n_atoms = atom->nlocal + atom->nghost;
-+
-+    atomic_types_.resize_({total_n_atoms});
-+    for (int i=0; i<total_n_atoms; i++) {
-+        atomic_types_[i] = options_.types_mapping[atom->type[i]];
-+    }
-+
-+    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU);
-+
-+    // atom->x contains "real" and then ghost atoms, in that order
-+    this->positions = torch::from_blob(
-+        *x, {total_n_atoms, 3},
-+        // requires_grad=true since we always need gradients w.r.t. positions
-+        tensor_options.requires_grad(true)
-+    );
-+
-+    auto cell = torch::zeros({3, 3}, tensor_options);
-+    cell[0][0] = domain->xprd;
-+
-+    cell[1][0] = domain->xy;
-+    cell[1][1] = domain->yprd;
-+
-+    cell[2][0] = domain->xz;
-+    cell[2][1] = domain->yz;
-+    cell[2][2] = domain->zprd;
-+
-+    auto system_positions = this->positions.to(dtype).to(device);
-+    cell = cell.to(dtype).to(device);
-+
-+    if (do_virial) {
-+        auto model_strain = this->strain.to(dtype).to(device);
-+
-+        // pretend to scale positions/cell by the strain so that
-+        // it enters the computational graph.
-+        system_positions = system_positions.matmul(model_strain);
-+        cell = cell.matmul(model_strain);
-+    }
-+
-+    // Periodic boundary conditions handling.
-+    // While Metatensor atomistic models can support mixed PBC settings, we
-+    // currently assume that the system is fully periodic and we throw an error
-+    // otherwise
-+    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-+        error->all(FLERR, "pair_metatensor requires a fully periodic system");
-+    }
-+    auto pbc = torch::tensor(
-+        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
-+        torch::TensorOptions().dtype(torch::kBool).device(device)
-+    );
-+
-+    // Note that something like this:
-+    //     cell.index_put_(
-+    //         {torch::logical_not(pbc)},
-+    //         torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(device))
-+    //     );
-+    //
-+    // would allow creating System with non-periodic directions, but we're using
-+    // the inverse of the cell matrix to filter the neighbor list, and the cell
-+    // matrix becomes singular if any of its rows are zero. This requires some
-+    // changes in the neighbor list filtering code to handle non-periodic
-+    // directions.
-+
-+    auto system = torch::make_intrusive<metatensor_torch::SystemHolder>(
-+        atomic_types_.to(device),
-+        system_positions,
-+        cell,
-+        pbc
-+    );
-+
-+    if (remap_pairs) {
-+        this->setup_neighbors_remap(system, list);
-+    } else {
-+        this->setup_neighbors_no_remap(system, list);
-+    }
-+
-+    return system;
-+}
-diff --git a/src/ML-METATENSOR/metatensor_system.h b/src/ML-METATENSOR/metatensor_system.h
-new file mode 100644
-index 0000000000..cebafd4a92
---- /dev/null
-+++ b/src/ML-METATENSOR/metatensor_system.h
-@@ -0,0 +1,143 @@
-+/* -*- c++ -*- ----------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+#ifndef LMP_METATENSOR_SYSTEM_H
-+#define LMP_METATENSOR_SYSTEM_H
-+
-+#include <vector>
-+#include <array>
-+#include <unordered_set>
-+
-+#include "pointers.h"
-+#include "pair.h"
-+#include "neigh_list.h"
-+
-+#include <metatensor/torch/atomistic.hpp>
-+
-+
-+namespace LAMMPS_NS {
-+
-+struct MetatensorSystemOptions {
-+    // Mapping from LAMMPS types to metatensor types.
-+    // If used with kokkos, this should be a device pointer
-+    int32_t* types_mapping;
-+    // interaction range of the model, in LAMMPS units
-+    double interaction_range;
-+    // should we run extra checks on the neighbor lists?
-+    bool check_consistency;
-+};
-+
-+// data for metatensor neighbors lists
-+struct MetatensorNeighborsData {
-+    // single neighbors sample containing [i, j, S_a, S_b, S_c]
-+    using sample_t = std::array<int32_t, 5>;
-+
-+    struct SampleHasher {
-+        static void hash_combine(std::size_t& seed, const int32_t& v) {
-+            seed ^= std::hash<int32_t>()(v) + 0x9e3779b9 + (seed<<6) + (seed>>2);
-+        }
-+
-+        size_t operator()(const sample_t& s) const {
-+            size_t hash = 0;
-+            hash_combine(hash, s[0]);
-+            hash_combine(hash, s[1]);
-+            hash_combine(hash, s[2]);
-+            hash_combine(hash, s[3]);
-+            hash_combine(hash, s[4]);
-+            return hash;
-+        }
-+    };
-+
-+    // cutoff for this NL in LAMMPS units
-+    double cutoff;
-+    // options of the NL as requested by the model
-+    metatensor_torch::NeighborListOptions options;
-+
-+    // Below are cached allocations for the LAMMPS -> metatensor NL translation
-+    // TODO: report memory usage for these?
-+
-+    // we keep the set of samples twice: once in `known_samples` to remove
-+    // duplicated pairs, and once in `samples` in a format that can be
-+    // used to create a torch::Tensor.
-+    std::unordered_set<sample_t, SampleHasher> known_samples;
-+    std::vector<sample_t> samples;
-+    // pairs distances vectors
-+    std::vector<std::array<double, 3>> distances_f64;
-+    std::vector<std::array<float, 3>> distances_f32;
-+};
-+
-+class MetatensorSystemAdaptor : public Pointers {
-+public:
-+    MetatensorSystemAdaptor(LAMMPS *lmp, MetatensorSystemOptions options);
-+
-+    virtual ~MetatensorSystemAdaptor();
-+
-+    void add_nl_request(double cutoff, metatensor_torch::NeighborListOptions request);
-+
-+    // Create a metatensor system matching the LAMMPS system data
-+    virtual metatensor_torch::System system_from_lmp(
-+        NeighList* list,
-+        bool do_virial,
-+        bool remap_pairs,
-+        torch::ScalarType dtype,
-+        torch::Device device
-+    );
-+
-+    // Explicit strain for virial calculations. This uses the same dtype/device
-+    // as LAMMPS data (positions, …)
-+    torch::Tensor strain;
-+    // keep the positions as coming from LAMMPS (before any dtype/device
-+    // conversion) to access its gradient
-+    torch::Tensor positions;
-+
-+ protected:
-+    // setup the metatensor neighbors list from the internal LAMMPS one,
-+    // remapping periodic ghosts to the corresponding local atom
-+    void setup_neighbors_remap(metatensor_torch::System& system, NeighList* list);
-+
-+    // setup the metatensor neighbors list from the internal LAMMPS one,
-+    // WITHOUT remapping periodic ghosts to the corresponding local atom.
-+    //
-+    // This produces a larger NL but skips the cost of the remapping
-+    void setup_neighbors_no_remap(metatensor_torch::System& system, NeighList* list);
-+
-+    // options for this system adaptor
-+    MetatensorSystemOptions options_;
-+
-+    // allocations caches for all the NL requested by the model
-+    std::vector<MetatensorNeighborsData> caches_;
-+    // allocation cache for the atomic types in the system
-+    torch::Tensor atomic_types_;
-+    // allocation cache holding the "original atom" id for all atoms in the
-+    // system. This is the same as the atom id for all local atoms. For ghost
-+    // atoms, this is either the id of the corresponding local atom if the ghost
-+    // is a periodic image of a local atom, the id of the first ghost we found
-+    // with a given atom tag if the ghost is a periodic image of another ghost;
-+    // or the id of the ghost in all other cases.
-+    std::vector<int> original_atom_id_;
-+    // allocation cache holding the map from atom tag to atom id for local
-+    // atoms.
-+    std::unordered_map<tagint, int> local_atoms_tags_;
-+    // allocation cache holding the map from atom tag to atom id for ghost
-+    // atoms. When there are multiple periodic images of the same atom, only one
-+    // will be included here.
-+    std::unordered_map<tagint, int> ghost_atoms_tags_;
-+
-+    // TODO: should we use LAMMPS allocations/deallocation facilities for the
-+    // allocation caches? If we don't, should we report memory usage from the
-+    // allocations caches to LAMMPS one way or another?
-+};
-+
-+}    // namespace LAMMPS_NS
-+
-+#endif
-diff --git a/src/ML-METATENSOR/metatensor_timer.cpp b/src/ML-METATENSOR/metatensor_timer.cpp
-new file mode 100644
-index 0000000000..8e269f95b6
---- /dev/null
-+++ b/src/ML-METATENSOR/metatensor_timer.cpp
-@@ -0,0 +1,63 @@
-+#include <mutex>
-+#include <iostream>
-+
-+#include "metatensor_timer.h"
-+
-+using namespace LAMMPS_NS;
-+
-+// lock to protect the other static from concurrent modification
-+static std::mutex METATENSOR_TIMER_MUTEX = {};
-+// depth of the timer, i.e. how many different timers are alive right now
-+static int64_t METATENSOR_TIMER_DEPTH = -1;
-+// strictly increasing timer counter, to know if a new one was created inside
-+// the scope of the current one.
-+static uint64_t METATENSOR_TIMER_COUNTER = 0;
-+// Is profiling enabled?
-+static bool METATENSOR_TIMER_ENABLED = false;
-+
-+
-+void MetatensorTimer::enable(bool toggle) {
-+    auto guard_ = std::lock_guard(METATENSOR_TIMER_MUTEX);
-+
-+    METATENSOR_TIMER_ENABLED = toggle;
-+}
-+
-+
-+MetatensorTimer::MetatensorTimer(std::string name):
-+    enabled_(false),
-+    name_(std::move(name))
-+{
-+    auto guard_ = std::lock_guard(METATENSOR_TIMER_MUTEX);
-+    if (METATENSOR_TIMER_ENABLED) {
-+        METATENSOR_TIMER_DEPTH += 1;
-+        METATENSOR_TIMER_COUNTER += 1;
-+
-+        this->enabled_ = true;
-+        this->starting_counter_ = METATENSOR_TIMER_COUNTER;
-+        this->start_ = std::chrono::high_resolution_clock::now();
-+        auto indent = std::string(METATENSOR_TIMER_DEPTH * 3, ' ');
-+
-+        if (METATENSOR_TIMER_DEPTH == 0) {
-+            std::cerr << "\n";
-+        }
-+
-+        std::cerr << "\n" << indent << this->name_ << " ...";
-+    }
-+}
-+
-+MetatensorTimer::~MetatensorTimer() {
-+    auto guard_ = std::lock_guard(METATENSOR_TIMER_MUTEX);
-+
-+    if (METATENSOR_TIMER_ENABLED && this->enabled_) {
-+        auto stop = std::chrono::high_resolution_clock::now();
-+        auto elapsed = std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start_).count();
-+
-+        if (METATENSOR_TIMER_COUNTER != starting_counter_) {
-+            auto indent = std::string(METATENSOR_TIMER_DEPTH * 3, ' ');
-+            std::cerr << "\n" << indent << this->name_;
-+        }
-+
-+        std::cerr << " took " << elapsed / 1e6 << "ms" << std::flush;
-+        METATENSOR_TIMER_DEPTH -= 1;
-+    }
-+}
-diff --git a/src/ML-METATENSOR/metatensor_timer.h b/src/ML-METATENSOR/metatensor_timer.h
-new file mode 100644
-index 0000000000..2eac972bc8
---- /dev/null
-+++ b/src/ML-METATENSOR/metatensor_timer.h
-@@ -0,0 +1,42 @@
-+/* -*- c++ -*- ----------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+#ifndef LMP_METATENSOR_TIMER_H
-+#define LMP_METATENSOR_TIMER_H
-+
-+#include <chrono>
-+#include <string>
-+
-+namespace LAMMPS_NS {
-+
-+/// Simple timer for profiling the LAMMPS/Metatensor integration. This starts
-+/// the timer when created, and print the elapsed time to stderr when going out
-+/// of scope.
-+class MetatensorTimer {
-+public:
-+    MetatensorTimer(std::string name);
-+    ~MetatensorTimer();
-+
-+    // enable/disable profiling
-+    static void enable(bool toggle);
-+
-+private:
-+    bool enabled_;
-+    std::string name_;
-+    size_t starting_counter_;
-+    std::chrono::time_point<std::chrono::high_resolution_clock> start_;
-+};
-+
-+}    // namespace LAMMPS_NS
-+
-+#endif
-diff --git a/src/ML-METATENSOR/metatensor_types.cpp b/src/ML-METATENSOR/metatensor_types.cpp
-new file mode 100644
-index 0000000000..3a017898a3
---- /dev/null
-+++ b/src/ML-METATENSOR/metatensor_types.cpp
-@@ -0,0 +1,97 @@
-+/* ----------------------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+/* ----------------------------------------------------------------------
-+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
-+------------------------------------------------------------------------- */
-+#include "metatensor_types.h"
-+
-+#include "citeme.h"
-+#include "comm.h"
-+#include "error.h"
-+
-+using namespace LAMMPS_NS;
-+
-+PairMetatensorData::PairMetatensorData(std::string length_unit, std::string energy_unit):
-+    device(torch::kCPU),
-+    check_consistency(false),
-+    remap_pairs(true),
-+    max_cutoff(-1)
-+{
-+    auto options = torch::TensorOptions().dtype(torch::kInt32);
-+    this->selected_atoms_values = torch::zeros({0, 2}, options);
-+
-+    // Initialize evaluation_options
-+    this->evaluation_options = torch::make_intrusive<metatensor_torch::ModelEvaluationOptionsHolder>();
-+    this->evaluation_options->set_length_unit(std::move(length_unit));
-+
-+    auto output = torch::make_intrusive<metatensor_torch::ModelOutputHolder>();
-+    output->explicit_gradients = {};
-+    output->set_quantity("energy");
-+    output->set_unit(std::move(energy_unit));
-+    output->per_atom = false;
-+
-+    this->evaluation_options->outputs.insert("energy", output);
-+}
-+
-+void PairMetatensorData::load_model(
-+   LAMMPS* lmp,
-+   const char* path,
-+   const char* extensions_directory
-+) {
-+   // TODO: seach for the model & extensions inside `$LAMMPS_POTENTIALS`?
-+
-+   if (this->model != nullptr) {
-+       lmp->error->all(FLERR, "torch model is already loaded");
-+   }
-+
-+   torch::optional<std::string> extensions = torch::nullopt;
-+   if (extensions_directory != nullptr) {
-+       extensions = std::string(extensions_directory);
-+   }
-+
-+   try {
-+       this->model = std::make_unique<torch::jit::Module>(
-+           metatensor_torch::load_atomistic_model(path, extensions)
-+       );
-+   } catch (const c10::Error& e) {
-+       lmp->error->all(FLERR, "failed to load metatensor model at '{}': {}", path, e.what());
-+   }
-+
-+   auto capabilities_ivalue = this->model->run_method("capabilities");
-+   this->capabilities = capabilities_ivalue.toCustomClass<metatensor_torch::ModelCapabilitiesHolder>();
-+
-+   if (!this->capabilities->outputs().contains("energy")) {
-+       lmp->error->all(FLERR, "the model at '{}' does not have an \"energy\" output, we can not use it in pair_style metatensor", path);
-+   }
-+
-+   if (lmp->comm->me == 0) {
-+       auto metadata_ivalue = this->model->run_method("metadata");
-+       auto metadata = metadata_ivalue.toCustomClass<metatensor_torch::ModelMetadataHolder>();
-+       auto to_print = metadata->print();
-+
-+       if (lmp->screen) {
-+           fprintf(lmp->screen, "\n%s\n", to_print.c_str());
-+       }
-+       if (lmp->logfile) {
-+           fprintf(lmp->logfile,"\n%s\n", to_print.c_str());
-+       }
-+
-+       // add the model references to LAMMPS citation handling mechanism
-+       for (const auto& it: metadata->references) {
-+           for (const auto& ref: it.value()) {
-+               lmp->citeme->add(ref + "\n");
-+           }
-+       }
-+   }
-+}
-diff --git a/src/ML-METATENSOR/metatensor_types.h b/src/ML-METATENSOR/metatensor_types.h
-new file mode 100644
-index 0000000000..32cab47d89
---- /dev/null
-+++ b/src/ML-METATENSOR/metatensor_types.h
-@@ -0,0 +1,57 @@
-+/* -*- c++ -*- ----------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+#include "lammps.h"
-+
-+#include <string>
-+
-+#include <torch/torch.h>
-+#include <metatensor/torch.hpp>
-+#include <metatensor/torch/atomistic.hpp>
-+
-+
-+
-+#ifndef LMP_METATENSOR_TYPES_H
-+#define LMP_METATENSOR_TYPES_H
-+
-+namespace LAMMPS_NS {
-+
-+struct PairMetatensorData {
-+   PairMetatensorData(std::string length_unit, std::string energy_unit);
-+
-+   void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
-+
-+   // torch model in metatensor format
-+   std::unique_ptr<torch::jit::Module> model;
-+   // device to use for the calculations
-+   torch::Device device;
-+   // model capabilities, declared by the model
-+   metatensor_torch::ModelCapabilities capabilities;
-+   // run-time evaluation options, decided by this class
-+   metatensor_torch::ModelEvaluationOptions evaluation_options;
-+   // should metatensor check the data LAMMPS send to the model
-+   // and the data the model returns?
-+   bool check_consistency;
-+   // whether pairs should be remapped, removing pairs between ghosts if there
-+   // is an equivalent pair involving at least one local atom.
-+   bool remap_pairs;
-+   // how far away the model needs to know about neighbors
-+   double max_cutoff;
-+
-+   // allocation cache for the selected atoms
-+   torch::Tensor selected_atoms_values;
-+};
-+
-+}    // namespace LAMMPS_NS
-+
-+#endif
-diff --git a/src/ML-METATENSOR/pair_metatensor.cpp b/src/ML-METATENSOR/pair_metatensor.cpp
-new file mode 100644
-index 0000000000..d936c9579f
---- /dev/null
-+++ b/src/ML-METATENSOR/pair_metatensor.cpp
-@@ -0,0 +1,565 @@
-+/* ----------------------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+
-+/* ----------------------------------------------------------------------
-+   Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
-+------------------------------------------------------------------------- */
-+#include "pair_metatensor.h"
-+#include "metatensor_types.h"
-+
-+#include "atom.h"
-+#include "error.h"
-+#include "force.h"
-+#include "memory.h"
-+#include "neighbor.h"
-+#include "update.h"
-+#include "comm.h"
-+
-+#include "neigh_list.h"
-+#include "neigh_request.h"
-+
-+#include <torch/version.h>
-+#include <torch/script.h>
-+#include <torch/cuda.h>
-+
-+#if TORCH_VERSION_MAJOR >= 2
-+    #include <torch/mps.h>
-+#endif
-+
-+#include <memory>
-+
-+#include <metatensor/torch.hpp>
-+#include <metatensor/torch/atomistic.hpp>
-+
-+#include "metatensor_system.h"
-+
-+#include "./metatensor_timer.h"
-+
-+using namespace LAMMPS_NS;
-+
-+PairMetatensor::PairMetatensor(LAMMPS *lmp):
-+    Pair(lmp),
-+    type_mapping(nullptr),
-+    system_adaptor(nullptr)
-+{
-+    std::string energy_unit;
-+    std::string length_unit;
-+    if (strcmp(update->unit_style, "real") == 0) {
-+        length_unit = "angstrom";
-+        energy_unit = "kcal/mol";
-+    } else if (strcmp(update->unit_style, "metal") == 0) {
-+        length_unit = "angstrom";
-+        energy_unit = "eV";
-+    } else if (strcmp(update->unit_style, "si") == 0) {
-+        length_unit = "meter";
-+        energy_unit = "joule";
-+    } else if (strcmp(update->unit_style, "electron") == 0) {
-+        length_unit = "Bohr";
-+        energy_unit = "Hartree";
-+    } else {
-+        error->all(FLERR, "unsupported units '{}' for pair metatensor ", update->unit_style);
-+    }
-+
-+    // we might not be running a pure pair potential,
-+    // so we can not compute virial as fdotr
-+    this->no_virial_fdotr_compute = 1;
-+
-+    this->mts_data = new PairMetatensorData(std::move(length_unit), std::move(energy_unit));
-+
-+    // settings for metatensor pair style
-+    this->single_enable = 0;
-+    this->restartinfo = 0;
-+    this->one_coeff = 1;
-+    this->manybody_flag = 1;
-+}
-+
-+PairMetatensor::~PairMetatensor() {
-+    delete this->mts_data;
-+
-+    if (allocated) {
-+        memory->destroy(setflag);
-+        memory->destroy(cutsq);
-+        memory->destroy(type_mapping);
-+    }
-+}
-+
-+// called when finding `pair_style metatensor` in the input
-+void PairMetatensor::settings(int argc, char ** argv) {
-+    if (argc == 0) {
-+        error->all(FLERR, "expected at least 1 argument to pair_style metatensor, got {}", argc);
-+    }
-+
-+    const char* model_path = argv[0];
-+    const char* extensions_directory = nullptr;
-+    const char* requested_device = nullptr;
-+    for (int i=1; i<argc; i++) {
-+        if (strcmp(argv[i], "check_consistency") == 0) {
-+            if (i == argc - 1) {
-+                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatensor, got nothing");
-+            } else if (strcmp(argv[i + 1], "on") == 0) {
-+                mts_data->check_consistency = true;
-+            } else if (strcmp(argv[i + 1], "off") == 0) {
-+                mts_data->check_consistency = false;
-+            } else {
-+                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatensor, got '{}'", argv[i + 1]);
-+            }
-+
-+            i += 1;
-+        } else if (strcmp(argv[i], "remap_pairs") == 0) {
-+            if (i == argc - 1) {
-+                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatensor, got nothing");
-+            } else if (strcmp(argv[i + 1], "on") == 0) {
-+                mts_data->remap_pairs = true;
-+            } else if (strcmp(argv[i + 1], "off") == 0) {
-+                mts_data->remap_pairs = false;
-+            } else {
-+                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatensor, got '{}'", argv[i + 1]);
-+            }
-+
-+            i += 1;
-+        } else if (strcmp(argv[i], "extensions") == 0) {
-+            if (i == argc - 1) {
-+                error->all(FLERR, "expected <path> after 'extensions' in pair_style metatensor, got nothing");
-+            }
-+            extensions_directory = argv[i + 1];
-+            i += 1;
-+        } else if (strcmp(argv[i], "device") == 0) {
-+            if (i == argc - 1) {
-+                error->all(FLERR, "expected string after 'device' in pair_style metatensor, got nothing");
-+            }
-+            requested_device = argv[i + 1];
-+            i += 1;
-+        } else {
-+            error->all(FLERR, "unexpected argument to pair_style metatensor: '{}'", argv[i]);
-+        }
-+    }
-+
-+    // load the model and get it's capabilities (including supported devices)
-+    mts_data->load_model(this->lmp, model_path, extensions_directory);
-+
-+    // Select the device to use based on the model's preference, the user choice
-+    // and what's available.
-+    this->pick_device(&mts_data->device, requested_device);
-+
-+    // move all data to the correct device
-+    mts_data->model->to(mts_data->device);
-+    mts_data->selected_atoms_values = mts_data->selected_atoms_values.to(mts_data->device);
-+
-+    auto message = "Running simulation on " + mts_data->device.str() + " device with " + mts_data->capabilities->dtype() + " data";
-+    if (screen) {
-+        fprintf(screen, "%s\n", message.c_str());
-+    }
-+    if (logfile) {
-+        fprintf(logfile,"%s\n", message.c_str());
-+    }
-+
-+    if (!allocated) {
-+        allocate();
-+    }
-+}
-+
-+std::vector<torch::DeviceType> PairMetatensor::available_devices() {
-+    auto devices = std::vector<torch::DeviceType>();
-+    for (const auto& supported: this->mts_data->capabilities->supported_devices) {
-+        if (supported == "cpu") {
-+            devices.push_back(torch::kCPU);
-+        } else if (supported == "cuda" && torch::cuda::is_available()) {
-+            devices.push_back(torch::kCUDA);
-+        } else if (supported == "mps") {
-+            #if TORCH_VERSION_MAJOR >= 2
-+            if (torch::mps::is_available()) {
-+                devices.push_back(torch::kMPS);
-+            }
-+            #endif
-+        } else {
-+            error->warning(FLERR,
-+                "the model declared support for unknown device '{}', it will be ignored", supported
-+            );
-+        }
-+    }
-+
-+    if (devices.empty()) {
-+        error->all(FLERR,
-+            "failed to find a valid device for this model: "
-+            "the model supports {}, none of these where available",
-+            torch::str(this->mts_data->capabilities->supported_devices)
-+        );
-+    }
-+
-+    return devices;
-+}
-+
-+void PairMetatensor::pick_device(torch::Device* device, const char* requested) {
-+    auto available_devices = this->available_devices();
-+
-+    auto picked_device_type = torch::kCPU;
-+    if (requested == nullptr) {
-+        // no user request, pick the device the model prefers
-+        picked_device_type = available_devices[0];
-+    } else {
-+        bool found_requested_device = false;
-+        for (const auto& device_type: available_devices) {
-+            if (device_type == torch::kCPU && strcmp(requested, "cpu") == 0) {
-+                picked_device_type = device_type;
-+                found_requested_device = true;
-+                break;
-+            } else if (device_type == torch::kCUDA && strcmp(requested, "cuda") == 0) {
-+                picked_device_type = device_type;
-+                found_requested_device = true;
-+                break;
-+            } else if (device_type == torch::kMPS && strcmp(requested, "mps") == 0) {
-+                picked_device_type = device_type;
-+                found_requested_device = true;
-+                break;
-+            }
-+        }
-+
-+        if (!found_requested_device) {
-+            error->all(FLERR,
-+                "failed to find requested device ({}): it is either "
-+                "not supported by this model or not available on this machine",
-+                requested
-+            );
-+        }
-+    }
-+
-+    if (picked_device_type == torch::kCUDA) {
-+        // distribute GPUs between multiple MPI processes on the same node
-+
-+        // (1) get a MPI communicator for all processes on the current node
-+        MPI_Comm local;
-+        MPI_Comm_split_type(world, MPI_COMM_TYPE_SHARED, 0, MPI_INFO_NULL, &local);
-+        // (2) get the rank of this MPI process on the current node
-+        int local_rank;
-+        MPI_Comm_rank(local, &local_rank);
-+
-+        int size;
-+        MPI_Comm_size(local, &size);
-+        if (size < torch::cuda::device_count()) {
-+            if (comm->me == 0) {
-+                error->warning(FLERR,
-+                    "found {} CUDA-capable GPUs, but only {} MPI processes on the current node; the remaining GPUs will not be used",
-+                    torch::cuda::device_count(), size
-+                );
-+            }
-+        }
-+
-+        // (3) split GPUs between node-local processes using round-robin allocation
-+        int gpu_to_use = local_rank % torch::cuda::device_count();
-+        *device = torch::Device(picked_device_type, gpu_to_use);
-+    } else {
-+        *device = torch::Device(picked_device_type);
-+    }
-+}
-+
-+
-+void PairMetatensor::allocate() {
-+    allocated = 1;
-+
-+    // setflags stores whether the coeff for a given pair of atom types are known
-+    setflag = memory->create(
-+        setflag,
-+        atom->ntypes + 1,
-+        atom->ntypes + 1,
-+        "pair:setflag"
-+    );
-+
-+    for (int i = 1; i <= atom->ntypes; i++) {
-+        for (int j = i; j <= atom->ntypes; j++) {
-+            setflag[i][j] = 0;
-+        }
-+    }
-+
-+    // cutsq stores the squared cutoff for each pair
-+    cutsq = memory->create(
-+        cutsq,
-+        atom->ntypes + 1,
-+        atom->ntypes + 1,
-+        "pair:cutsq"
-+    );
-+
-+    // lammps_types_to_species stores the mapping from lammps atom types to
-+    // the metatensor model species
-+    type_mapping = memory->create(
-+        type_mapping,
-+        atom->ntypes + 1,
-+        "PairMetatensor:type_mapping"
-+    );
-+
-+    for (int i = 1; i <= atom->ntypes; i++) {
-+        type_mapping[i] = -1;
-+    }
-+}
-+
-+double PairMetatensor::init_one(int, int) {
-+    return mts_data->max_cutoff;
-+}
-+
-+
-+// called on pair_coeff
-+void PairMetatensor::coeff(int argc, char ** argv) {
-+    if (argc < 3 || strcmp(argv[0], "*") != 0 || strcmp(argv[1], "*") != 0) {
-+        error->all(FLERR, "invalid pair_coeff, expected `pair_coeff * * <list of types>`");
-+    }
-+
-+    if (atom->ntypes != argc - 2) {
-+        error->all(FLERR,
-+            "invalid pair_coeff, expected `pair_coeff * * <list of types>` with {} types",
-+            atom->ntypes
-+        );
-+    }
-+
-+    for (int lammps_type=1; lammps_type<argc - 1; lammps_type++) {
-+        int type = utils::inumeric(FLERR, argv[lammps_type + 1], true, lmp);
-+        type_mapping[lammps_type] = type;
-+    }
-+
-+    // mark all pairs coeffs as known
-+    for (int i = 1; i <= atom->ntypes; i++) {
-+        for (int j = 1; j <= atom->ntypes; j++) {
-+            setflag[i][j] = 1;
-+            setflag[j][i] = 1;
-+        }
-+    }
-+}
-+
-+
-+// called when the run starts
-+void PairMetatensor::init_style() {
-+    // Require newton pair on since we need to communicate forces accumulated on
-+    // ghost atoms to neighboring domains. These forces contributions come from
-+    // gradient of a local descriptor w.r.t. domain ghosts (periodic images
-+    // ghosts are handled separately).
-+    if (force->newton_pair != 1) {
-+        error->all(FLERR, "Pair style metatensor requires newton pair on");
-+    }
-+
-+    // get the model's interaction range
-+    auto range = mts_data->capabilities->engine_interaction_range(mts_data->evaluation_options->length_unit());
-+    if (range < 0) {
-+        error->all(FLERR, "interaction_range is negative for this model");
-+    } else if (!std::isfinite(range)) {
-+        if (comm->nprocs > 1) {
-+            error->all(FLERR,
-+                "interaction_range is infinite for this model, "
-+                "using multiple MPI domains is not supported"
-+            );
-+        }
-+
-+        // determine the maximal cutoff in the NL
-+        auto requested_nl = mts_data->model->run_method("requested_neighbor_lists");
-+        for (const auto& ivalue: requested_nl.toList()) {
-+            auto options = ivalue.get().toCustomClass<metatensor_torch::NeighborListOptionsHolder>();
-+            auto cutoff = options->engine_cutoff(mts_data->evaluation_options->length_unit());
-+
-+            mts_data->max_cutoff = std::max(mts_data->max_cutoff, cutoff);
-+        }
-+    } else {
-+        mts_data->max_cutoff = range;
-+    }
-+
-+    if (!std::isfinite(mts_data->max_cutoff)) {
-+        error->all(FLERR,
-+            "the largest cutoff of this model is infinite, "
-+            "we can't compute the corresponding neighbor list"
-+        );
-+    }
-+
-+    // create system adaptor
-+    auto options = MetatensorSystemOptions{
-+        this->type_mapping,
-+        mts_data->max_cutoff,
-+        mts_data->check_consistency,
-+    };
-+    this->system_adaptor = std::make_unique<MetatensorSystemAdaptor>(lmp, options);
-+
-+    // We ask LAMMPS for a full neighbor lists because we need to know about
-+    // ALL pairs, even if options->full_list() is false. We will then filter
-+    // the pairs to only include each pair once where needed.
-+    auto request = neighbor->add_request(this, NeighConst::REQ_FULL | NeighConst::REQ_GHOST);
-+    request->set_cutoff(mts_data->max_cutoff);
-+
-+    // Translate from the metatensor neighbor lists requests to LAMMPS neighbor
-+    // lists requests.
-+    auto requested_nl = mts_data->model->run_method("requested_neighbor_lists");
-+    for (const auto& ivalue: requested_nl.toList()) {
-+        auto options = ivalue.get().toCustomClass<metatensor_torch::NeighborListOptionsHolder>();
-+        auto cutoff = options->engine_cutoff(mts_data->evaluation_options->length_unit());
-+        assert(cutoff <= mts_data->max_cutoff);
-+
-+        this->system_adaptor->add_nl_request(cutoff, options);
-+    }
-+}
-+
-+
-+void PairMetatensor::init_list(int id, NeighList *ptr) {
-+    mts_list = ptr;
-+}
-+
-+
-+void PairMetatensor::compute(int eflag, int vflag) {
-+    if (std::getenv("LAMMPS_METATENSOR_PROFILE") != nullptr) {
-+        MetatensorTimer::enable(true);
-+    } else {
-+        MetatensorTimer::enable(false);
-+    }
-+
-+    auto _ = MetatensorTimer("PairMetatensor::compute");
-+
-+    if (eflag || vflag) {
-+        ev_setup(eflag, vflag);
-+    } else {
-+        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
-+    }
-+
-+    if (eflag_atom) {
-+        mts_data->evaluation_options->outputs.at("energy")->per_atom = true;
-+    } else {
-+        mts_data->evaluation_options->outputs.at("energy")->per_atom = false;
-+    }
-+
-+    auto dtype = torch::kFloat64;
-+    if (mts_data->capabilities->dtype() == "float64") {
-+        dtype = torch::kFloat64;
-+    } else if (mts_data->capabilities->dtype() == "float32") {
-+        dtype = torch::kFloat32;
-+    } else {
-+        error->all(FLERR, "the model requested an unsupported dtype '{}'", mts_data->capabilities->dtype());
-+    }
-+
-+    // transform from LAMMPS to metatensor System
-+    auto system = this->system_adaptor->system_from_lmp(
-+        mts_list,
-+        static_cast<bool>(vflag_global),
-+        mts_data->remap_pairs,
-+        dtype,
-+        mts_data->device
-+    );
-+
-+    // only run the calculation for atoms actually in the current domain
-+    mts_data->selected_atoms_values.resize_({atom->nlocal, 2});
-+    mts_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
-+    auto options = mts_data->selected_atoms_values.options();
-+    mts_data->selected_atoms_values.index_put_(
-+        {torch::indexing::Slice(), 1},
-+        torch::arange(atom->nlocal, options)
-+    );
-+
-+    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-+        std::vector<std::string>{"system", "atom"}, mts_data->selected_atoms_values
-+    );
-+    mts_data->evaluation_options->set_selected_atoms(selected_atoms);
-+
-+    torch::IValue result_ivalue;
-+    try {
-+        auto _ = MetatensorTimer("running Model::forward");
-+        result_ivalue = mts_data->model->forward({
-+            std::vector<metatensor_torch::System>{system},
-+            mts_data->evaluation_options,
-+            mts_data->check_consistency
-+        });
-+    } catch (const std::exception& e) {
-+        error->all(FLERR, "error evaluating the torch model: {}", e.what());
-+    }
-+
-+    auto result = result_ivalue.toGenericDict();
-+    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
-+    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
-+    auto energy_tensor = energy_block->values();
-+
-+    // compute forces/virial on device with backward propagation
-+    {
-+        // reset gradients to zero before calling backward
-+        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
-+        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
-+
-+        auto _ = MetatensorTimer("running Model::backward");
-+        energy_tensor.backward(-torch::ones_like(energy_tensor));
-+    }
-+
-+    {
-+        auto _ = MetatensorTimer("storing model output in LAMMPS data structures");
-+
-+        // move results to cpu for storing
-+        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
-+        auto energy_samples = energy_block->samples();
-+
-+        // store the energy returned by the model
-+        torch::Tensor global_energy;
-+        if (eflag_atom) {
-+            assert(energy_samples->size() == 2);
-+            assert(energy_samples->names()[0] == "system");
-+            assert(energy_samples->names()[1] == "atom");
-+
-+            auto samples_values = energy_samples->values().to(torch::kCPU);
-+            auto samples = samples_values.accessor<int32_t, 2>();
-+
-+            int64_t n_atoms = atom->nlocal + atom->nghost;
-+            assert(samples_values.sizes() == mts_data->selected_atoms_values.sizes());
-+
-+            auto energies = energy_detached.accessor<double, 2>();
-+            for (int64_t i=0; i<energy_samples->count(); i++) {
-+                assert(samples[i][0] == 0);
-+                // handle potentially out of order samples in
-+                // the per-atom energy tensor
-+                auto atom_i = samples[i][1];
-+                assert(atom_i < n_atoms);
-+                eatom[atom_i] += energies[i][0];
-+            }
-+
-+            global_energy = energy_detached.sum(0);
-+            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
-+        } else {
-+            assert(energy_samples->size() == 1);
-+            assert(energy_samples->names()[0] == "system");
-+
-+            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
-+            global_energy = energy_detached.reshape({1});
-+        }
-+
-+        if (eflag_global) {
-+            eng_vdwl += global_energy.item<double>();
-+        }
-+
-+        // store forces/virial
-+        auto forces_tensor = this->system_adaptor->positions.grad();
-+        assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
-+
-+        auto forces = forces_tensor.accessor<double, 2>();
-+        for (int i=0; i<atom->nlocal + atom->nghost; i++) {
-+            atom->f[i][0] += forces[i][0];
-+            atom->f[i][1] += forces[i][1];
-+            atom->f[i][2] += forces[i][2];
-+        }
-+
-+        assert(!vflag_fdotr);
-+
-+        if (vflag_global) {
-+            auto virial_tensor = this->system_adaptor->strain.grad();
-+            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
-+            auto predicted_virial = virial_tensor.accessor<double, 2>();
-+
-+            virial[0] += predicted_virial[0][0];
-+            virial[1] += predicted_virial[1][1];
-+            virial[2] += predicted_virial[2][2];
-+
-+            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
-+            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
-+            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
-+        }
-+
-+        if (vflag_atom) {
-+            error->all(FLERR, "per atom virial is not implemented");
-+        }
-+    }
-+}
-diff --git a/src/ML-METATENSOR/pair_metatensor.h b/src/ML-METATENSOR/pair_metatensor.h
-new file mode 100644
-index 0000000000..9f7d1155d0
---- /dev/null
-+++ b/src/ML-METATENSOR/pair_metatensor.h
-@@ -0,0 +1,72 @@
-+/* -*- c++ -*- ----------------------------------------------------------
-+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
-+   https://www.lammps.org/, Sandia National Laboratories
-+   LAMMPS Development team: developers@lammps.org
-+
-+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
-+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
-+   certain rights in this software.  This software is distributed under
-+   the GNU General Public License.
-+
-+   See the README file in the top-level LAMMPS directory.
-+------------------------------------------------------------------------- */
-+#ifdef PAIR_CLASS
-+// clang-format off
-+PairStyle(metatensor, PairMetatensor);
-+// clang-format on
-+#else
-+
-+#ifndef LMP_PAIR_METATENSOR_H
-+#define LMP_PAIR_METATENSOR_H
-+
-+#include "pair.h"
-+
-+#include <vector>
-+
-+// this is the actual namespace where `torch::Device` is defined
-+namespace c10 {
-+    class Device;
-+
-+    enum class DeviceType: int8_t;
-+}
-+
-+namespace LAMMPS_NS {
-+class MetatensorSystemAdaptor;
-+struct PairMetatensorData;
-+
-+class PairMetatensor : public Pair {
-+public:
-+    PairMetatensor(class LAMMPS *);
-+    ~PairMetatensor();
-+
-+    void compute(int, int) override;
-+    void settings(int, char **) override;
-+    void coeff(int, char **) override;
-+    void init_style() override;
-+    double init_one(int, int) override;
-+    void init_list(int id, NeighList *ptr) override;
-+
-+    void allocate();
-+
-+protected:
-+    // get the set of devices both available on the current machine and supported
-+    // by the model
-+    std::vector<c10::DeviceType> available_devices();
-+
-+    // pick the correct device to use from the user request (or nullptr) in
-+    // `pair_style metatensor`
-+    virtual void pick_device(c10::Device* device, const char* requested);
-+
-+    PairMetatensorData* mts_data;
-+    NeighList *mts_list;
-+
-+    // mapping from LAMMPS types to metatensor types
-+    int32_t *type_mapping;
-+    // adaptor from LAMMPS system to metatensor's
-+    std::unique_ptr<MetatensorSystemAdaptor> system_adaptor;
-+};
-+
-+}    // namespace LAMMPS_NS
-+
-+#endif
-+#endif
-diff --git a/src/ML-METATENSOR/patch-torch.sh b/src/ML-METATENSOR/patch-torch.sh
-new file mode 100755
-index 0000000000..8ec7cafac0
---- /dev/null
-+++ b/src/ML-METATENSOR/patch-torch.sh
-@@ -0,0 +1,45 @@
-+#!/usr/bin/env bash
-+
-+# This pulls in the fix from https://github.com/pytorch/pytorch/pull/119945
-+# until it is properly released
-+
-+set -eu
-+
-+TORCH_PREFIX=$1
-+
-+if [ -f "$TORCH_PREFIX/share/cmake/Caffe2/public/mkl.cmake" ]; then
-+    MKL_CMAKE="$TORCH_PREFIX/share/cmake/Caffe2/public/mkl.cmake"
-+elif [ -f "$TORCH_PREFIX/Caffe2/public/mkl.cmake" ]; then
-+    MKL_CMAKE="$TORCH_PREFIX/Caffe2/public/mkl.cmake"
-+else
-+    echo "Failed to find mkl.cmake in '$TORCH_PREFIX'"
-+    exit 1
-+fi
-+
-+cat > "$MKL_CMAKE" << EOF
-+
-+find_package(MKL QUIET)
-+
-+if(TARGET caffe2::mkl)
-+  return()
-+endif()
-+
-+add_library(caffe2::mkl INTERFACE IMPORTED)
-+target_include_directories(caffe2::mkl INTERFACE \${MKL_INCLUDE_DIR})
-+target_link_libraries(caffe2::mkl INTERFACE \${MKL_LIBRARIES})
-+foreach(MKL_LIB IN LISTS MKL_LIBRARIES)
-+  if(EXISTS "\${MKL_LIB}")
-+    get_filename_component(MKL_LINK_DIR "\${MKL_LIB}" DIRECTORY)
-+    if(IS_DIRECTORY "\${MKL_LINK_DIR}")
-+      target_link_directories(caffe2::mkl INTERFACE "\${MKL_LINK_DIR}")
-+    endif()
-+  endif()
-+endforeach()
-+
-+# TODO: This is a hack, it will not pick up architecture dependent
-+# MKL libraries correctly; see https://github.com/pytorch/pytorch/issues/73008
-+set_property(
-+  TARGET caffe2::mkl PROPERTY INTERFACE_LINK_DIRECTORIES
-+  \${MKL_ROOT}/lib \${MKL_ROOT}/lib/intel64 \${MKL_ROOT}/lib/intel64_win \${MKL_ROOT}/lib/win-x64)
-+
-+EOF
-diff --git a/src/Makefile b/src/Makefile
-index 866c778aeb..42c4c80979 100644
---- a/src/Makefile
-+++ b/src/Makefile
-@@ -103,6 +103,7 @@ PACKAGE = \
- 	ml-pace \
- 	ml-pod \
- 	ml-quip \
-+	ml-metatensor \
- 	ml-rann \
- 	ml-snap \
- 	ml-uf3 \
-@@ -234,6 +235,7 @@ PACKLIB = \
- 	plumed \
- 	qmmm \
- 	ml-quip \
-+	ml-metatensor \
- 	rheo \
- 	scafacos \
- 	machdyn \
-@@ -252,6 +254,7 @@ PACKEXT = \
- 	ml-hdnnp \
- 	ml-pace \
- 	ml-quip \
-+	ml-metatensor \
- 	molfile \
- 	netcdf \
- 	plumed \
-diff --git a/src/STUBS/mpi.cpp b/src/STUBS/mpi.cpp
-index 22cbc9af17..e431837f34 100644
---- a/src/STUBS/mpi.cpp
-+++ b/src/STUBS/mpi.cpp
-@@ -378,6 +378,13 @@ int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *comm_out)
-
- /* ---------------------------------------------------------------------- */
-
-+int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *comm_out) {
-+  *comm_out = comm + 1;
-+  return 0;
-+}
-+
-+/* ---------------------------------------------------------------------- */
-+
- int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *comm_out)
- {
-   *comm_out = comm + 1;
-diff --git a/src/STUBS/mpi.h b/src/STUBS/mpi.h
-index b89c098bad..e65199f6e9 100644
---- a/src/STUBS/mpi.h
-+++ b/src/STUBS/mpi.h
-@@ -58,6 +58,7 @@
- #define MPI_STATUS_IGNORE NULL
-
- #define MPI_Comm int
-+#define MPI_Info int
- #define MPI_Request int
- #define MPI_Datatype int
- #define MPI_Op int
-@@ -65,6 +66,11 @@
- #define MPI_Group int
- #define MPI_Offset long
-
-+#define MPI_INFO_NULL 0
-+
-+// TODO: should all the COMM_TYPE be defined here?
-+#define MPI_COMM_TYPE_SHARED 0xABCDEF01
-+
- #define MPI_IN_PLACE NULL
-
- #define MPI_MAX_PROCESSOR_NAME 128
-@@ -115,6 +121,7 @@ int MPI_Sendrecv(const void *sbuf, int scount, MPI_Datatype sdatatype, int dest,
- int MPI_Get_count(MPI_Status *status, MPI_Datatype datatype, int *count);
-
- int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *comm_out);
-+int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *comm_out);
- int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *comm_out);
- int MPI_Comm_free(MPI_Comm *comm);
- MPI_Fint MPI_Comm_c2f(MPI_Comm comm);

From 3b74bcbb50fe8ee9113a92c75f7c696522f31e38 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Tue, 3 Jun 2025 10:58:03 +0200
Subject: [PATCH 07/37] Do not use transposed neighbors in kokkos

---
 src/KOKKOS/metatomic_system_kokkos.cpp | 2 +-
 src/KOKKOS/pair_metatomic_kokkos.cpp   | 6 +-----
 2 files changed, 2 insertions(+), 6 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 9490ba24139..4d7669f7b11 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -109,7 +109,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
         torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
     ).to(this->device_);
 
-    auto neighbors_kk = list->d_neighbors_transpose;
+    auto neighbors_kk = list->d_neighbors;
     auto max_number_of_neighbors = list->maxneighs;
 
     auto neighbors = torch::zeros(
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index a9c1f81fb11..fc8aba10e1e 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -18,7 +18,6 @@
 #include "pair_metatomic_kokkos.h"
 
 #include "error.h"
-#include "kokkos.h"
 #include "neigh_request.h"
 #include "atom_masks.h"
 
@@ -42,10 +41,7 @@ template<typename T, class DeviceType>
 using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
 
 template<class DeviceType>
-PairMetatomicKokkos<DeviceType>::PairMetatomicKokkos(LAMMPS* lmp): PairMetatomic(lmp) {
-    // this will allow us to receive the NL in a GPU-friendly format
-    this->lmp->kokkos->neigh_transpose = 1;
-}
+PairMetatomicKokkos<DeviceType>::PairMetatomicKokkos(LAMMPS* lmp): PairMetatomic(lmp) {}
 
 template<class DeviceType>
 PairMetatomicKokkos<DeviceType>::~PairMetatomicKokkos() {}

From f7c0455ba250cea3c6a1694101476860b574a333 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Tue, 3 Jun 2025 10:59:17 +0200
Subject: [PATCH 08/37] Register multiple copies of pair_style metatomic

So we can mix multiple in the same pair_style hybrid command
---
 examples/PACKAGES/metatomic/in.kokkos.metatomic |  4 ++++
 examples/PACKAGES/metatomic/in.metatomic        |  4 ++++
 src/KOKKOS/pair_metatomic_kokkos.h              | 12 ++++++++++++
 src/ML-METATOMIC/pair_metatomic.h               | 12 ++++++++++++
 4 files changed, 32 insertions(+)

diff --git a/examples/PACKAGES/metatomic/in.kokkos.metatomic b/examples/PACKAGES/metatomic/in.kokkos.metatomic
index 4d7d90130e8..df872b5318a 100644
--- a/examples/PACKAGES/metatomic/in.kokkos.metatomic
+++ b/examples/PACKAGES/metatomic/in.kokkos.metatomic
@@ -19,6 +19,10 @@ velocity all create 123 42
 pair_style metatomic/kk nickel-lj.pt
 pair_coeff * * 28
 
+# pair_style hybrid/overlay/kk metatomic_1/kk nickel-lj.pt metatomic_2/kk nickel-lj.pt
+# pair_coeff * * metatomic_1/kk 28
+# pair_coeff * * metatomic_2/kk 28
+
 timestep 0.001
 run_style verlet/kk
 fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
diff --git a/examples/PACKAGES/metatomic/in.metatomic b/examples/PACKAGES/metatomic/in.metatomic
index 12e008ae148..dddb94422cf 100644
--- a/examples/PACKAGES/metatomic/in.metatomic
+++ b/examples/PACKAGES/metatomic/in.metatomic
@@ -16,6 +16,10 @@ pair_style metatomic nickel-lj.pt
 # pair_style metatomic nickel-lj-extensions.pt extensions collected-extensions/
 pair_coeff * * 28
 
+# pair_style hybrid/scaled 0.5 metatomic_1 nickel-lj.pt 0.5 metatomic_2 nickel-lj.pt
+# pair_coeff * * metatomic_1 28
+# pair_coeff * * metatomic_2 28
+
 timestep 0.001
 fix 1 all npt temp 123 123 $(100 * dt) iso 0 0 $(1000 * dt) drag 1.0
 
diff --git a/src/KOKKOS/pair_metatomic_kokkos.h b/src/KOKKOS/pair_metatomic_kokkos.h
index c8e6496a14a..931086f2449 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.h
+++ b/src/KOKKOS/pair_metatomic_kokkos.h
@@ -13,6 +13,18 @@
 #ifdef PAIR_CLASS
 // clang-format off
 PairStyle(metatomic/kk, PairMetatomicKokkos<LMPDeviceType>);
+
+// additional versions of pair_style metatomic/kk, to be used with pair_style
+// hybrid when combining multiple metatomic potentials together
+PairStyle(metatomic_1/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_2/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_3/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_4/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_5/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_6/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_7/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_8/kk, PairMetatomicKokkos<LMPDeviceType>);
+PairStyle(metatomic_9/kk, PairMetatomicKokkos<LMPDeviceType>);
 // clang-format on
 #else
 
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
index 3539e35a0b5..0c25067a889 100644
--- a/src/ML-METATOMIC/pair_metatomic.h
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -13,6 +13,18 @@
 #ifdef PAIR_CLASS
 // clang-format off
 PairStyle(metatomic, PairMetatomic);
+
+// additional versions of pair_style metatomic, to be used with pair_style
+// hybrid when combining multiple metatomic potentials together
+PairStyle(metatomic_1, PairMetatomic);
+PairStyle(metatomic_2, PairMetatomic);
+PairStyle(metatomic_3, PairMetatomic);
+PairStyle(metatomic_4, PairMetatomic);
+PairStyle(metatomic_5, PairMetatomic);
+PairStyle(metatomic_6, PairMetatomic);
+PairStyle(metatomic_7, PairMetatomic);
+PairStyle(metatomic_8, PairMetatomic);
+PairStyle(metatomic_9, PairMetatomic);
 // clang-format on
 #else
 

From 02b5a5df811ee49610a1dad81d4f2e5704ff56a5 Mon Sep 17 00:00:00 2001
From: Filippo Bigi <98903385+frostedoyster@users.noreply.github.com>
Date: Wed, 4 Jun 2025 16:00:47 +0200
Subject: [PATCH 09/37] Implement non-conservative forces and stresses (#13)

---
 src/KOKKOS/metatomic_system_kokkos.cpp |  4 +-
 src/KOKKOS/pair_metatomic_kokkos.cpp   | 33 ++++++++++++---
 src/ML-METATOMIC/metatomic_system.cpp  |  4 +-
 src/ML-METATOMIC/metatomic_system.h    |  2 +
 src/ML-METATOMIC/metatomic_types.cpp   |  1 +
 src/ML-METATOMIC/metatomic_types.h     |  2 +
 src/ML-METATOMIC/pair_metatomic.cpp    | 56 +++++++++++++++++++++++---
 7 files changed, 88 insertions(+), 14 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 4d7669f7b11..845b699d01f 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -42,7 +42,7 @@ MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *l
     auto tensor_options = torch::TensorOptions()
         .dtype(torch::kFloat64)
         .device(this->device_)
-        .requires_grad(true);
+        .requires_grad(options_.requires_grad);
 
     this->strain = torch::eye(3, tensor_options);
 }
@@ -329,7 +329,7 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     this->positions = torch::from_blob(
         k_x.data(), {total_n_atoms, 3},
         // requires_grad=true since we always need gradients w.r.t. positions
-        tensor_options.requires_grad(true)
+        tensor_options.requires_grad(options_.requires_grad)
     );
 
     auto cell = torch::zeros({3, 3}, tensor_options);
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index fc8aba10e1e..cbde531415e 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -67,6 +67,7 @@ void PairMetatomicKokkos<DeviceType>::init_style() {
         this->type_mapping_kk.data(),
         mta_data->max_cutoff,
         mta_data->check_consistency,
+        !(mta_data->non_conservative),
     };
 
     // override the system adaptor with the kokkos version
@@ -176,14 +177,30 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
     auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
     auto energy_tensor = energy_block->values();
 
-    // compute forces/virial on device with backward propagation
-    {
+    torch::Tensor forces_tensor;
+    torch::Tensor virial_tensor;
+
+    if (mta_data->non_conservative) {
+        auto forces = result.at("non_conservative_forces").toCustomClass<metatensor_torch::TensorMapHolder>();;
+        auto forces_block = metatensor_torch::TensorMapHolder::block_by_id(forces, 0);
+        forces_tensor = forces_block->values().squeeze(-1);
+        forces_tensor = forces_tensor.to(torch::kFloat64);
+        auto stress = result.at("non_conservative_stress").toCustomClass<metatensor_torch::TensorMapHolder>();;
+        auto stress_block = metatensor_torch::TensorMapHolder::block_by_id(stress, 0);
+        auto stress_tensor = stress_block->values().squeeze(0).squeeze(-1);
+        virial_tensor = - stress_tensor * torch::abs(torch::det(system->cell()));
+        virial_tensor = virial_tensor.to(torch::kCPU).to(torch::kFloat64);
+    } else {
+        // compute forces/virial on device with backward propagation
         // reset gradients to zero before calling backward
         this->system_adaptor->positions.mutable_grad() = torch::Tensor();
         this->system_adaptor->strain.mutable_grad() = torch::Tensor();
 
         auto _ = MetatomicTimer("running Model::backward");
         energy_tensor.backward(-torch::ones_like(energy_tensor));
+
+        forces_tensor = this->system_adaptor->positions.grad();
+        virial_tensor = this->system_adaptor->strain.grad().to(torch::kCPU);
     }
 
     {
@@ -231,8 +248,8 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
         }
 
         // store forces/virial
-        auto forces_tensor = this->system_adaptor->positions.grad().contiguous();
         assert(forces_tensor.scalar_type() == torch::kFloat64);
+        forces_tensor = forces_tensor.contiguous();
 
         auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
         auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
@@ -240,8 +257,15 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
             forces_tensor.size(0), 3
         );
 
+        int num_forces_to_update;
+        if (mta_data->non_conservative) {
+            num_forces_to_update = atomKK->nlocal;
+        } else {
+            num_forces_to_update = atomKK->nlocal + atomKK->nghost;
+        }
+
         Kokkos::parallel_for(
-            system->size(),
+            num_forces_to_update,
             KOKKOS_LAMBDA(size_t i) {
                 forces_lammps_kk(i, 0) += forces_metatensor_kk(i, 0);
                 forces_lammps_kk(i, 1) += forces_metatensor_kk(i, 1);
@@ -252,7 +276,6 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
         assert(!vflag_fdotr);
 
         if (vflag_global) {
-            auto virial_tensor = this->system_adaptor->strain.grad().to(torch::kCPU);
             assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
             auto predicted_virial = virial_tensor.template accessor<double, 2>();
 
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index a5c51cc8bf6..acaa1e3d87f 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -36,7 +36,7 @@ MetatomicSystemAdaptor::MetatomicSystemAdaptor(LAMMPS *lmp, MetatomicSystemOptio
     auto tensor_options = torch::TensorOptions()
         .dtype(torch::kFloat64)
         .device(torch::kCPU)
-        .requires_grad(true);
+        .requires_grad(options_.requires_grad);
 
     this->strain = torch::eye(3, tensor_options);
 }
@@ -495,7 +495,7 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     this->positions = torch::from_blob(
         *x, {total_n_atoms, 3},
         // requires_grad=true since we always need gradients w.r.t. positions
-        tensor_options.requires_grad(true)
+        tensor_options.requires_grad(options_.requires_grad)
     );
 
     auto cell = torch::zeros({3, 3}, tensor_options);
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index 2778cff8bfa..5731c60b978 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -35,6 +35,8 @@ struct MetatomicSystemOptions {
     double interaction_range;
     // should we run extra checks on the neighbor lists?
     bool check_consistency;
+    // should the positions and strain require grad?
+    bool requires_grad;
 };
 
 // data for metatensor neighbors lists
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 6ac27b2814c..c2e07ba8945 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -26,6 +26,7 @@ PairMetatomicData::PairMetatomicData(std::string length_unit, std::string energy
     device(torch::kCPU),
     check_consistency(false),
     remap_pairs(true),
+    non_conservative(false),
     max_cutoff(-1)
 {
     auto options = torch::TensorOptions().dtype(torch::kInt32);
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index 3304aabc858..0010d628a6a 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -44,6 +44,8 @@ struct PairMetatomicData {
    // whether pairs should be remapped, removing pairs between ghosts if there
    // is an equivalent pair involving at least one local atom.
    bool remap_pairs;
+   // whether non-conservative forces and stresses should be used
+   bool non_conservative;
    // how far away the model needs to know about neighbors
    double max_cutoff;
 
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 5c16f096739..12c92e9efd5 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -125,6 +125,31 @@ void PairMetatomic::settings(int argc, char ** argv) {
                 error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got '{}'", argv[i + 1]);
             }
 
+            i += 1;
+        } else if (strcmp(argv[i], "non_conservative") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatensor, got nothing");
+            } else if (strcmp(argv[i + 1], "on") == 0) {
+                mta_data->non_conservative = true;
+                // add the non-conservative forces and stress to the requested outputs
+                auto output_nc_forces = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+                output_nc_forces->explicit_gradients = {};
+                output_nc_forces->set_quantity("force");
+                output_nc_forces->set_unit(mta_data->evaluation_options->outputs.at("energy")->unit() + "/" + mta_data->evaluation_options->length_unit());
+                output_nc_forces->per_atom = true;
+                mta_data->evaluation_options->outputs.insert("non_conservative_forces", output_nc_forces);
+                auto output_nc_stress = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+                output_nc_stress->explicit_gradients = {};
+                output_nc_stress->set_quantity("pressure");
+                output_nc_stress->set_unit(mta_data->evaluation_options->outputs.at("energy")->unit() + "/" + mta_data->evaluation_options->length_unit() + "^3");
+                output_nc_stress->per_atom = false;
+                mta_data->evaluation_options->outputs.insert("non_conservative_stress", output_nc_stress);
+            } else if (strcmp(argv[i + 1], "off") == 0) {
+                mta_data->non_conservative = false;
+            } else {
+                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatensor, got '{}'", argv[i + 1]);
+            }
+
             i += 1;
         } else if (strcmp(argv[i], "extensions") == 0) {
             if (i == argc - 1) {
@@ -379,6 +404,7 @@ void PairMetatomic::init_style() {
         this->type_mapping,
         mta_data->max_cutoff,
         mta_data->check_consistency,
+        !(mta_data->non_conservative),
     };
     this->system_adaptor = std::make_unique<MetatomicSystemAdaptor>(lmp, options);
 
@@ -476,14 +502,29 @@ void PairMetatomic::compute(int eflag, int vflag) {
     auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
     auto energy_tensor = energy_block->values();
 
-    // compute forces/virial on device with backward propagation
-    {
+    torch::Tensor forces_tensor;
+    torch::Tensor virial_tensor;
+
+    if (mta_data->non_conservative) {
+        auto forces = result.at("non_conservative_forces").toCustomClass<metatensor_torch::TensorMapHolder>();;
+        auto forces_block = metatensor_torch::TensorMapHolder::block_by_id(forces, 0);
+        forces_tensor = forces_block->values().squeeze(-1);
+        forces_tensor = forces_tensor.to(torch::kCPU).to(torch::kFloat64);
+        auto stress = result.at("non_conservative_stress").toCustomClass<metatensor_torch::TensorMapHolder>();;
+        auto stress_block = metatensor_torch::TensorMapHolder::block_by_id(stress, 0);
+        auto stress_tensor = stress_block->values().squeeze(0).squeeze(-1);
+        virial_tensor = - stress_tensor * torch::abs(torch::det(system->cell()));
+        virial_tensor = virial_tensor.to(torch::kCPU).to(torch::kFloat64);
+    } else {
         // reset gradients to zero before calling backward
         this->system_adaptor->positions.mutable_grad() = torch::Tensor();
         this->system_adaptor->strain.mutable_grad() = torch::Tensor();
 
         auto _ = MetatomicTimer("running Model::backward");
         energy_tensor.backward(-torch::ones_like(energy_tensor));
+
+        forces_tensor = this->system_adaptor->positions.grad();
+        virial_tensor = this->system_adaptor->strain.grad();
     }
 
     {
@@ -531,11 +572,17 @@ void PairMetatomic::compute(int eflag, int vflag) {
         }
 
         // store forces/virial
-        auto forces_tensor = this->system_adaptor->positions.grad();
         assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
 
+        int num_forces_to_update;
+        if (mta_data->non_conservative) {
+            num_forces_to_update = atom->nlocal;
+        } else {
+            num_forces_to_update = atom->nlocal + atom->nghost;
+        }
+
         auto forces = forces_tensor.accessor<double, 2>();
-        for (int i=0; i<atom->nlocal + atom->nghost; i++) {
+        for (int i=0; i<num_forces_to_update; i++) {
             atom->f[i][0] += forces[i][0];
             atom->f[i][1] += forces[i][1];
             atom->f[i][2] += forces[i][2];
@@ -544,7 +591,6 @@ void PairMetatomic::compute(int eflag, int vflag) {
         assert(!vflag_fdotr);
 
         if (vflag_global) {
-            auto virial_tensor = this->system_adaptor->strain.grad();
             assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
             auto predicted_virial = virial_tensor.accessor<double, 2>();
 

From 0a7e393673e21b4f1b1e2a512f85ddbe01fc1092 Mon Sep 17 00:00:00 2001
From: Filippo Bigi <98903385+frostedoyster@users.noreply.github.com>
Date: Wed, 4 Jun 2025 17:10:40 +0200
Subject: [PATCH 10/37] Add scale factor to metatomic pair_style

---
 src/KOKKOS/pair_metatomic_kokkos.cpp | 23 +++++++++++----------
 src/ML-METATOMIC/pair_metatomic.cpp  | 31 +++++++++++++++++-----------
 src/ML-METATOMIC/pair_metatomic.h    |  2 ++
 3 files changed, 33 insertions(+), 23 deletions(-)

diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index cbde531415e..fa102d8b966 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -230,7 +230,7 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
                 // the per-atom energy tensor
                 auto atom_i = samples[i][1];
                 assert(atom_i < n_atoms);
-                eatom[atom_i] += energies[i][0];
+                eatom[atom_i] += this->scale * energies[i][0];
             }
 
             global_energy = energy_detached.sum(0);
@@ -244,7 +244,7 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
         }
 
         if (eflag_global) {
-            eng_vdwl += global_energy.item<double>();
+            eng_vdwl += this->scale * global_energy.item<double>();
         }
 
         // store forces/virial
@@ -264,12 +264,13 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
             num_forces_to_update = atomKK->nlocal + atomKK->nghost;
         }
 
+        double scale = this->scale;  // the GPU can't access the `this` pointer
         Kokkos::parallel_for(
             num_forces_to_update,
             KOKKOS_LAMBDA(size_t i) {
-                forces_lammps_kk(i, 0) += forces_metatensor_kk(i, 0);
-                forces_lammps_kk(i, 1) += forces_metatensor_kk(i, 1);
-                forces_lammps_kk(i, 2) += forces_metatensor_kk(i, 2);
+                forces_lammps_kk(i, 0) += scale * forces_metatensor_kk(i, 0);
+                forces_lammps_kk(i, 1) += scale * forces_metatensor_kk(i, 1);
+                forces_lammps_kk(i, 2) += scale * forces_metatensor_kk(i, 2);
             }
         );
 
@@ -279,13 +280,13 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
             assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
             auto predicted_virial = virial_tensor.template accessor<double, 2>();
 
-            virial[0] += predicted_virial[0][0];
-            virial[1] += predicted_virial[1][1];
-            virial[2] += predicted_virial[2][2];
+            virial[0] += this->scale * predicted_virial[0][0];
+            virial[1] += this->scale * predicted_virial[1][1];
+            virial[2] += this->scale * predicted_virial[2][2];
 
-            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
-            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
-            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
+            virial[3] += this->scale * 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
+            virial[4] += this->scale * 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
+            virial[5] += this->scale * 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
         }
 
         if (vflag_atom) {
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 12c92e9efd5..12b1c29e2fd 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -49,7 +49,8 @@ using namespace LAMMPS_NS;
 PairMetatomic::PairMetatomic(LAMMPS *lmp):
     Pair(lmp),
     type_mapping(nullptr),
-    system_adaptor(nullptr)
+    system_adaptor(nullptr),
+    scale(1.0)
 {
     std::string energy_unit;
     std::string length_unit;
@@ -163,6 +164,12 @@ void PairMetatomic::settings(int argc, char ** argv) {
             }
             requested_device = argv[i + 1];
             i += 1;
+        } else if (strcmp(argv[i], "scale") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a number after 'scale' in pair_style metatomic, got nothing");
+            }
+            this->scale = utils::numeric(FLERR, argv[i + 1], false, lmp);
+            i += 1;
         } else {
             error->all(FLERR, "unexpected argument to pair_style metatomic: '{}'", argv[i]);
         }
@@ -554,7 +561,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
                 // the per-atom energy tensor
                 auto atom_i = samples[i][1];
                 assert(atom_i < n_atoms);
-                eatom[atom_i] += energies[i][0];
+                eatom[atom_i] += this->scale * energies[i][0];
             }
 
             global_energy = energy_detached.sum(0);
@@ -568,7 +575,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
         }
 
         if (eflag_global) {
-            eng_vdwl += global_energy.item<double>();
+            eng_vdwl += this->scale * global_energy.item<double>();
         }
 
         // store forces/virial
@@ -583,9 +590,9 @@ void PairMetatomic::compute(int eflag, int vflag) {
 
         auto forces = forces_tensor.accessor<double, 2>();
         for (int i=0; i<num_forces_to_update; i++) {
-            atom->f[i][0] += forces[i][0];
-            atom->f[i][1] += forces[i][1];
-            atom->f[i][2] += forces[i][2];
+            atom->f[i][0] += this->scale * forces[i][0];
+            atom->f[i][1] += this->scale * forces[i][1];
+            atom->f[i][2] += this->scale * forces[i][2];
         }
 
         assert(!vflag_fdotr);
@@ -594,13 +601,13 @@ void PairMetatomic::compute(int eflag, int vflag) {
             assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
             auto predicted_virial = virial_tensor.accessor<double, 2>();
 
-            virial[0] += predicted_virial[0][0];
-            virial[1] += predicted_virial[1][1];
-            virial[2] += predicted_virial[2][2];
+            virial[0] += this->scale * predicted_virial[0][0];
+            virial[1] += this->scale * predicted_virial[1][1];
+            virial[2] += this->scale * predicted_virial[2][2];
 
-            virial[3] += 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
-            virial[4] += 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
-            virial[5] += 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
+            virial[3] += this->scale * 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
+            virial[4] += this->scale * 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
+            virial[5] += this->scale * 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
         }
 
         if (vflag_atom) {
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
index 0c25067a889..6ccad8cb388 100644
--- a/src/ML-METATOMIC/pair_metatomic.h
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -76,6 +76,8 @@ class PairMetatomic : public Pair {
     int32_t *type_mapping;
     // adaptor from LAMMPS system to metatomic's
     std::unique_ptr<MetatomicSystemAdaptor> system_adaptor;
+
+    double scale;
 };
 
 }    // namespace LAMMPS_NS

From a614dcad8d66beae4637e17311884798053b53a0 Mon Sep 17 00:00:00 2001
From: Filippo Bigi <98903385+frostedoyster@users.noreply.github.com>
Date: Thu, 10 Jul 2025 11:59:56 +0200
Subject: [PATCH 11/37] Add datamask flags to metatomic/kk pair style (#17)

This ensure the code works with pair_style hybrid/overlay/kk
---
 src/KOKKOS/pair_metatomic_kokkos.cpp | 14 +++++++++++---
 1 file changed, 11 insertions(+), 3 deletions(-)

diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index fa102d8b966..92ad218dc49 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -41,7 +41,15 @@ template<typename T, class DeviceType>
 using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
 
 template<class DeviceType>
-PairMetatomicKokkos<DeviceType>::PairMetatomicKokkos(LAMMPS* lmp): PairMetatomic(lmp) {}
+PairMetatomicKokkos<DeviceType>::PairMetatomicKokkos(LAMMPS* lmp): PairMetatomic(lmp) {
+    respa_enable = 0;
+
+    kokkosable = 1;
+    execution_space = ExecutionSpaceFromDevice<DeviceType>::space;
+
+    datamask_read = X_MASK | F_MASK | TYPE_MASK | TAG_MASK | ENERGY_MASK | VIRIAL_MASK;
+    datamask_modify = F_MASK | ENERGY_MASK | VIRIAL_MASK;
+}
 
 template<class DeviceType>
 PairMetatomicKokkos<DeviceType>::~PairMetatomicKokkos() {}
@@ -113,8 +121,8 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
     auto _ = MetatomicTimer("PairMetatomicKokkos::compute");
 
     /// Declare what we need to read from the atomKK object and what we will modify
-    this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, X_MASK | F_MASK | TAG_MASK | TYPE_MASK | ENERGY_MASK | VIRIAL_MASK);
-    this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, ENERGY_MASK | F_MASK | VIRIAL_MASK);
+    this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, datamask_read);
+    this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, datamask_modify);
 
     if (eflag || vflag) {
         ev_setup(eflag, vflag);

From c89b4daacc5f36f9ff1cc71a42f119251dae62d9 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Thu, 11 Sep 2025 16:00:14 +0200
Subject: [PATCH 12/37] Update to metatensor-torch 0.8.0 and metatomic 0.1.4

---
 cmake/Modules/Packages/ML-METATOMIC.cmake | 18 +++++++++---------
 src/KOKKOS/metatomic_system_kokkos.cpp    |  5 +++--
 src/KOKKOS/pair_metatomic_kokkos.cpp      |  4 +++-
 src/ML-METATOMIC/metatomic_system.cpp     | 10 ++++++----
 src/ML-METATOMIC/metatomic_types.cpp      |  2 +-
 src/ML-METATOMIC/metatomic_types.h        |  2 +-
 src/ML-METATOMIC/pair_metatomic.cpp       |  4 +++-
 7 files changed, 26 insertions(+), 19 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index f4fc7d1563c..4d198ecbe54 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -41,14 +41,14 @@ endif()
 
 ################ definition of metatensor and metatomic targets ################
 
-set(METATENSOR_CORE_VERSION "0.1.14")
-set(METATENSOR_CORE_SHA1 "9e21c48d9059d8a37618958d9d253220dedf7562")
+set(METATENSOR_CORE_VERSION "0.1.17")
+set(METATENSOR_CORE_SHA256 "42119e11908239915ccc187d7ca65449b461f1d4b5af4d6df1fb613d687da76a")
 
-set(METATENSOR_TORCH_VERSION "0.7.6")
-set(METATENSOR_TORCH_SHA1 "5668f5088a42507e9ca4a7b723b3baac0286035c")
+set(METATENSOR_TORCH_VERSION "0.8.0")
+set(METATENSOR_TORCH_SHA256 "61d383ce958deafe0e3916088185527680c9118588722b17ec5c39cfbaa6da55")
 
-set(METATOMIC_TORCH_VERSION "0.1.1")
-set(METATOMIC_TORCH_SHA1 "12b830c23674339fc185ce6e94e5a445416199ff")
+set(METATOMIC_TORCH_VERSION "0.1.4")
+set(METATOMIC_TORCH_SHA256 "385ec8b8515d674b6a9f093f724792b2469e7ea2365ca596f574b64e38494f94")
 
 set(DOWNLOAD_METATENSOR_DEFAULT ON)
 find_package(metatensor_torch QUIET ${METATENSOR_TORCH_VERSION})
@@ -72,7 +72,7 @@ if (DOWNLOAD_METATENSOR)
     set(URL_BASE "https://github.com/metatensor/metatensor/releases/download")
     FetchContent_Declare(metatensor
         URL ${URL_BASE}/metatensor-core-v${METATENSOR_CORE_VERSION}/metatensor-core-cxx-${METATENSOR_CORE_VERSION}.tar.gz
-        URL_HASH SHA1=${METATENSOR_CORE_SHA1}
+        URL_HASH SHA256=${METATENSOR_CORE_SHA256}
     )
 
     message(STATUS "Fetching metatensor v${METATENSOR_CORE_VERSION} from github")
@@ -80,7 +80,7 @@ if (DOWNLOAD_METATENSOR)
 
     FetchContent_Declare(metatensor-torch
         URL ${URL_BASE}/metatensor-torch-v${METATENSOR_TORCH_VERSION}/metatensor-torch-cxx-${METATENSOR_TORCH_VERSION}.tar.gz
-        URL_HASH SHA1=${METATENSOR_TORCH_SHA1}
+        URL_HASH SHA256=${METATENSOR_TORCH_SHA256}
     )
 
     message(STATUS "Fetching metatensor-torch v${METATENSOR_TORCH_VERSION} from github")
@@ -96,7 +96,7 @@ if (DOWNLOAD_METATOMIC)
     set(URL_BASE "https://github.com/metatensor/metatomic/releases/download")
     FetchContent_Declare(metatomic-torch
         URL ${URL_BASE}/metatomic-torch-v${METATOMIC_TORCH_VERSION}/metatomic-torch-cxx-${METATOMIC_TORCH_VERSION}.tar.gz
-        URL_HASH SHA1=${METATOMIC_TORCH_SHA1}
+        URL_HASH SHA256=${METATOMIC_TORCH_SHA256}
     )
 
     message(STATUS "Fetching metatomic-torch v${METATOMIC_TORCH_VERSION} from github")
diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 845b699d01f..61b6fc36e39 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -277,7 +277,8 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
             auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
             samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
                 std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-                samples_values
+                samples_values,
+                metatensor::assume_unique{}
             );
         }
 
@@ -288,7 +289,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
             neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
                 distances_filt_cur.index_select(0, samples_indices).unsqueeze(-1),
                 samples,
-                std::vector<metatensor_torch::TorchLabels>{
+                std::vector<metatensor_torch::Labels>{
                     metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(this->device_),
                 },
                 metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(this->device_)
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index 92ad218dc49..996c60088ec 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -164,7 +164,9 @@ void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
     );
 
     auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-        std::vector<std::string>{"system", "atom"}, mta_data->selected_atoms_values
+        std::vector<std::string>{"system", "atom"},
+        mta_data->selected_atoms_values,
+        metatensor::assume_unique{}
     );
     mta_data->evaluation_options->set_selected_atoms(selected_atoms);
 
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index acaa1e3d87f..3141b672fc2 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -297,7 +297,8 @@ void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& syst
             auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
             samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
                 std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-                samples_values
+                samples_values,
+                metatensor::assume_unique{}
             );
         }
 
@@ -331,7 +332,7 @@ void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& syst
             neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
                 distances_vectors,
                 samples,
-                std::vector<metatensor_torch::TorchLabels>{
+                std::vector<metatensor_torch::Labels>{
                     metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
                 },
                 metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
@@ -425,7 +426,8 @@ void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& s
             auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) +" pairs)");
             samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
                 std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-                samples_values
+                samples_values,
+                metatensor::assume_unique{}
             );
         }
 
@@ -459,7 +461,7 @@ void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& s
             neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
                 distances_vectors,
                 samples,
-                std::vector<metatensor_torch::TorchLabels>{
+                std::vector<metatensor_torch::Labels>{
                     metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
                 },
                 metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index c2e07ba8945..866296dec3d 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -62,7 +62,7 @@ void PairMetatomicData::load_model(
    }
 
    try {
-       this->model = std::make_unique<torch::jit::Module>(
+       this->model = std::make_unique<metatensor_torch::Module>(
            metatomic_torch::load_atomistic_model(path, extensions)
        );
    } catch (const c10::Error& e) {
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index 0010d628a6a..eb70c9d4313 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -31,7 +31,7 @@ struct PairMetatomicData {
    void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
 
    // torch model in metatensor format
-   std::unique_ptr<torch::jit::Module> model;
+   std::unique_ptr<metatensor_torch::Module> model;
    // device to use for the calculations
    torch::Device device;
    // model capabilities, declared by the model
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 12b1c29e2fd..a3202608d92 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -488,7 +488,9 @@ void PairMetatomic::compute(int eflag, int vflag) {
     );
 
     auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-        std::vector<std::string>{"system", "atom"}, mta_data->selected_atoms_values
+        std::vector<std::string>{"system", "atom"},
+        mta_data->selected_atoms_values,
+        metatensor::assume_unique{}
     );
     mta_data->evaluation_options->set_selected_atoms(selected_atoms);
 

From 8a9e1ec94def86301b4afebbeb03d2bff3d1e04e Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Thu, 11 Sep 2025 16:05:04 +0200
Subject: [PATCH 13/37] Correct a few missing metatensor => metatomic
 substitutions

---
 src/ML-METATOMIC/metatomic_system.cpp |  9 ++++-----
 src/ML-METATOMIC/metatomic_system.h   | 12 ++++++------
 src/ML-METATOMIC/metatomic_timer.h    |  2 +-
 src/ML-METATOMIC/metatomic_types.cpp  |  4 ++--
 src/ML-METATOMIC/metatomic_types.h    |  2 +-
 src/ML-METATOMIC/pair_metatomic.cpp   |  6 +++---
 6 files changed, 17 insertions(+), 18 deletions(-)

diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 3141b672fc2..8fa0ca907a8 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -359,7 +359,7 @@ void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& s
             auto cutoff2 = cache.cutoff * cache.cutoff;
             auto full_list = cache.options->full_list();
 
-            // convert from LAMMPS neighbors list to metatensor format
+            // convert from LAMMPS neighbors list to metatomic format
             cache.known_samples.clear();
             cache.samples.clear();
             cache.distances_f32.clear();
@@ -523,11 +523,10 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     }
 
     // Periodic boundary conditions handling.
-    // While Metatensor atomistic models can support mixed PBC settings, we
-    // currently assume that the system is fully periodic and we throw an error
-    // otherwise
+    // While metatomic models can support mixed PBC settings, we currently
+    // assume that the system is fully periodic and we throw an error otherwise
     if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-        error->all(FLERR, "pair_metatensor requires a fully periodic system");
+        error->all(FLERR, "pair_style metatomic requires a fully periodic system");
     }
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index 5731c60b978..15c58a8bf8f 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -28,7 +28,7 @@
 namespace LAMMPS_NS {
 
 struct MetatomicSystemOptions {
-    // Mapping from LAMMPS types to metatensor types.
+    // Mapping from LAMMPS types to metatomic types.
     // If used with kokkos, this should be a device pointer
     int32_t* types_mapping;
     // interaction range of the model, in LAMMPS units
@@ -39,7 +39,7 @@ struct MetatomicSystemOptions {
     bool requires_grad;
 };
 
-// data for metatensor neighbors lists
+// data for metatomic neighbors lists
 struct MetatomicNeighborsData {
     // single neighbors sample containing [i, j, S_a, S_b, S_c]
     using sample_t = std::array<int32_t, 5>;
@@ -65,7 +65,7 @@ struct MetatomicNeighborsData {
     // options of the NL as requested by the model
     metatomic_torch::NeighborListOptions options;
 
-    // Below are cached allocations for the LAMMPS -> metatensor NL translation
+    // Below are cached allocations for the LAMMPS -> metatomic NL translation
     // TODO: report memory usage for these?
 
     // we keep the set of samples twice: once in `known_samples` to remove
@@ -86,7 +86,7 @@ class MetatomicSystemAdaptor : public Pointers {
 
     void add_nl_request(double cutoff, metatomic_torch::NeighborListOptions request);
 
-    // Create a metatensor system matching the LAMMPS system data
+    // Create a metatomic system matching the LAMMPS system data
     virtual metatomic_torch::System system_from_lmp(
         NeighList* list,
         bool do_virial,
@@ -103,11 +103,11 @@ class MetatomicSystemAdaptor : public Pointers {
     torch::Tensor positions;
 
  protected:
-    // setup the metatensor neighbors list from the internal LAMMPS one,
+    // setup the metatomic neighbors list from the internal LAMMPS one,
     // remapping periodic ghosts to the corresponding local atom
     void setup_neighbors_remap(metatomic_torch::System& system, NeighList* list);
 
-    // setup the metatensor neighbors list from the internal LAMMPS one,
+    // setup the metatomic neighbors list from the internal LAMMPS one,
     // WITHOUT remapping periodic ghosts to the corresponding local atom.
     //
     // This produces a larger NL but skips the cost of the remapping
diff --git a/src/ML-METATOMIC/metatomic_timer.h b/src/ML-METATOMIC/metatomic_timer.h
index 4b3019aa1c4..ba945f8a148 100644
--- a/src/ML-METATOMIC/metatomic_timer.h
+++ b/src/ML-METATOMIC/metatomic_timer.h
@@ -19,7 +19,7 @@
 
 namespace LAMMPS_NS {
 
-/// Simple timer for profiling the LAMMPS/Metatensor integration. This starts
+/// Simple timer for profiling the LAMMPS/metatomic integration. This starts
 /// the timer when created, and print the elapsed time to stderr when going out
 /// of scope.
 class MetatomicTimer {
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 866296dec3d..1bfcc6be8a0 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -66,14 +66,14 @@ void PairMetatomicData::load_model(
            metatomic_torch::load_atomistic_model(path, extensions)
        );
    } catch (const c10::Error& e) {
-       lmp->error->all(FLERR, "failed to load metatensor model at '{}': {}", path, e.what());
+       lmp->error->all(FLERR, "failed to load metatomic model at '{}': {}", path, e.what());
    }
 
    auto capabilities_ivalue = this->model->run_method("capabilities");
    this->capabilities = capabilities_ivalue.toCustomClass<metatomic_torch::ModelCapabilitiesHolder>();
 
    if (!this->capabilities->outputs().contains("energy")) {
-       lmp->error->all(FLERR, "the model at '{}' does not have an \"energy\" output, we can not use it in pair_style metatensor", path);
+       lmp->error->all(FLERR, "the model at '{}' does not have an \"energy\" output, we can not use it in pair_style metatomic", path);
    }
 
    if (lmp->comm->me == 0) {
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index eb70c9d4313..b7416751219 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -30,7 +30,7 @@ struct PairMetatomicData {
 
    void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
 
-   // torch model in metatensor format
+   // the metatomic model
    std::unique_ptr<metatensor_torch::Module> model;
    // device to use for the calculations
    torch::Device device;
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index a3202608d92..2ffea591fc8 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -93,7 +93,7 @@ PairMetatomic::~PairMetatomic() {
     }
 }
 
-// called when finding `pair_style metatensor` in the input
+// called when finding `pair_style metatomic` in the input
 void PairMetatomic::settings(int argc, char ** argv) {
     if (argc == 0) {
         error->all(FLERR, "expected at least 1 argument to pair_style metatomic, got {}", argc);
@@ -129,7 +129,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
             i += 1;
         } else if (strcmp(argv[i], "non_conservative") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatensor, got nothing");
+                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got nothing");
             } else if (strcmp(argv[i + 1], "on") == 0) {
                 mta_data->non_conservative = true;
                 // add the non-conservative forces and stress to the requested outputs
@@ -148,7 +148,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
             } else if (strcmp(argv[i + 1], "off") == 0) {
                 mta_data->non_conservative = false;
             } else {
-                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatensor, got '{}'", argv[i + 1]);
+                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got '{}'", argv[i + 1]);
             }
 
             i += 1;

From ab5c15b0f7432875dfaad8bc5f166a6431887e1a Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 12 Sep 2025 11:03:56 +0200
Subject: [PATCH 14/37] C++17 is now required by LAMMPS

---
 cmake/CMakeLists.txt                      | 4 +---
 cmake/Modules/Packages/ML-METATOMIC.cmake | 6 ------
 2 files changed, 1 insertion(+), 9 deletions(-)

diff --git a/cmake/CMakeLists.txt b/cmake/CMakeLists.txt
index 5ce07bedcfc..507385fd534 100644
--- a/cmake/CMakeLists.txt
+++ b/cmake/CMakeLists.txt
@@ -153,9 +153,7 @@ endif()
 if(CMAKE_CXX_STANDARD LESS 17)
   message(FATAL_ERROR "C++ standard must be set to at least 17")
 endif()
-if((PKG_KOKKOS OR PKG_ML-METATOMIC) AND (CMAKE_CXX_STANDARD LESS 17))
-  set(CMAKE_CXX_STANDARD 17)
-endif()
+
 # turn off C++20 check in lmptype.h
 #if(LAMMPS_CXX17)
 #  add_compile_definitions(LAMMPS_CXX17)
diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index 4d198ecbe54..9d9798f9559 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -1,9 +1,3 @@
-# metatensor requires C++17 due to Torch requiring C++17
-if(CMAKE_CXX_STANDARD LESS 17)
-  message(FATAL_ERROR "The ML-METATOMIC package requires the C++ standard to
-be set to at least C++17")
-endif()
-
 if (BUILD_OMP AND APPLE)
     message(FATAL_ERROR
         "Can not enable both BUILD_OMP and PGK_ML-METATOMIC on Apple systems, "

From da995e94a6f62b99fa4d2be9342990fe433b7ce4 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 12 Sep 2025 11:05:54 +0200
Subject: [PATCH 15/37] Disable the use of make build system for ML-METATOMIC

---
 src/ML-METATOMIC/Install.sh | 38 +++++++++++++++++++++++++++++++++++++
 1 file changed, 38 insertions(+)
 create mode 100644 src/ML-METATOMIC/Install.sh

diff --git a/src/ML-METATOMIC/Install.sh b/src/ML-METATOMIC/Install.sh
new file mode 100644
index 00000000000..f1ad06760a5
--- /dev/null
+++ b/src/ML-METATOMIC/Install.sh
@@ -0,0 +1,38 @@
+# Install/unInstall package files in LAMMPS
+# mode = 0/1/2 for uninstall/install/update
+
+mode=$1
+
+# enforce using portable C locale
+LC_ALL=C
+export LC_ALL
+
+action () {
+  if (test $mode = 0) then
+    rm -f ../$1
+  fi
+}
+
+# all package files with no dependencies
+
+for file in *.cpp *.h; do
+  test -f ${file} && action $file
+done
+
+# edit 2 Makefile.package files to include/exclude package info
+
+if (test $1 = 1 || test $1 = 2) then
+  echo "The ML-METATOMIC package does not support the legacy build system. Please build LAMMPS with CMake instead."
+  exit 1
+
+elif (test $1 = 0) then
+
+  if (test -e ../Makefile.package) then
+    sed -i -e 's/[^ \t]*hdnnp[^ \t]* //g' ../Makefile.package
+  fi
+
+  if (test -e ../Makefile.package.settings) then
+    sed -i -e '/^[ \t]*include.*hdnnp.*$/d' ../Makefile.package.settings
+  fi
+
+fi

From d2bac82a7242d74b3ab0665b582b0ae61ba3cfd6 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Thu, 25 Sep 2025 13:49:43 +0200
Subject: [PATCH 16/37] Use metatensor-torch v0.8.1

---
 cmake/Modules/Packages/ML-METATOMIC.cmake | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index 9d9798f9559..6d3afb2c6c9 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -38,8 +38,8 @@ endif()
 set(METATENSOR_CORE_VERSION "0.1.17")
 set(METATENSOR_CORE_SHA256 "42119e11908239915ccc187d7ca65449b461f1d4b5af4d6df1fb613d687da76a")
 
-set(METATENSOR_TORCH_VERSION "0.8.0")
-set(METATENSOR_TORCH_SHA256 "61d383ce958deafe0e3916088185527680c9118588722b17ec5c39cfbaa6da55")
+set(METATENSOR_TORCH_VERSION "0.8.1")
+set(METATENSOR_TORCH_SHA256 "9da124e8e09dc1859700723a76ff29aef7a216b84a19d38746cc45bf45bc599b")
 
 set(METATOMIC_TORCH_VERSION "0.1.4")
 set(METATOMIC_TORCH_SHA256 "385ec8b8515d674b6a9f093f724792b2469e7ea2365ca596f574b64e38494f94")

From ea547e5768155f94dbb6e9e391da8c9f10ecad54 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Thu, 25 Sep 2025 17:18:34 +0200
Subject: [PATCH 17/37] Improve handling of outputs from a model

We now check that a model does have the correct output, and handle
models with fewer outputs better (such as a model without "energy"
used in non-conservative mode).
---
 examples/PACKAGES/metatomic/nickel-lj.pt | Bin 47169 -> 48577 bytes
 src/ML-METATOMIC/metatomic_types.cpp     |  17 +--
 src/ML-METATOMIC/metatomic_types.h       |  13 +-
 src/ML-METATOMIC/pair_metatomic.cpp      | 176 +++++++++++++++++------
 src/ML-METATOMIC/pair_metatomic.h        |   3 +
 5 files changed, 149 insertions(+), 60 deletions(-)

diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 1bfcc6be8a0..91436f0d3c6 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -22,7 +22,7 @@
 
 using namespace LAMMPS_NS;
 
-PairMetatomicData::PairMetatomicData(std::string length_unit, std::string energy_unit):
+PairMetatomicData::PairMetatomicData(std::string length_unit):
     device(torch::kCPU),
     check_consistency(false),
     remap_pairs(true),
@@ -35,14 +35,6 @@ PairMetatomicData::PairMetatomicData(std::string length_unit, std::string energy
     // Initialize evaluation_options
     this->evaluation_options = torch::make_intrusive<metatomic_torch::ModelEvaluationOptionsHolder>();
     this->evaluation_options->set_length_unit(std::move(length_unit));
-
-    auto output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
-    output->explicit_gradients = {};
-    output->set_quantity("energy");
-    output->set_unit(std::move(energy_unit));
-    output->per_atom = false;
-
-    this->evaluation_options->outputs.insert("energy", output);
 }
 
 void PairMetatomicData::load_model(
@@ -52,6 +44,7 @@ void PairMetatomicData::load_model(
 ) {
    // TODO: seach for the model & extensions inside `$LAMMPS_POTENTIALS`?
 
+   this->model_path = path;
    if (this->model != nullptr) {
        lmp->error->all(FLERR, "torch model is already loaded");
    }
@@ -63,7 +56,7 @@ void PairMetatomicData::load_model(
 
    try {
        this->model = std::make_unique<metatensor_torch::Module>(
-           metatomic_torch::load_atomistic_model(path, extensions)
+           metatomic_torch::load_atomistic_model(this->model_path, extensions)
        );
    } catch (const c10::Error& e) {
        lmp->error->all(FLERR, "failed to load metatomic model at '{}': {}", path, e.what());
@@ -72,10 +65,6 @@ void PairMetatomicData::load_model(
    auto capabilities_ivalue = this->model->run_method("capabilities");
    this->capabilities = capabilities_ivalue.toCustomClass<metatomic_torch::ModelCapabilitiesHolder>();
 
-   if (!this->capabilities->outputs().contains("energy")) {
-       lmp->error->all(FLERR, "the model at '{}' does not have an \"energy\" output, we can not use it in pair_style metatomic", path);
-   }
-
    if (lmp->comm->me == 0) {
        auto metadata_ivalue = this->model->run_method("metadata");
        auto metadata = metadata_ivalue.toCustomClass<metatomic_torch::ModelMetadataHolder>();
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index b7416751219..243a3141c4f 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -26,18 +26,29 @@
 namespace LAMMPS_NS {
 
 struct PairMetatomicData {
-   PairMetatomicData(std::string length_unit, std::string energy_unit);
+   PairMetatomicData(std::string length_unit);
 
    void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
 
    // the metatomic model
    std::unique_ptr<metatensor_torch::Module> model;
+   // the path used to load the model
+   std::string model_path;
    // device to use for the calculations
    torch::Device device;
    // model capabilities, declared by the model
    metatomic_torch::ModelCapabilities capabilities;
    // run-time evaluation options, decided by this class
    metatomic_torch::ModelEvaluationOptions evaluation_options;
+
+   // energy output that we'll request from the model
+   metatomic_torch::ModelOutput energy_output;
+   // did the energy output in the model capabilities support per-atom energy?
+   bool is_energy_output_per_atom;
+   // non-conservative forces and stresses outputs that we'll request
+   metatomic_torch::ModelOutput nc_forces_output;
+   metatomic_torch::ModelOutput nc_stress_output;
+
    // should metatomic check the data LAMMPS send to the model
    // and the data the model returns?
    bool check_consistency;
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 2ffea591fc8..cbe253ddd1d 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -24,6 +24,7 @@
 #include "neighbor.h"
 #include "update.h"
 #include "comm.h"
+#include "domain.h"
 
 #include "neigh_list.h"
 #include "neigh_request.h"
@@ -46,26 +47,33 @@
 
 using namespace LAMMPS_NS;
 
+static double compute_volume(Domain* domain) {
+    // from Thermo::compute_vol
+    if (domain->dimension == 3) {
+        return domain->xprd * domain->yprd * domain->zprd;
+    } else {
+        return domain->xprd * domain->yprd;
+    }
+}
+
 PairMetatomic::PairMetatomic(LAMMPS *lmp):
     Pair(lmp),
     type_mapping(nullptr),
     system_adaptor(nullptr),
     scale(1.0)
 {
-    std::string energy_unit;
-    std::string length_unit;
     if (strcmp(update->unit_style, "real") == 0) {
-        length_unit = "angstrom";
-        energy_unit = "kcal/mol";
+        this->length_unit = "angstrom";
+        this->energy_unit = "kcal/mol";
     } else if (strcmp(update->unit_style, "metal") == 0) {
-        length_unit = "angstrom";
-        energy_unit = "eV";
+        this->length_unit = "angstrom";
+        this->energy_unit = "eV";
     } else if (strcmp(update->unit_style, "si") == 0) {
-        length_unit = "meter";
-        energy_unit = "joule";
+        this->length_unit = "meter";
+        this->energy_unit = "joule";
     } else if (strcmp(update->unit_style, "electron") == 0) {
-        length_unit = "Bohr";
-        energy_unit = "Hartree";
+        this->length_unit = "Bohr";
+        this->energy_unit = "Hartree";
     } else {
         error->all(FLERR, "unsupported units '{}' for pair metatomic ", update->unit_style);
     }
@@ -74,7 +82,7 @@ PairMetatomic::PairMetatomic(LAMMPS *lmp):
     // so we can not compute virial as fdotr
     this->no_virial_fdotr_compute = 1;
 
-    this->mta_data = new PairMetatomicData(std::move(length_unit), std::move(energy_unit));
+    this->mta_data = new PairMetatomicData(this->length_unit);
 
     // settings for metatomic pair style
     this->single_enable = 0;
@@ -132,19 +140,6 @@ void PairMetatomic::settings(int argc, char ** argv) {
                 error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got nothing");
             } else if (strcmp(argv[i + 1], "on") == 0) {
                 mta_data->non_conservative = true;
-                // add the non-conservative forces and stress to the requested outputs
-                auto output_nc_forces = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
-                output_nc_forces->explicit_gradients = {};
-                output_nc_forces->set_quantity("force");
-                output_nc_forces->set_unit(mta_data->evaluation_options->outputs.at("energy")->unit() + "/" + mta_data->evaluation_options->length_unit());
-                output_nc_forces->per_atom = true;
-                mta_data->evaluation_options->outputs.insert("non_conservative_forces", output_nc_forces);
-                auto output_nc_stress = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
-                output_nc_stress->explicit_gradients = {};
-                output_nc_stress->set_quantity("pressure");
-                output_nc_stress->set_unit(mta_data->evaluation_options->outputs.at("energy")->unit() + "/" + mta_data->evaluation_options->length_unit() + "^3");
-                output_nc_stress->per_atom = false;
-                mta_data->evaluation_options->outputs.insert("non_conservative_stress", output_nc_stress);
             } else if (strcmp(argv[i + 1], "off") == 0) {
                 mta_data->non_conservative = false;
             } else {
@@ -178,6 +173,61 @@ void PairMetatomic::settings(int argc, char ** argv) {
     // load the model and get it's capabilities (including supported devices)
     mta_data->load_model(this->lmp, model_path, extensions_directory);
 
+    // Check that the model has the required outputs
+    const auto& outputs = mta_data->capabilities->outputs();
+    auto energy_output = outputs.find("energy");
+    // LAMMPS assume that an energy will be available
+    if (energy_output == outputs.end()) {
+        lmp->error->all(FLERR,
+            "the model at '{}' does not have an 'energy' output, "
+            "we can not use it with pair_style metatomic.",
+            model_path
+        );
+    }
+
+    mta_data->is_energy_output_per_atom = energy_output->value()->per_atom;
+    mta_data->energy_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+    mta_data->energy_output->explicit_gradients = {};
+    mta_data->energy_output->set_quantity("energy");
+    mta_data->energy_output->set_unit(this->energy_unit);
+
+
+    if (mta_data->non_conservative) {
+        auto nc_forces = outputs.find("non_conservative_forces");
+        if (nc_forces == outputs.end()) {
+            error->all(FLERR,
+                "the model at '{}' does not have a 'non_conservative_forces' output, "
+                "we can not enable non_conservative simulations",
+                model_path
+            );
+        }
+
+        if (!nc_forces->value()->per_atom) {
+            error->all(FLERR,
+                "the 'non_conservative_forces' output of the model at '{}' "
+                "can not produce per-atom output, we can not enable non_conservative simulations",
+                model_path
+            );
+        }
+
+        mta_data->nc_forces_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+        mta_data->nc_forces_output->explicit_gradients = {};
+        mta_data->nc_forces_output->set_quantity("force");
+        mta_data->nc_forces_output->set_unit(this->energy_unit + "/" + this->length_unit);
+        mta_data->nc_forces_output->per_atom = true;
+
+        auto nc_stress = outputs.find("non_conservative_stress");
+        if (nc_stress != outputs.end()) {
+            mta_data->nc_stress_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+            mta_data->nc_stress_output->explicit_gradients = {};
+            mta_data->nc_stress_output->set_quantity("pressure");
+            mta_data->nc_stress_output->set_unit(this->energy_unit + "/" + this->length_unit + "^3");
+            mta_data->nc_stress_output->per_atom = false;
+        } else {
+            mta_data->nc_stress_output = nullptr;
+        }
+    }
+
     // Select the device to use based on the model's preference, the user choice
     // and what's available.
     this->pick_device(&mta_data->device, requested_device);
@@ -448,16 +498,41 @@ void PairMetatomic::compute(int eflag, int vflag) {
 
     auto _ = MetatomicTimer("PairMetatomic::compute");
 
-    if (eflag || vflag) {
-        ev_setup(eflag, vflag);
-    } else {
-        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
+    ev_init(eflag, vflag);
+
+    mta_data->evaluation_options->outputs.clear();
+    // we need an energy output if the energy was explicitly requested (through
+    // `eflag_either`), or when running in standard/conservative mode, because
+    // we'll get the forces as the gradient of the energy through autodiff.
+    if (eflag_either || !mta_data->non_conservative) {
+        if (eflag_atom) {
+            if (!mta_data->is_energy_output_per_atom) {
+                error->all(FLERR,
+                    "the model at '{}' does not support per-atom 'energy' output",
+                    mta_data->model_path
+                );
+            }
+            mta_data->energy_output->per_atom = true;
+        } else {
+            assert(eflag_global);
+            mta_data->energy_output->per_atom = false;
+        }
+
+        mta_data->evaluation_options->outputs.insert("energy", mta_data->energy_output);
     }
 
-    if (eflag_atom) {
-        mta_data->evaluation_options->outputs.at("energy")->per_atom = true;
-    } else {
-        mta_data->evaluation_options->outputs.at("energy")->per_atom = false;
+    if (mta_data->non_conservative) {
+        mta_data->evaluation_options->outputs.insert("non_conservative_forces", mta_data->nc_forces_output);
+        if (vflag_global) {
+            if (mta_data->nc_stress_output == nullptr) {
+                error->all(FLERR,
+                    "the model at '{}' does not have a 'non_conservative_stress' output, "
+                    "we can not run non_conservative simulations that require computing the stress/virial",
+                    mta_data->model_path
+                );
+            }
+            mta_data->evaluation_options->outputs.insert("non_conservative_stress", mta_data->nc_stress_output);
+        }
     }
 
     auto dtype = torch::kFloat64;
@@ -494,10 +569,10 @@ void PairMetatomic::compute(int eflag, int vflag) {
     );
     mta_data->evaluation_options->set_selected_atoms(selected_atoms);
 
-    torch::IValue result_ivalue;
+    torch::IValue results_ivalue;
     try {
         auto _ = MetatomicTimer("running Model::forward");
-        result_ivalue = mta_data->model->forward({
+        results_ivalue = mta_data->model->forward({
             std::vector<metatomic_torch::System>{system},
             mta_data->evaluation_options,
             mta_data->check_consistency
@@ -506,25 +581,37 @@ void PairMetatomic::compute(int eflag, int vflag) {
         error->all(FLERR, "error evaluating the torch model: {}", e.what());
     }
 
-    auto result = result_ivalue.toGenericDict();
-    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
-    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
-    auto energy_tensor = energy_block->values();
+    auto results = results_ivalue.toGenericDict();
+    torch::Tensor energy_tensor;
+    metatensor_torch::Labels energy_samples;
+
+    // get the energy if we need to compute the energy, or if we are using it to
+    // get the forces/virial with autograd
+    if (eflag_either || !mta_data->non_conservative) {
+        auto energy = results.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
+        auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
+        energy_tensor = energy_block->values();
+        energy_samples = energy_block->samples();
+    }
 
     torch::Tensor forces_tensor;
     torch::Tensor virial_tensor;
 
     if (mta_data->non_conservative) {
-        auto forces = result.at("non_conservative_forces").toCustomClass<metatensor_torch::TensorMapHolder>();;
+        auto forces = results.at("non_conservative_forces").toCustomClass<metatensor_torch::TensorMapHolder>();;
         auto forces_block = metatensor_torch::TensorMapHolder::block_by_id(forces, 0);
         forces_tensor = forces_block->values().squeeze(-1);
         forces_tensor = forces_tensor.to(torch::kCPU).to(torch::kFloat64);
-        auto stress = result.at("non_conservative_stress").toCustomClass<metatensor_torch::TensorMapHolder>();;
-        auto stress_block = metatensor_torch::TensorMapHolder::block_by_id(stress, 0);
-        auto stress_tensor = stress_block->values().squeeze(0).squeeze(-1);
-        virial_tensor = - stress_tensor * torch::abs(torch::det(system->cell()));
-        virial_tensor = virial_tensor.to(torch::kCPU).to(torch::kFloat64);
+
+        if (vflag_global) {
+            auto stress = results.at("non_conservative_stress").toCustomClass<metatensor_torch::TensorMapHolder>();;
+            auto stress_block = metatensor_torch::TensorMapHolder::block_by_id(stress, 0);
+            auto stress_tensor = stress_block->values().squeeze(0).squeeze(-1);
+            virial_tensor = - stress_tensor * compute_volume(domain);
+            virial_tensor = virial_tensor.to(torch::kCPU).to(torch::kFloat64);
+        }
     } else {
+        // compute forces/virial on device with backward propagation
         // reset gradients to zero before calling backward
         this->system_adaptor->positions.mutable_grad() = torch::Tensor();
         this->system_adaptor->strain.mutable_grad() = torch::Tensor();
@@ -541,7 +628,6 @@ void PairMetatomic::compute(int eflag, int vflag) {
 
         // move results to cpu for storing
         auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
-        auto energy_samples = energy_block->samples();
 
         // store the energy returned by the model
         torch::Tensor global_energy;
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
index 6ccad8cb388..c90f39436d7 100644
--- a/src/ML-METATOMIC/pair_metatomic.h
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -77,6 +77,9 @@ class PairMetatomic : public Pair {
     // adaptor from LAMMPS system to metatomic's
     std::unique_ptr<MetatomicSystemAdaptor> system_adaptor;
 
+    std::string length_unit;
+    std::string energy_unit;
+
     double scale;
 };
 

From 9d845134600276b53a8221cbe1b2d12e34e7bfa9 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Thu, 25 Sep 2025 17:24:02 +0200
Subject: [PATCH 18/37] Share more code between the standard and kokkos
 versions of the metatomic pair style

---
 src/KOKKOS/pair_metatomic_kokkos.cpp | 213 ++++-----------------------
 src/KOKKOS/pair_metatomic_kokkos.h   |   7 +-
 src/ML-METATOMIC/pair_metatomic.cpp  | 123 +++++++++-------
 src/ML-METATOMIC/pair_metatomic.h    |  14 +-
 4 files changed, 111 insertions(+), 246 deletions(-)

diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index 996c60088ec..a975957f693 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -25,7 +25,6 @@
 
 #include "metatomic_system_kokkos.h"
 #include "metatomic_types.h"
-#include "metatomic_timer.h"
 
 #include <algorithm>
 #include <cctype>
@@ -93,218 +92,60 @@ void PairMetatomicKokkos<DeviceType>::init_style() {
 }
 
 template<class DeviceType>
-void PairMetatomicKokkos<DeviceType>::pick_device(torch::Device* device, const char* requested) {
-    *device = KokkosDeviceToTorch<DeviceType>::convert();
+void PairMetatomicKokkos<DeviceType>::pick_device(torch::Device& device, const char* requested) {
+    device = KokkosDeviceToTorch<DeviceType>::convert();
 
     if (requested != nullptr) {
         auto requested_str = std::string(requested);
         std::transform(requested_str.begin(), requested_str.end(), requested_str.begin(), ::tolower);
-        if (c10::DeviceTypeName(device->type(), /*lower_case=*/true) != requested_str) {
+        if (c10::DeviceTypeName(device.type(), /*lower_case=*/true) != requested_str) {
             error->all(FLERR,
                 "requested device '{}' does not match the device being used by kokkos '{}', "
                 "use the non-kokkos version of this pair style to use a different "
                 "device for the model and LAMMPS",
-                requested, device->str()
+                requested, device.str()
             );
         }
     }
 }
 
 template<class DeviceType>
-void PairMetatomicKokkos<DeviceType>::compute(int eflag, int vflag) {
-    if (std::getenv("LAMMPS_METATENSOR_PROFILE") != nullptr) {
-        MetatomicTimer::enable(true);
-    } else {
-        MetatomicTimer::enable(false);
-    }
-
-    auto _ = MetatomicTimer("PairMetatomicKokkos::compute");
-
+void PairMetatomicKokkos<DeviceType>::pre_compute() {
     /// Declare what we need to read from the atomKK object and what we will modify
     this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, datamask_read);
     this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, datamask_modify);
+}
 
-    if (eflag || vflag) {
-        ev_setup(eflag, vflag);
-    } else {
-        evflag = vflag_fdotr = eflag_global = eflag_atom = 0;
-    }
-
-    if (eflag_atom) {
-        mta_data->evaluation_options->outputs.at("energy")->per_atom = true;
-    } else {
-        mta_data->evaluation_options->outputs.at("energy")->per_atom = false;
-    }
-
-    auto dtype = torch::kFloat64;
-    if (mta_data->capabilities->dtype() == "float64") {
-        dtype = torch::kFloat64;
-    } else if (mta_data->capabilities->dtype() == "float32") {
-        dtype = torch::kFloat32;
-    } else {
-        error->all(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
-    }
-
-    // transform from LAMMPS to metatensor System
-    auto system = this->system_adaptor->system_from_lmp(
-        mta_list,
-        static_cast<bool>(vflag_global),
-        mta_data->remap_pairs,
-        dtype,
-        mta_data->device
-    );
-
-    // only run the calculation for atoms actually in the current domain
-    mta_data->selected_atoms_values.resize_({atom->nlocal, 2});
-    mta_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
-    auto tensor_options = mta_data->selected_atoms_values.options();
-    mta_data->selected_atoms_values.index_put_(
-        {torch::indexing::Slice(), 1},
-        torch::arange(atom->nlocal, tensor_options)
-    );
-
-    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-        std::vector<std::string>{"system", "atom"},
-        mta_data->selected_atoms_values,
-        metatensor::assume_unique{}
+template<class DeviceType>
+void PairMetatomicKokkos<DeviceType>::store_forces(const at::Tensor& forces_tensor) {
+    assert(forces_tensor.scalar_type() == torch::kFloat64);
+    auto forces = forces_tensor.contiguous();
+
+    auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
+    auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
+        forces.template data_ptr<double>(),
+        forces.size(0), 3
     );
-    mta_data->evaluation_options->set_selected_atoms(selected_atoms);
-
-    torch::IValue result_ivalue;
-    try {
-        auto _ = MetatomicTimer("running Model::forward");
-        result_ivalue = mta_data->model->forward({
-            std::vector<metatomic_torch::System>{system},
-            mta_data->evaluation_options,
-            mta_data->check_consistency
-        });
-    } catch (const std::exception& e) {
-        error->all(FLERR, "error evaluating the torch model: {}", e.what());
-    }
-
-    auto result = result_ivalue.toGenericDict();
-    auto energy = result.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
-    auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
-    auto energy_tensor = energy_block->values();
-
-    torch::Tensor forces_tensor;
-    torch::Tensor virial_tensor;
 
+    int num_forces_to_update;
     if (mta_data->non_conservative) {
-        auto forces = result.at("non_conservative_forces").toCustomClass<metatensor_torch::TensorMapHolder>();;
-        auto forces_block = metatensor_torch::TensorMapHolder::block_by_id(forces, 0);
-        forces_tensor = forces_block->values().squeeze(-1);
-        forces_tensor = forces_tensor.to(torch::kFloat64);
-        auto stress = result.at("non_conservative_stress").toCustomClass<metatensor_torch::TensorMapHolder>();;
-        auto stress_block = metatensor_torch::TensorMapHolder::block_by_id(stress, 0);
-        auto stress_tensor = stress_block->values().squeeze(0).squeeze(-1);
-        virial_tensor = - stress_tensor * torch::abs(torch::det(system->cell()));
-        virial_tensor = virial_tensor.to(torch::kCPU).to(torch::kFloat64);
+        num_forces_to_update = atomKK->nlocal;
     } else {
-        // compute forces/virial on device with backward propagation
-        // reset gradients to zero before calling backward
-        this->system_adaptor->positions.mutable_grad() = torch::Tensor();
-        this->system_adaptor->strain.mutable_grad() = torch::Tensor();
-
-        auto _ = MetatomicTimer("running Model::backward");
-        energy_tensor.backward(-torch::ones_like(energy_tensor));
-
-        forces_tensor = this->system_adaptor->positions.grad();
-        virial_tensor = this->system_adaptor->strain.grad().to(torch::kCPU);
+        num_forces_to_update = atomKK->nlocal + atomKK->nghost;
     }
 
-    {
-        auto _ = MetatomicTimer("storing model output in LAMMPS data structures");
-
-        // move results to cpu for storing
-        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
-        auto energy_samples = energy_block->samples();
-
-        // store the energy returned by the model
-        torch::Tensor global_energy;
-        if (eflag_atom) {
-            assert(energy_samples->size() == 2);
-            assert(energy_samples->names()[0] == "system");
-            assert(energy_samples->names()[1] == "atom");
-
-            auto samples_values = energy_samples->values().to(torch::kCPU);
-            auto samples = samples_values.accessor<int32_t, 2>();
-
-            int64_t n_atoms = atom->nlocal + atom->nghost;
-            assert(samples_values.sizes() == mta_data->selected_atoms_values.sizes());
-
-            auto energies = energy_detached.accessor<double, 2>();
-            for (int64_t i=0; i<energy_samples->count(); i++) {
-                assert(samples[i][0] == 0);
-                // handle potentially out of order samples in
-                // the per-atom energy tensor
-                auto atom_i = samples[i][1];
-                assert(atom_i < n_atoms);
-                eatom[atom_i] += this->scale * energies[i][0];
-            }
-
-            global_energy = energy_detached.sum(0);
-            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
-        } else {
-            assert(energy_samples->size() == 1);
-            assert(energy_samples->names()[0] == "system");
-
-            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
-            global_energy = energy_detached.reshape({1});
-        }
-
-        if (eflag_global) {
-            eng_vdwl += this->scale * global_energy.item<double>();
-        }
-
-        // store forces/virial
-        assert(forces_tensor.scalar_type() == torch::kFloat64);
-        forces_tensor = forces_tensor.contiguous();
-
-        auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
-        auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
-            forces_tensor.template data_ptr<double>(),
-            forces_tensor.size(0), 3
-        );
-
-        int num_forces_to_update;
-        if (mta_data->non_conservative) {
-            num_forces_to_update = atomKK->nlocal;
-        } else {
-            num_forces_to_update = atomKK->nlocal + atomKK->nghost;
-        }
-
-        double scale = this->scale;  // the GPU can't access the `this` pointer
-        Kokkos::parallel_for(
-            num_forces_to_update,
-            KOKKOS_LAMBDA(size_t i) {
-                forces_lammps_kk(i, 0) += scale * forces_metatensor_kk(i, 0);
-                forces_lammps_kk(i, 1) += scale * forces_metatensor_kk(i, 1);
-                forces_lammps_kk(i, 2) += scale * forces_metatensor_kk(i, 2);
-            }
-        );
-
-        assert(!vflag_fdotr);
-
-        if (vflag_global) {
-            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
-            auto predicted_virial = virial_tensor.template accessor<double, 2>();
-
-            virial[0] += this->scale * predicted_virial[0][0];
-            virial[1] += this->scale * predicted_virial[1][1];
-            virial[2] += this->scale * predicted_virial[2][2];
-
-            virial[3] += this->scale * 0.5 * (predicted_virial[1][0] + predicted_virial[0][1]);
-            virial[4] += this->scale * 0.5 * (predicted_virial[2][0] + predicted_virial[0][2]);
-            virial[5] += this->scale * 0.5 * (predicted_virial[2][1] + predicted_virial[1][2]);
-        }
-
-        if (vflag_atom) {
-            error->all(FLERR, "per atom virial is not implemented");
+    double scale = this->scale;  // the GPU can't access the `this` pointer
+    Kokkos::parallel_for(
+        num_forces_to_update,
+        KOKKOS_LAMBDA(size_t i) {
+            forces_lammps_kk(i, 0) += scale * forces_metatensor_kk(i, 0);
+            forces_lammps_kk(i, 1) += scale * forces_metatensor_kk(i, 1);
+            forces_lammps_kk(i, 2) += scale * forces_metatensor_kk(i, 2);
         }
-    }
+    );
 }
 
+
 namespace LAMMPS_NS {
 template class PairMetatomicKokkos<LMPDeviceType>;
 #ifdef LMP_KOKKOS_GPU
diff --git a/src/KOKKOS/pair_metatomic_kokkos.h b/src/KOKKOS/pair_metatomic_kokkos.h
index 931086f2449..11b5abdbc9a 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.h
+++ b/src/KOKKOS/pair_metatomic_kokkos.h
@@ -49,9 +49,12 @@ class PairMetatomicKokkos : public PairMetatomic {
     ~PairMetatomicKokkos();
 
     void init_style() override;
-    void compute(int eflag, int vflag) override;
+
+    void pre_compute() override;
+    void store_forces(const at::Tensor& forces_tensor) override;
+
 private:
-    void pick_device(c10::Device* device, const char* requested) override;
+    void pick_device(c10::Device& device, const char* requested) override;
 
     Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType> type_mapping_kk;
 };
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index cbe253ddd1d..2fdd08960ae 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -230,7 +230,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
 
     // Select the device to use based on the model's preference, the user choice
     // and what's available.
-    this->pick_device(&mta_data->device, requested_device);
+    this->pick_device(mta_data->device, requested_device);
 
     // move all data to the correct device
     mta_data->model->to(mta_data->device);
@@ -280,7 +280,7 @@ std::vector<torch::DeviceType> PairMetatomic::available_devices() {
     return devices;
 }
 
-void PairMetatomic::pick_device(torch::Device* device, const char* requested) {
+void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
     auto available_devices = this->available_devices();
 
     auto picked_device_type = torch::kCPU;
@@ -337,9 +337,9 @@ void PairMetatomic::pick_device(torch::Device* device, const char* requested) {
 
         // (3) split GPUs between node-local processes using round-robin allocation
         int gpu_to_use = local_rank % torch::cuda::device_count();
-        *device = torch::Device(picked_device_type, gpu_to_use);
+        device = torch::Device(picked_device_type, gpu_to_use);
     } else {
-        *device = torch::Device(picked_device_type);
+        device = torch::Device(picked_device_type);
     }
 }
 
@@ -626,68 +626,61 @@ void PairMetatomic::compute(int eflag, int vflag) {
     {
         auto _ = MetatomicTimer("storing model output in LAMMPS data structures");
 
-        // move results to cpu for storing
-        auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
-
-        // store the energy returned by the model
-        torch::Tensor global_energy;
-        if (eflag_atom) {
-            assert(energy_samples->size() == 2);
-            assert(energy_samples->names()[0] == "system");
-            assert(energy_samples->names()[1] == "atom");
-
-            auto samples_values = energy_samples->values().to(torch::kCPU);
-            auto samples = samples_values.accessor<int32_t, 2>();
-
-            int64_t n_atoms = atom->nlocal + atom->nghost;
-            assert(samples_values.sizes() == mta_data->selected_atoms_values.sizes());
-
-            auto energies = energy_detached.accessor<double, 2>();
-            for (int64_t i=0; i<energy_samples->count(); i++) {
-                assert(samples[i][0] == 0);
-                // handle potentially out of order samples in
-                // the per-atom energy tensor
-                auto atom_i = samples[i][1];
-                assert(atom_i < n_atoms);
-                eatom[atom_i] += this->scale * energies[i][0];
+        // store the energy if requested
+        if (eflag_either) {
+            // move results to cpu for storing
+            auto energy_detached = energy_tensor.detach().to(torch::kCPU).to(torch::kFloat64);
+
+            // store the energy returned by the model
+            if (eflag_atom) {
+                assert(mta_data->energy_output->per_atom);
+                assert(energy_samples->size() == 2);
+                assert(energy_samples->names()[0] == "system");
+                assert(energy_samples->names()[1] == "atom");
+
+                auto samples_values = energy_samples->values().to(torch::kCPU);
+                auto samples = samples_values.accessor<int32_t, 2>();
+
+                assert(samples_values.sizes() == mta_data->selected_atoms_values.sizes());
+
+                auto energies = energy_detached.accessor<double, 2>();
+                for (int64_t i=0; i<energy_samples->count(); i++) {
+                    assert(samples[i][0] == 0);
+                    // handle potentially out of order samples in
+                    // the per-atom energy tensor
+                    auto atom_i = samples[i][1];
+                    assert(atom_i < atom->nlocal + atom->nghost);
+                    eatom[atom_i] += this->scale * energies[i][0];
+                }
             }
 
-            global_energy = energy_detached.sum(0);
-            assert(energy_detached.sizes() == std::vector<int64_t>({1}));
-        } else {
-            assert(energy_samples->size() == 1);
-            assert(energy_samples->names()[0] == "system");
+            if (eflag_global) {
+                torch::Tensor global_energy;
+                if (mta_data->energy_output->per_atom) {
+                    global_energy = energy_detached.sum(0);
+                    assert(energy_detached.sizes() == std::vector<int64_t>({1}));
+                } else {
+                    assert(energy_samples->size() == 1);
+                    assert(energy_samples->names()[0] == "system");
 
-            assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
-            global_energy = energy_detached.reshape({1});
-        }
+                    assert(energy_detached.sizes() == std::vector<int64_t>({1, 1}));
+                    global_energy = energy_detached.reshape({1});
+                }
 
-        if (eflag_global) {
-            eng_vdwl += this->scale * global_energy.item<double>();
+                eng_vdwl += this->scale * global_energy.item<double>();
+            }
         }
 
         // store forces/virial
-        assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
-
-        int num_forces_to_update;
-        if (mta_data->non_conservative) {
-            num_forces_to_update = atom->nlocal;
-        } else {
-            num_forces_to_update = atom->nlocal + atom->nghost;
-        }
-
-        auto forces = forces_tensor.accessor<double, 2>();
-        for (int i=0; i<num_forces_to_update; i++) {
-            atom->f[i][0] += this->scale * forces[i][0];
-            atom->f[i][1] += this->scale * forces[i][1];
-            atom->f[i][2] += this->scale * forces[i][2];
-        }
+        this->store_forces(forces_tensor);
 
         assert(!vflag_fdotr);
 
         if (vflag_global) {
-            assert(virial_tensor.is_cpu() && virial_tensor.scalar_type() == torch::kFloat64);
-            auto predicted_virial = virial_tensor.accessor<double, 2>();
+            auto virial_cpu = virial_tensor.to(torch::kCPU);
+            assert(virial_cpu.is_cpu() && virial_cpu.scalar_type() == torch::kFloat64);
+
+            auto predicted_virial = virial_cpu.template accessor<double, 2>();
 
             virial[0] += this->scale * predicted_virial[0][0];
             virial[1] += this->scale * predicted_virial[1][1];
@@ -703,3 +696,23 @@ void PairMetatomic::compute(int eflag, int vflag) {
         }
     }
 }
+
+void PairMetatomic::pre_compute() {}
+
+void PairMetatomic::store_forces(const at::Tensor& forces_tensor) {
+    assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
+
+    int num_forces_to_update;
+    if (mta_data->non_conservative) {
+        num_forces_to_update = atom->nlocal;
+    } else {
+        num_forces_to_update = atom->nlocal + atom->nghost;
+    }
+
+    auto forces = forces_tensor.accessor<double, 2>();
+    for (int i=0; i<num_forces_to_update; i++) {
+        atom->f[i][0] += this->scale * forces[i][0];
+        atom->f[i][1] += this->scale * forces[i][1];
+        atom->f[i][2] += this->scale * forces[i][2];
+    }
+}
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
index c90f39436d7..e3f5f637ae4 100644
--- a/src/ML-METATOMIC/pair_metatomic.h
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -35,13 +35,15 @@ PairStyle(metatomic_9, PairMetatomic);
 
 #include <vector>
 
-// this is the actual namespace where `torch::Device` is defined
 namespace c10 {
     class Device;
-
     enum class DeviceType: int8_t;
 }
 
+namespace at {
+    class Tensor;
+}
+
 namespace LAMMPS_NS {
 class MetatomicSystemAdaptor;
 struct PairMetatomicData;
@@ -60,6 +62,12 @@ class PairMetatomic : public Pair {
 
     void allocate();
 
+    // store the forces from the model in LAMMPS data structures
+    virtual void store_forces(const at::Tensor& forces_tensor);
+
+    // called one at the beginning of `compute`
+    virtual void pre_compute();
+
 protected:
     // get the set of devices both available on the current machine and supported
     // by the model
@@ -67,7 +75,7 @@ class PairMetatomic : public Pair {
 
     // pick the correct device to use from the user request (or nullptr) in
     // `pair_style metatomic`
-    virtual void pick_device(c10::Device* device, const char* requested);
+    virtual void pick_device(c10::Device& device, const char* requested);
 
     PairMetatomicData* mta_data;
     NeighList *mta_list;

From 7b0b6fa1dcfab05d903201e1d691b0c7cb4707b4 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 26 Sep 2025 14:39:19 +0200
Subject: [PATCH 19/37] Add uncertainty quantification to pair_style metatomic

---
 examples/PACKAGES/metatomic/nickel-lj.pt | Bin 48577 -> 48577 bytes
 src/ML-METATOMIC/metatomic_types.h       |  14 +++-
 src/ML-METATOMIC/pair_metatomic.cpp      |  79 ++++++++++++++++++++++-
 3 files changed, 87 insertions(+), 6 deletions(-)

diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index 243a3141c4f..8f1d71c4225 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -41,11 +41,19 @@ struct PairMetatomicData {
    // run-time evaluation options, decided by this class
    metatomic_torch::ModelEvaluationOptions evaluation_options;
 
-   // energy output that we'll request from the model
+   // the energy output we'll request from a model
    metatomic_torch::ModelOutput energy_output;
-   // did the energy output in the model capabilities support per-atom energy?
+   // wether the model capabilities say that it can do per-atom energies
    bool is_energy_output_per_atom;
-   // non-conservative forces and stresses outputs that we'll request
+
+   // energy uncertainty output we'll request from a model, or nullptr if the
+   // model does not have such output
+   metatomic_torch::ModelOutput uncertainty_output;
+   // threshold for energy uncertainty warnings
+   double uncertainty_threshold;
+
+   // non-conservative forces/stress outputs we'll request from a model, or
+   // nullptr if the model does not have such outputs
    metatomic_torch::ModelOutput nc_forces_output;
    metatomic_torch::ModelOutput nc_stress_output;
 
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 2fdd08960ae..067a6b8b91d 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -83,6 +83,8 @@ PairMetatomic::PairMetatomic(LAMMPS *lmp):
     this->no_virial_fdotr_compute = 1;
 
     this->mta_data = new PairMetatomicData(this->length_unit);
+    // use a default uncertainty threshold of 100 meV/atom
+    this->mta_data->uncertainty_threshold = 0.1 * metatomic_torch::unit_conversion_factor("energy", "eV", energy_unit);
 
     // settings for metatomic pair style
     this->single_enable = 0;
@@ -110,6 +112,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
     const char* model_path = argv[0];
     const char* extensions_directory = nullptr;
     const char* requested_device = nullptr;
+    bool do_uncertainty = true;
     for (int i=1; i<argc; i++) {
         if (strcmp(argv[i], "check_consistency") == 0) {
             if (i == argc - 1) {
@@ -164,6 +167,20 @@ void PairMetatomic::settings(int argc, char ** argv) {
                 error->all(FLERR, "expected a number after 'scale' in pair_style metatomic, got nothing");
             }
             this->scale = utils::numeric(FLERR, argv[i + 1], false, lmp);
+            i += 1;
+        } else if (strcmp(argv[i], "uncertainty_threshold") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a number or off after 'uncertainty_threshold' in pair_style metatomic, got nothing");
+            } else if (strcmp(argv[i + 1], "off") == 0) {
+                do_uncertainty = false;
+            } else {
+                mta_data->uncertainty_threshold = utils::numeric(FLERR, argv[i + 1], false, lmp);
+            }
+
+            if (mta_data->uncertainty_threshold <= 0) {
+                error->all(FLERR, "'uncertainty_threshold' in pair_style metatomic must be positive");
+            }
+
             i += 1;
         } else {
             error->all(FLERR, "unexpected argument to pair_style metatomic: '{}'", argv[i]);
@@ -187,10 +204,29 @@ void PairMetatomic::settings(int argc, char ** argv) {
 
     mta_data->is_energy_output_per_atom = energy_output->value()->per_atom;
     mta_data->energy_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
-    mta_data->energy_output->explicit_gradients = {};
     mta_data->energy_output->set_quantity("energy");
     mta_data->energy_output->set_unit(this->energy_unit);
 
+    auto uncertainty_output = outputs.find("energy_uncertainty");
+    if (uncertainty_output != outputs.end()) {
+        if (do_uncertainty && uncertainty_output->value()->per_atom) {
+            // TODO: maybe if there is a global uncertainty output we should use
+            // that as a fallback?
+
+            mta_data->uncertainty_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
+            mta_data->uncertainty_output->set_quantity("energy");
+            mta_data->uncertainty_output->set_unit(this->energy_unit);
+            mta_data->uncertainty_output->per_atom = true;
+
+            auto message = "Found an 'energy_uncertainty' output, we will check for atoms with high uncertainty on the energy predictions";
+            if (screen) {
+                fprintf(screen, "%s\n", message);
+            }
+            if (logfile) {
+                fprintf(logfile,"%s\n", message);
+            }
+        }
+    }
 
     if (mta_data->non_conservative) {
         auto nc_forces = outputs.find("non_conservative_forces");
@@ -211,7 +247,6 @@ void PairMetatomic::settings(int argc, char ** argv) {
         }
 
         mta_data->nc_forces_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
-        mta_data->nc_forces_output->explicit_gradients = {};
         mta_data->nc_forces_output->set_quantity("force");
         mta_data->nc_forces_output->set_unit(this->energy_unit + "/" + this->length_unit);
         mta_data->nc_forces_output->per_atom = true;
@@ -219,7 +254,6 @@ void PairMetatomic::settings(int argc, char ** argv) {
         auto nc_stress = outputs.find("non_conservative_stress");
         if (nc_stress != outputs.end()) {
             mta_data->nc_stress_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
-            mta_data->nc_stress_output->explicit_gradients = {};
             mta_data->nc_stress_output->set_quantity("pressure");
             mta_data->nc_stress_output->set_unit(this->energy_unit + "/" + this->length_unit + "^3");
             mta_data->nc_stress_output->per_atom = false;
@@ -519,6 +553,10 @@ void PairMetatomic::compute(int eflag, int vflag) {
         }
 
         mta_data->evaluation_options->outputs.insert("energy", mta_data->energy_output);
+
+        if (mta_data->uncertainty_output != nullptr) {
+            mta_data->evaluation_options->outputs.insert("energy_uncertainty", mta_data->uncertainty_output);
+        }
     }
 
     if (mta_data->non_conservative) {
@@ -582,6 +620,41 @@ void PairMetatomic::compute(int eflag, int vflag) {
     }
 
     auto results = results_ivalue.toGenericDict();
+
+    // check the max uncertainty
+    if (mta_data->uncertainty_output != nullptr) {
+        auto uncertainty = results.at("energy_uncertainty").toCustomClass<metatensor_torch::TensorMapHolder>();
+        auto uncertainty_block = metatensor_torch::TensorMapHolder::block_by_id(uncertainty, 0);
+        assert(uncertainty_block->values().sizes().size() == 2);
+        assert(uncertainty_block->values().size(1) == 1);
+
+        auto atoms_above_thresholds = uncertainty_block->values().reshape({-1}) > mta_data->uncertainty_threshold;
+        if (torch::any(atoms_above_thresholds).to(torch::kCPU).item<bool>()) {
+            auto atoms = uncertainty_block->samples()->column("atom").index({atoms_above_thresholds});
+            std::ostringstream atoms_message;
+            atoms_message << "atoms at index [";
+            for (size_t i=0; i<10; i++) {
+                if (i > 0) {
+                    atoms_message << ", ";
+                }
+                atoms_message << atoms[i].item<int32_t>();
+            }
+            atoms_message << "]";
+
+            if (atoms.size(0) > 10) {
+                atoms_message << " and " << (atoms.size(0) - 10) << " more";
+            }
+
+            error->warning(FLERR,
+                "The uncertainty on atomic energies for {} are larger than "
+                "the threshold of {}. Be careful when analyzing the results, "
+                "and consider retraining the model to better describe these "
+                "configurations.",
+                atoms_message.str(), mta_data->uncertainty_threshold
+            );
+        }
+    }
+
     torch::Tensor energy_tensor;
     metatensor_torch::Labels energy_samples;
 

From d8bc2d1e85cf34b8bef6f7fbfdbe27df77fd9dbe Mon Sep 17 00:00:00 2001
From: Philip Loche <philip.loche@posteo.de>
Date: Thu, 9 Oct 2025 14:51:49 +0200
Subject: [PATCH 20/37] Use metatomic's `pick_device` function (#24)

---
 cmake/Modules/Packages/ML-METATOMIC.cmake |  4 +-
 src/ML-METATOMIC/pair_metatomic.cpp       | 72 +++--------------------
 2 files changed, 10 insertions(+), 66 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index 6d3afb2c6c9..6819f334e65 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -41,8 +41,8 @@ set(METATENSOR_CORE_SHA256 "42119e11908239915ccc187d7ca65449b461f1d4b5af4d6df1fb
 set(METATENSOR_TORCH_VERSION "0.8.1")
 set(METATENSOR_TORCH_SHA256 "9da124e8e09dc1859700723a76ff29aef7a216b84a19d38746cc45bf45bc599b")
 
-set(METATOMIC_TORCH_VERSION "0.1.4")
-set(METATOMIC_TORCH_SHA256 "385ec8b8515d674b6a9f093f724792b2469e7ea2365ca596f574b64e38494f94")
+set(METATOMIC_TORCH_VERSION "0.1.5")
+set(METATOMIC_TORCH_SHA256 "8ecd1587797fe1cf6b2162ddc10cc84c558fdfd55ab225bc5de4fe15ace8fc3d")
 
 set(DOWNLOAD_METATENSOR_DEFAULT ON)
 find_package(metatensor_torch QUIET ${METATENSOR_TORCH_VERSION})
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 067a6b8b91d..852600cdae0 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -283,72 +283,16 @@ void PairMetatomic::settings(int argc, char ** argv) {
     }
 }
 
-std::vector<torch::DeviceType> PairMetatomic::available_devices() {
-    auto devices = std::vector<torch::DeviceType>();
-    for (const auto& supported: this->mta_data->capabilities->supported_devices) {
-        if (supported == "cpu") {
-            devices.push_back(torch::kCPU);
-        } else if (supported == "cuda" && torch::cuda::is_available()) {
-            devices.push_back(torch::kCUDA);
-        } else if (supported == "mps") {
-            #if TORCH_VERSION_MAJOR >= 2
-            if (torch::mps::is_available()) {
-                devices.push_back(torch::kMPS);
-            }
-            #endif
-        } else {
-            error->warning(FLERR,
-                "the model declared support for unknown device '{}', it will be ignored", supported
-            );
-        }
-    }
-
-    if (devices.empty()) {
-        error->all(FLERR,
-            "failed to find a valid device for this model: "
-            "the model supports {}, none of these where available",
-            torch::str(this->mta_data->capabilities->supported_devices)
-        );
-    }
-
-    return devices;
-}
-
 void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
-    auto available_devices = this->available_devices();
-
-    auto picked_device_type = torch::kCPU;
-    if (requested == nullptr) {
-        // no user request, pick the device the model prefers
-        picked_device_type = available_devices[0];
-    } else {
-        bool found_requested_device = false;
-        for (const auto& device_type: available_devices) {
-            if (device_type == torch::kCPU && strcmp(requested, "cpu") == 0) {
-                picked_device_type = device_type;
-                found_requested_device = true;
-                break;
-            } else if (device_type == torch::kCUDA && strcmp(requested, "cuda") == 0) {
-                picked_device_type = device_type;
-                found_requested_device = true;
-                break;
-            } else if (device_type == torch::kMPS && strcmp(requested, "mps") == 0) {
-                picked_device_type = device_type;
-                found_requested_device = true;
-                break;
-            }
-        }
 
-        if (!found_requested_device) {
-            error->all(FLERR,
-                "failed to find requested device ({}): it is either "
-                "not supported by this model or not available on this machine",
-                requested
-            );
-        }
+    std::string device_string;
+    try {
+        auto device_string = metatomic_torch::pick_device(this->mta_data->capabilities->supported_devices, requested);
+    } catch (const c10::Error& e) {
+        error->all(FLERR, "pair_style metatomic: {}", e.what());
     }
 
-    if (picked_device_type == torch::kCUDA) {
+    if (device_string == "cuda") {
         // distribute GPUs between multiple MPI processes on the same node
 
         // (1) get a MPI communicator for all processes on the current node
@@ -371,9 +315,9 @@ void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
 
         // (3) split GPUs between node-local processes using round-robin allocation
         int gpu_to_use = local_rank % torch::cuda::device_count();
-        device = torch::Device(picked_device_type, gpu_to_use);
+        device = torch::Device("cuda:" + std::to_string(gpu_to_use));
     } else {
-        device = torch::Device(picked_device_type);
+        device = torch::Device(device_string);
     }
 }
 

From 74e8da184d3f6e011e8676a00deced23bf00e497 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Tue, 14 Oct 2025 19:33:36 +0200
Subject: [PATCH 21/37] Fix find_package call for older cmake

---
 cmake/Modules/Packages/ML-METATOMIC.cmake | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index 6819f334e65..52d9279083a 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -45,13 +45,13 @@ set(METATOMIC_TORCH_VERSION "0.1.5")
 set(METATOMIC_TORCH_SHA256 "8ecd1587797fe1cf6b2162ddc10cc84c558fdfd55ab225bc5de4fe15ace8fc3d")
 
 set(DOWNLOAD_METATENSOR_DEFAULT ON)
-find_package(metatensor_torch QUIET ${METATENSOR_TORCH_VERSION})
+find_package(metatensor_torch ${METATENSOR_TORCH_VERSION} QUIET)
 if (metatensor_torch_FOUND)
     set(DOWNLOAD_METATENSOR_DEFAULT OFF)
 endif()
 
 set(DOWNLOAD_METATOMIC_DEFAULT ON)
-find_package(metatomic_torch QUIET ${METATOMIC_TORCH_VERSION})
+find_package(metatomic_torch ${METATOMIC_TORCH_VERSION} QUIET)
 if (metatomic_torch_FOUND)
     set(DOWNLOAD_METATOMIC_DEFAULT OFF)
 endif()
@@ -81,7 +81,7 @@ if (DOWNLOAD_METATENSOR)
     FetchContent_MakeAvailable(metatensor-torch)
 else()
     # make sure to fail the configuration if cmake can not find metatensor-torch
-    find_package(metatensor_torch REQUIRED ${METATENSOR_TORCH_VERSION})
+    find_package(metatensor_torch ${METATENSOR_TORCH_VERSION} REQUIRED)
 endif()
 
 if (DOWNLOAD_METATOMIC)
@@ -97,7 +97,7 @@ if (DOWNLOAD_METATOMIC)
     FetchContent_MakeAvailable(metatomic-torch)
 else()
     # make sure to fail the configuration if cmake can not find metatomic-torch
-    find_package(metatomic_torch REQUIRED ${METATOMIC_TORCH_VERSION})
+    find_package(metatomic_torch ${METATOMIC_TORCH_VERSION} REQUIRED)
 endif()
 
 

From e9b222e03c1a0b81dd183f398e536e38a28b75da Mon Sep 17 00:00:00 2001
From: Philip Loche <ploche@physik.fu-berlin.de>
Date: Thu, 9 Oct 2025 17:30:32 +0200
Subject: [PATCH 22/37] Add variants options

---
 examples/PACKAGES/metatomic/nickel-lj.pt | Bin 48577 -> 69835 bytes
 src/ML-METATOMIC/metatomic_types.h       |   9 ++
 src/ML-METATOMIC/pair_metatomic.cpp      | 167 +++++++++++++++++++----
 3 files changed, 152 insertions(+), 24 deletions(-)

diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index 8f1d71c4225..3eea1e3ea77 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -70,6 +70,15 @@ struct PairMetatomicData {
 
    // allocation cache for the selected atoms
    torch::Tensor selected_atoms_values;
+
+   // energy key for the model
+   std::string energy_key;
+   // energy uncertainty key for the model
+   std::string energy_uq_key;
+   // non-conservative forces key for the model
+   std::string nc_forces_key;
+   // non-conservative stress key for the model
+   std::string nc_stress_key;
 };
 
 }    // namespace LAMMPS_NS
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 852600cdae0..8d3b578df1c 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -113,6 +113,11 @@ void PairMetatomic::settings(int argc, char ** argv) {
     const char* extensions_directory = nullptr;
     const char* requested_device = nullptr;
     bool do_uncertainty = true;
+    const char* variant = nullptr;
+    const char* variant_energy = nullptr;
+    const char* variant_energy_uq = nullptr;
+    const char* variant_nc_forces = nullptr;
+    const char* variant_nc_stress = nullptr;
     for (int i=1; i<argc; i++) {
         if (strcmp(argv[i], "check_consistency") == 0) {
             if (i == argc - 1) {
@@ -180,19 +185,125 @@ void PairMetatomic::settings(int argc, char ** argv) {
             if (mta_data->uncertainty_threshold <= 0) {
                 error->all(FLERR, "'uncertainty_threshold' in pair_style metatomic must be positive");
             }
-
+            i += 1;
+        } else if (strcmp(argv[i], "variant") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a name after 'variant' in pair_style metatomic, got nothing");
+            }
+            variant = argv[i + 1];
+            i += 1;
+        } else if (strcmp(argv[i], "variant/energy") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a name or 'off' after 'variant/energy' in pair_style metatomic, got nothing");
+            }
+            variant_energy = argv[i + 1];
+            i += 1;
+        } else if (strcmp(argv[i], "variant/energy_uncertainty") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a name or 'off' after 'variant/energy_uncertainty' in pair_style metatomic, got nothing");
+            }
+            variant_energy_uq = argv[i + 1];
+            i += 1;
+        } else if (strcmp(argv[i], "variant/non_conservative_forces") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a name or 'off' after 'variant/non_conservative_forces' in pair_style metatomic, got nothing");
+            }
+            variant_nc_forces = argv[i + 1];
+            i += 1;
+        } else if (strcmp(argv[i], "variant/non_conservative_stress") == 0) {
+            if (i == argc - 1) {
+                error->all(FLERR, "expected a name or 'off' after 'variant/non_conservative_stress' in pair_style metatomic, got nothing");
+            }
+            variant_nc_stress = argv[i + 1];
             i += 1;
         } else {
             error->all(FLERR, "unexpected argument to pair_style metatomic: '{}'", argv[i]);
         }
     }
 
-    // load the model and get it's capabilities (including supported devices)
+    // Load the model and get it's capabilities (including supported devices)
     mta_data->load_model(this->lmp, model_path, extensions_directory);
 
+    // Set and resolve the variants to use
+    mta_data->energy_key = "energy";
+    mta_data->energy_uq_key = "energy_uncertainty";
+    mta_data->nc_forces_key = "non_conservative_forces";
+    mta_data->nc_stress_key = "non_conservative_stress";
+
+    // Apply global variant (applies to all)
+    if (variant != nullptr) {
+        mta_data->energy_key += "/" + std::string(variant);
+        mta_data->energy_uq_key += "/" + std::string(variant);
+        mta_data->nc_forces_key += "/" + std::string(variant);
+        mta_data->nc_stress_key += "/" + std::string(variant);
+    }
+
+    // Apply variant/energy
+    if (variant_energy != nullptr) {
+        if (strcmp(variant_energy, "off") == 0) {
+            mta_data->energy_key = "energy";
+        } else {
+            mta_data->energy_key = "energy/" + std::string(variant_energy);
+        }
+    }
+
+    // Apply variant/energy_uncertainty
+    if (variant_energy_uq != nullptr) {
+        if (strcmp(variant_energy_uq, "off") == 0) {
+            mta_data->energy_uq_key = "energy_uncertainty";
+        } else {
+            mta_data->energy_uq_key = "energy_uncertainty/" + std::string(variant_energy_uq);
+        }
+    }
+
+    // Handle non-conservative variants
+    bool has_nc_forces = variant_nc_forces != nullptr;
+    bool has_nc_stress = variant_nc_stress != nullptr;
+
+    if (has_nc_forces && has_nc_stress) {
+        bool forces_none = strcmp(variant_nc_forces, "off") == 0;
+        bool stress_none = strcmp(variant_nc_stress, "off") == 0;
+        if (forces_none != stress_none) {
+            error->all(FLERR,
+                "if both 'variant/non_conservative_stress' and "
+                "'variant/non_conservative_forces' are set, they must either "
+                "both be 'off' or both not be 'off'");
+        }
+    } else if (has_nc_forces && !has_nc_stress) {
+        if (strcmp(variant_nc_forces, "off") != 0) {
+            error->all(FLERR,
+                "'variant/non_conservative_forces' is set but "
+                "'variant/non_conservative_stress' is not; "
+                "both must be set together or both be 'off'");
+        }
+    } else if (!has_nc_forces && has_nc_stress) {
+        if (strcmp(variant_nc_stress, "off") != 0) {
+            error->all(FLERR,
+                "'variant/non_conservative_stress' is set but "
+                "'variant/non_conservative_forces' is not; "
+                "both must be set together or both be 'off'");
+        }
+    }
+
+    if (has_nc_forces) {
+        if (strcmp(variant_nc_forces, "off") == 0) {
+            mta_data->nc_forces_key = "non_conservative_forces";
+        } else {
+            mta_data->nc_forces_key = "non_conservative_forces/" + std::string(variant_nc_forces);
+        }
+    }
+
+    if (has_nc_stress) {
+        if (strcmp(variant_nc_stress, "off") == 0) {
+            mta_data->nc_stress_key = "non_conservative_stress";
+        } else {
+            mta_data->nc_stress_key = "non_conservative_stress/" + std::string(variant_nc_stress);
+        }
+    }
+
     // Check that the model has the required outputs
     const auto& outputs = mta_data->capabilities->outputs();
-    auto energy_output = outputs.find("energy");
+    auto energy_output = outputs.find(mta_data->energy_key);
     // LAMMPS assume that an energy will be available
     if (energy_output == outputs.end()) {
         lmp->error->all(FLERR,
@@ -207,7 +318,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
     mta_data->energy_output->set_quantity("energy");
     mta_data->energy_output->set_unit(this->energy_unit);
 
-    auto uncertainty_output = outputs.find("energy_uncertainty");
+    auto uncertainty_output = outputs.find(mta_data->energy_uq_key);
     if (uncertainty_output != outputs.end()) {
         if (do_uncertainty && uncertainty_output->value()->per_atom) {
             // TODO: maybe if there is a global uncertainty output we should use
@@ -218,31 +329,31 @@ void PairMetatomic::settings(int argc, char ** argv) {
             mta_data->uncertainty_output->set_unit(this->energy_unit);
             mta_data->uncertainty_output->per_atom = true;
 
-            auto message = "Found an 'energy_uncertainty' output, we will check for atoms with high uncertainty on the energy predictions";
+            auto message = "Found '{}' output, we will check for atoms with high uncertainty on the energy predictions";
             if (screen) {
-                fprintf(screen, "%s\n", message);
+                fprintf(screen, "%s\n", fmt::format(message, mta_data->energy_uq_key).c_str());
             }
             if (logfile) {
-                fprintf(logfile,"%s\n", message);
+                fprintf(logfile,"%s\n", fmt::format(message, mta_data->energy_uq_key).c_str());
             }
         }
     }
 
     if (mta_data->non_conservative) {
-        auto nc_forces = outputs.find("non_conservative_forces");
+        auto nc_forces = outputs.find(mta_data->nc_forces_key);
         if (nc_forces == outputs.end()) {
             error->all(FLERR,
-                "the model at '{}' does not have a 'non_conservative_forces' output, "
+                "the model at '{}' does not have a '{}' output, "
                 "we can not enable non_conservative simulations",
-                model_path
+                model_path, mta_data->nc_forces_key
             );
         }
 
         if (!nc_forces->value()->per_atom) {
             error->all(FLERR,
-                "the 'non_conservative_forces' output of the model at '{}' "
+                "the '{}' output of the model at '{}' "
                 "can not produce per-atom output, we can not enable non_conservative simulations",
-                model_path
+                mta_data->nc_forces_key, model_path
             );
         }
 
@@ -251,7 +362,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
         mta_data->nc_forces_output->set_unit(this->energy_unit + "/" + this->length_unit);
         mta_data->nc_forces_output->per_atom = true;
 
-        auto nc_stress = outputs.find("non_conservative_stress");
+        auto nc_stress = outputs.find(mta_data->nc_stress_key);
         if (nc_stress != outputs.end()) {
             mta_data->nc_stress_output = torch::make_intrusive<metatomic_torch::ModelOutputHolder>();
             mta_data->nc_stress_output->set_quantity("pressure");
@@ -285,9 +396,17 @@ void PairMetatomic::settings(int argc, char ** argv) {
 
 void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
 
+    torch::optional<std::string> requested_string;
     std::string device_string;
+
+    if (requested != nullptr) {
+        requested_string = std::string(requested);
+    } else {
+        requested_string = torch::nullopt;
+    }
+
     try {
-        auto device_string = metatomic_torch::pick_device(this->mta_data->capabilities->supported_devices, requested);
+        device_string = metatomic_torch::pick_device(this->mta_data->capabilities->supported_devices, requested_string);
     } catch (const c10::Error& e) {
         error->all(FLERR, "pair_style metatomic: {}", e.what());
     }
@@ -496,24 +615,24 @@ void PairMetatomic::compute(int eflag, int vflag) {
             mta_data->energy_output->per_atom = false;
         }
 
-        mta_data->evaluation_options->outputs.insert("energy", mta_data->energy_output);
+        mta_data->evaluation_options->outputs.insert(mta_data->energy_key, mta_data->energy_output);
 
         if (mta_data->uncertainty_output != nullptr) {
-            mta_data->evaluation_options->outputs.insert("energy_uncertainty", mta_data->uncertainty_output);
+            mta_data->evaluation_options->outputs.insert(mta_data->energy_uq_key, mta_data->uncertainty_output);
         }
     }
 
     if (mta_data->non_conservative) {
-        mta_data->evaluation_options->outputs.insert("non_conservative_forces", mta_data->nc_forces_output);
+        mta_data->evaluation_options->outputs.insert(mta_data->nc_forces_key, mta_data->nc_forces_output);
         if (vflag_global) {
             if (mta_data->nc_stress_output == nullptr) {
                 error->all(FLERR,
-                    "the model at '{}' does not have a 'non_conservative_stress' output, "
+                    "the model at '{}' does not have a '{}' output, "
                     "we can not run non_conservative simulations that require computing the stress/virial",
-                    mta_data->model_path
+                    mta_data->model_path, mta_data->nc_stress_key
                 );
             }
-            mta_data->evaluation_options->outputs.insert("non_conservative_stress", mta_data->nc_stress_output);
+            mta_data->evaluation_options->outputs.insert(mta_data->nc_stress_key, mta_data->nc_stress_output);
         }
     }
 
@@ -567,7 +686,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
 
     // check the max uncertainty
     if (mta_data->uncertainty_output != nullptr) {
-        auto uncertainty = results.at("energy_uncertainty").toCustomClass<metatensor_torch::TensorMapHolder>();
+        auto uncertainty = results.at(mta_data->energy_uq_key).toCustomClass<metatensor_torch::TensorMapHolder>();
         auto uncertainty_block = metatensor_torch::TensorMapHolder::block_by_id(uncertainty, 0);
         assert(uncertainty_block->values().sizes().size() == 2);
         assert(uncertainty_block->values().size(1) == 1);
@@ -605,7 +724,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
     // get the energy if we need to compute the energy, or if we are using it to
     // get the forces/virial with autograd
     if (eflag_either || !mta_data->non_conservative) {
-        auto energy = results.at("energy").toCustomClass<metatensor_torch::TensorMapHolder>();
+        auto energy = results.at(mta_data->energy_key).toCustomClass<metatensor_torch::TensorMapHolder>();
         auto energy_block = metatensor_torch::TensorMapHolder::block_by_id(energy, 0);
         energy_tensor = energy_block->values();
         energy_samples = energy_block->samples();
@@ -615,13 +734,13 @@ void PairMetatomic::compute(int eflag, int vflag) {
     torch::Tensor virial_tensor;
 
     if (mta_data->non_conservative) {
-        auto forces = results.at("non_conservative_forces").toCustomClass<metatensor_torch::TensorMapHolder>();;
+        auto forces = results.at(mta_data->nc_forces_key).toCustomClass<metatensor_torch::TensorMapHolder>();
         auto forces_block = metatensor_torch::TensorMapHolder::block_by_id(forces, 0);
         forces_tensor = forces_block->values().squeeze(-1);
         forces_tensor = forces_tensor.to(torch::kCPU).to(torch::kFloat64);
 
         if (vflag_global) {
-            auto stress = results.at("non_conservative_stress").toCustomClass<metatensor_torch::TensorMapHolder>();;
+            auto stress = results.at(mta_data->nc_stress_key).toCustomClass<metatensor_torch::TensorMapHolder>();
             auto stress_block = metatensor_torch::TensorMapHolder::block_by_id(stress, 0);
             auto stress_tensor = stress_block->values().squeeze(0).squeeze(-1);
             virial_tensor = - stress_tensor * compute_volume(domain);

From ff0622939c8e454b8bd2f74f5bee5a4def089427 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 24 Oct 2025 10:52:21 +0200
Subject: [PATCH 23/37] Handle uncertainty warnings when few atoms have high
 uncertainty

---
 src/ML-METATOMIC/pair_metatomic.cpp | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 8d3b578df1c..a0d427e3abc 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -696,7 +696,10 @@ void PairMetatomic::compute(int eflag, int vflag) {
             auto atoms = uncertainty_block->samples()->column("atom").index({atoms_above_thresholds});
             std::ostringstream atoms_message;
             atoms_message << "atoms at index [";
-            for (size_t i=0; i<10; i++) {
+
+            // only print the first 10 atoms above the threshold to avoid
+            // flooding the output
+            for (size_t i=0; i<std::min(static_cast<int64_t>(10), atoms.size(0)); i++) {
                 if (i > 0) {
                     atoms_message << ", ";
                 }

From 1a6c5b50a4fb2fc37dce45c6d642d7d5a62b0f44 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 24 Oct 2025 11:16:40 +0200
Subject: [PATCH 24/37] Print information only on rank 0

---
 src/ML-METATOMIC/pair_metatomic.cpp | 19 ++++++++++++-------
 1 file changed, 12 insertions(+), 7 deletions(-)

diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index a0d427e3abc..f4517036979 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -329,12 +329,14 @@ void PairMetatomic::settings(int argc, char ** argv) {
             mta_data->uncertainty_output->set_unit(this->energy_unit);
             mta_data->uncertainty_output->per_atom = true;
 
-            auto message = "Found '{}' output, we will check for atoms with high uncertainty on the energy predictions";
-            if (screen) {
-                fprintf(screen, "%s\n", fmt::format(message, mta_data->energy_uq_key).c_str());
-            }
-            if (logfile) {
-                fprintf(logfile,"%s\n", fmt::format(message, mta_data->energy_uq_key).c_str());
+            if (comm->me == 0) {
+                auto message = "Found '{}' output, we will check for atoms with high uncertainty on the energy predictions";
+                if (screen) {
+                    fprintf(screen, "%s\n", fmt::format(message, mta_data->energy_uq_key).c_str());
+                }
+                if (logfile) {
+                    fprintf(logfile,"%s\n", fmt::format(message, mta_data->energy_uq_key).c_str());
+                }
             }
         }
     }
@@ -406,7 +408,10 @@ void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
     }
 
     try {
-        device_string = metatomic_torch::pick_device(this->mta_data->capabilities->supported_devices, requested_string);
+        device_string = metatomic_torch::pick_device(
+            this->mta_data->capabilities->supported_devices,
+            requested_string
+        );
     } catch (const c10::Error& e) {
         error->all(FLERR, "pair_style metatomic: {}", e.what());
     }

From 5be8d61ac1310a960a49ef51ba4b05be5474a12f Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 24 Oct 2025 13:50:24 +0200
Subject: [PATCH 25/37] Use error->one instead of error->all

Otherwise we can have a deadlock if only one MPI rank has the
error
---
 src/KOKKOS/metatomic_system_kokkos.cpp |  9 +++-
 src/KOKKOS/pair_metatomic_kokkos.cpp   |  2 +-
 src/ML-METATOMIC/metatomic_system.cpp  | 14 ++---
 src/ML-METATOMIC/metatomic_timer.cpp   |  6 ++-
 src/ML-METATOMIC/metatomic_types.cpp   |  4 +-
 src/ML-METATOMIC/pair_metatomic.cpp    | 74 +++++++++++++-------------
 6 files changed, 59 insertions(+), 50 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 61b6fc36e39..47a952ddf60 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -47,6 +47,9 @@ MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *l
     this->strain = torch::eye(3, tensor_options);
 }
 
+#include <iostream>
+#include "comm.h"
+
 template<class DeviceType>
 void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list) {
     auto _ = MetatomicTimer("converting kokkos neighbors with ghosts remapping");
@@ -54,6 +57,8 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
 
     auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
 
+    std::cout << "rank = " << comm->me << " nlocal = " << atomKK->nlocal << " nghost = " << atomKK->nghost << std::endl;
+
     {
         auto _ = MetatomicTimer("identifying ghosts and real atoms");
         /*-------------- this will be done on CPU for now ------------------------*/
@@ -360,7 +365,7 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     // While Metatomic models can support mixed PBC settings, we currently
     // assume that the system is fully periodic and we throw an error otherwise
     if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-        error->all(FLERR, "metatomic/kk currently requires a fully periodic system");
+        error->one(FLERR, "metatomic/kk currently requires a fully periodic system");
     }
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
@@ -379,7 +384,7 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
         assert(kk_list != nullptr);
         this->setup_neighbors_remap_kk(system, kk_list);
     } else {
-        error->all(FLERR, "the kokkos version of metatomic requires remap_pairs to be true");
+        error->one(FLERR, "the kokkos version of metatomic requires remap_pairs to be true");
     }
 
     return system;
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index a975957f693..6857056bd48 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -99,7 +99,7 @@ void PairMetatomicKokkos<DeviceType>::pick_device(torch::Device& device, const c
         auto requested_str = std::string(requested);
         std::transform(requested_str.begin(), requested_str.end(), requested_str.begin(), ::tolower);
         if (c10::DeviceTypeName(device.type(), /*lower_case=*/true) != requested_str) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "requested device '{}' does not match the device being used by kokkos '{}', "
                 "use the non-kokkos version of this pair style to use a different "
                 "device for the model and LAMMPS",
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 8fa0ca907a8..3ad6d546d98 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -45,13 +45,13 @@ MetatomicSystemAdaptor::~MetatomicSystemAdaptor() {}
 
 void MetatomicSystemAdaptor::add_nl_request(double cutoff, metatomic_torch::NeighborListOptions request) {
     if (cutoff > options_.interaction_range) {
-        error->all(FLERR,
+        error->one(FLERR,
             "Invalid metatomic model: one of the requested neighbor lists "
             "has a cutoff ({}) larger than the model interaction range ({})",
             cutoff, options_.interaction_range
         );
     } else if (cutoff < 0 || !std::isfinite(cutoff)) {
-        error->all(FLERR,
+        error->one(FLERR,
             "model requested an invalid cutoff for neighbors list: {} "
             "(cutoff in model units is {})",
             cutoff, request->cutoff()
@@ -278,7 +278,7 @@ void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& syst
                             });
                         } else {
                             // should be unreachable
-                            error->all(FLERR, "invalid dtype, this is a bug");
+                            error->one(FLERR, "invalid dtype, this is a bug");
                         }
                     }
                 }
@@ -317,7 +317,7 @@ void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& syst
             );
         } else {
             // should be unreachable
-            error->all(FLERR, "invalid dtype, this is a bug");
+            error->one(FLERR, "invalid dtype, this is a bug");
         }
 
         {
@@ -408,7 +408,7 @@ void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& s
                         });
                     } else {
                         // should be unreachable
-                        error->all(FLERR, "invalid dtype, this is a bug");
+                        error->one(FLERR, "invalid dtype, this is a bug");
                     }
                 }
             }
@@ -446,7 +446,7 @@ void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& s
             );
         } else {
             // should be unreachable
-            error->all(FLERR, "invalid dtype, this is a bug");
+            error->one(FLERR, "invalid dtype, this is a bug");
         }
 
         {
@@ -526,7 +526,7 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     // While metatomic models can support mixed PBC settings, we currently
     // assume that the system is fully periodic and we throw an error otherwise
     if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-        error->all(FLERR, "pair_style metatomic requires a fully periodic system");
+        error->one(FLERR, "pair_style metatomic requires a fully periodic system");
     }
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
diff --git a/src/ML-METATOMIC/metatomic_timer.cpp b/src/ML-METATOMIC/metatomic_timer.cpp
index ba33a6b8a6c..f171705d25a 100644
--- a/src/ML-METATOMIC/metatomic_timer.cpp
+++ b/src/ML-METATOMIC/metatomic_timer.cpp
@@ -1,3 +1,4 @@
+#include <mpi.h>
 #include <mutex>
 #include <iostream>
 
@@ -57,7 +58,10 @@ MetatomicTimer::~MetatomicTimer() {
             std::cerr << "\n" << indent << this->name_;
         }
 
-        std::cerr << " took " << elapsed / 1e6 << "ms" << std::flush;
+        int rank;
+        MPI_Comm_rank(MPI_COMM_WORLD, &rank);
+
+        std::cerr << " took " << elapsed / 1e6 << "ms (rank " << rank << ")" << std::flush;
         METATOMIC_TIMER_DEPTH -= 1;
     }
 }
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 91436f0d3c6..7e95dcfb797 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -46,7 +46,7 @@ void PairMetatomicData::load_model(
 
    this->model_path = path;
    if (this->model != nullptr) {
-       lmp->error->all(FLERR, "torch model is already loaded");
+       lmp->error->one(FLERR, "torch model is already loaded");
    }
 
    torch::optional<std::string> extensions = torch::nullopt;
@@ -59,7 +59,7 @@ void PairMetatomicData::load_model(
            metatomic_torch::load_atomistic_model(this->model_path, extensions)
        );
    } catch (const c10::Error& e) {
-       lmp->error->all(FLERR, "failed to load metatomic model at '{}': {}", path, e.what());
+       lmp->error->one(FLERR, "failed to load metatomic model at '{}': {}", path, e.what());
    }
 
    auto capabilities_ivalue = this->model->run_method("capabilities");
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index f4517036979..6d9b22b13d7 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -75,7 +75,7 @@ PairMetatomic::PairMetatomic(LAMMPS *lmp):
         this->length_unit = "Bohr";
         this->energy_unit = "Hartree";
     } else {
-        error->all(FLERR, "unsupported units '{}' for pair metatomic ", update->unit_style);
+        error->one(FLERR, "unsupported units '{}' for pair metatomic ", update->unit_style);
     }
 
     // we might not be running a pure pair potential,
@@ -106,7 +106,7 @@ PairMetatomic::~PairMetatomic() {
 // called when finding `pair_style metatomic` in the input
 void PairMetatomic::settings(int argc, char ** argv) {
     if (argc == 0) {
-        error->all(FLERR, "expected at least 1 argument to pair_style metatomic, got {}", argc);
+        error->one(FLERR, "expected at least 1 argument to pair_style metatomic, got {}", argc);
     }
 
     const char* model_path = argv[0];
@@ -121,61 +121,61 @@ void PairMetatomic::settings(int argc, char ** argv) {
     for (int i=1; i<argc; i++) {
         if (strcmp(argv[i], "check_consistency") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got nothing");
             } else if (strcmp(argv[i + 1], "on") == 0) {
                 mta_data->check_consistency = true;
             } else if (strcmp(argv[i + 1], "off") == 0) {
                 mta_data->check_consistency = false;
             } else {
-                error->all(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got '{}'", argv[i + 1]);
+                error->one(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got '{}'", argv[i + 1]);
             }
 
             i += 1;
         } else if (strcmp(argv[i], "remap_pairs") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got nothing");
             } else if (strcmp(argv[i + 1], "on") == 0) {
                 mta_data->remap_pairs = true;
             } else if (strcmp(argv[i + 1], "off") == 0) {
                 mta_data->remap_pairs = false;
             } else {
-                error->all(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got '{}'", argv[i + 1]);
+                error->one(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got '{}'", argv[i + 1]);
             }
 
             i += 1;
         } else if (strcmp(argv[i], "non_conservative") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got nothing");
             } else if (strcmp(argv[i + 1], "on") == 0) {
                 mta_data->non_conservative = true;
             } else if (strcmp(argv[i + 1], "off") == 0) {
                 mta_data->non_conservative = false;
             } else {
-                error->all(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got '{}'", argv[i + 1]);
+                error->one(FLERR, "expected <on/off> after 'non_conservative' in pair_style metatomic, got '{}'", argv[i + 1]);
             }
 
             i += 1;
         } else if (strcmp(argv[i], "extensions") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected <path> after 'extensions' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected <path> after 'extensions' in pair_style metatomic, got nothing");
             }
             extensions_directory = argv[i + 1];
             i += 1;
         } else if (strcmp(argv[i], "device") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected string after 'device' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected string after 'device' in pair_style metatomic, got nothing");
             }
             requested_device = argv[i + 1];
             i += 1;
         } else if (strcmp(argv[i], "scale") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a number after 'scale' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a number after 'scale' in pair_style metatomic, got nothing");
             }
             this->scale = utils::numeric(FLERR, argv[i + 1], false, lmp);
             i += 1;
         } else if (strcmp(argv[i], "uncertainty_threshold") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a number or off after 'uncertainty_threshold' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a number or off after 'uncertainty_threshold' in pair_style metatomic, got nothing");
             } else if (strcmp(argv[i + 1], "off") == 0) {
                 do_uncertainty = false;
             } else {
@@ -183,41 +183,41 @@ void PairMetatomic::settings(int argc, char ** argv) {
             }
 
             if (mta_data->uncertainty_threshold <= 0) {
-                error->all(FLERR, "'uncertainty_threshold' in pair_style metatomic must be positive");
+                error->one(FLERR, "'uncertainty_threshold' in pair_style metatomic must be positive");
             }
             i += 1;
         } else if (strcmp(argv[i], "variant") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a name after 'variant' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a name after 'variant' in pair_style metatomic, got nothing");
             }
             variant = argv[i + 1];
             i += 1;
         } else if (strcmp(argv[i], "variant/energy") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a name or 'off' after 'variant/energy' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a name or 'off' after 'variant/energy' in pair_style metatomic, got nothing");
             }
             variant_energy = argv[i + 1];
             i += 1;
         } else if (strcmp(argv[i], "variant/energy_uncertainty") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a name or 'off' after 'variant/energy_uncertainty' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a name or 'off' after 'variant/energy_uncertainty' in pair_style metatomic, got nothing");
             }
             variant_energy_uq = argv[i + 1];
             i += 1;
         } else if (strcmp(argv[i], "variant/non_conservative_forces") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a name or 'off' after 'variant/non_conservative_forces' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a name or 'off' after 'variant/non_conservative_forces' in pair_style metatomic, got nothing");
             }
             variant_nc_forces = argv[i + 1];
             i += 1;
         } else if (strcmp(argv[i], "variant/non_conservative_stress") == 0) {
             if (i == argc - 1) {
-                error->all(FLERR, "expected a name or 'off' after 'variant/non_conservative_stress' in pair_style metatomic, got nothing");
+                error->one(FLERR, "expected a name or 'off' after 'variant/non_conservative_stress' in pair_style metatomic, got nothing");
             }
             variant_nc_stress = argv[i + 1];
             i += 1;
         } else {
-            error->all(FLERR, "unexpected argument to pair_style metatomic: '{}'", argv[i]);
+            error->one(FLERR, "unexpected argument to pair_style metatomic: '{}'", argv[i]);
         }
     }
 
@@ -264,21 +264,21 @@ void PairMetatomic::settings(int argc, char ** argv) {
         bool forces_none = strcmp(variant_nc_forces, "off") == 0;
         bool stress_none = strcmp(variant_nc_stress, "off") == 0;
         if (forces_none != stress_none) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "if both 'variant/non_conservative_stress' and "
                 "'variant/non_conservative_forces' are set, they must either "
                 "both be 'off' or both not be 'off'");
         }
     } else if (has_nc_forces && !has_nc_stress) {
         if (strcmp(variant_nc_forces, "off") != 0) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "'variant/non_conservative_forces' is set but "
                 "'variant/non_conservative_stress' is not; "
                 "both must be set together or both be 'off'");
         }
     } else if (!has_nc_forces && has_nc_stress) {
         if (strcmp(variant_nc_stress, "off") != 0) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "'variant/non_conservative_stress' is set but "
                 "'variant/non_conservative_forces' is not; "
                 "both must be set together or both be 'off'");
@@ -306,7 +306,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
     auto energy_output = outputs.find(mta_data->energy_key);
     // LAMMPS assume that an energy will be available
     if (energy_output == outputs.end()) {
-        lmp->error->all(FLERR,
+        lmp->error->one(FLERR,
             "the model at '{}' does not have an 'energy' output, "
             "we can not use it with pair_style metatomic.",
             model_path
@@ -344,7 +344,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
     if (mta_data->non_conservative) {
         auto nc_forces = outputs.find(mta_data->nc_forces_key);
         if (nc_forces == outputs.end()) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "the model at '{}' does not have a '{}' output, "
                 "we can not enable non_conservative simulations",
                 model_path, mta_data->nc_forces_key
@@ -352,7 +352,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
         }
 
         if (!nc_forces->value()->per_atom) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "the '{}' output of the model at '{}' "
                 "can not produce per-atom output, we can not enable non_conservative simulations",
                 mta_data->nc_forces_key, model_path
@@ -413,7 +413,7 @@ void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
             requested_string
         );
     } catch (const c10::Error& e) {
-        error->all(FLERR, "pair_style metatomic: {}", e.what());
+        error->one(FLERR, "pair_style metatomic: {}", e.what());
     }
 
     if (device_string == "cuda") {
@@ -492,11 +492,11 @@ double PairMetatomic::init_one(int, int) {
 // called on pair_coeff
 void PairMetatomic::coeff(int argc, char ** argv) {
     if (argc < 3 || strcmp(argv[0], "*") != 0 || strcmp(argv[1], "*") != 0) {
-        error->all(FLERR, "invalid pair_coeff, expected `pair_coeff * * <list of types>`");
+        error->one(FLERR, "invalid pair_coeff, expected `pair_coeff * * <list of types>`");
     }
 
     if (atom->ntypes != argc - 2) {
-        error->all(FLERR,
+        error->one(FLERR,
             "invalid pair_coeff, expected `pair_coeff * * <list of types>` with {} types",
             atom->ntypes
         );
@@ -524,16 +524,16 @@ void PairMetatomic::init_style() {
     // gradient of a local descriptor w.r.t. domain ghosts (periodic images
     // ghosts are handled separately).
     if (force->newton_pair != 1) {
-        error->all(FLERR, "Pair style metatomic requires newton pair on");
+        error->one(FLERR, "Pair style metatomic requires newton pair on");
     }
 
     // get the model's interaction range
     auto range = mta_data->capabilities->engine_interaction_range(mta_data->evaluation_options->length_unit());
     if (range < 0) {
-        error->all(FLERR, "interaction_range is negative for this model");
+        error->one(FLERR, "interaction_range is negative for this model");
     } else if (!std::isfinite(range)) {
         if (comm->nprocs > 1) {
-            error->all(FLERR,
+            error->one(FLERR,
                 "interaction_range is infinite for this model, "
                 "using multiple MPI domains is not supported"
             );
@@ -552,7 +552,7 @@ void PairMetatomic::init_style() {
     }
 
     if (!std::isfinite(mta_data->max_cutoff)) {
-        error->all(FLERR,
+        error->one(FLERR,
             "the largest cutoff of this model is infinite, "
             "we can't compute the corresponding neighbor list"
         );
@@ -609,7 +609,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
     if (eflag_either || !mta_data->non_conservative) {
         if (eflag_atom) {
             if (!mta_data->is_energy_output_per_atom) {
-                error->all(FLERR,
+                error->one(FLERR,
                     "the model at '{}' does not support per-atom 'energy' output",
                     mta_data->model_path
                 );
@@ -631,7 +631,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
         mta_data->evaluation_options->outputs.insert(mta_data->nc_forces_key, mta_data->nc_forces_output);
         if (vflag_global) {
             if (mta_data->nc_stress_output == nullptr) {
-                error->all(FLERR,
+                error->one(FLERR,
                     "the model at '{}' does not have a '{}' output, "
                     "we can not run non_conservative simulations that require computing the stress/virial",
                     mta_data->model_path, mta_data->nc_stress_key
@@ -647,7 +647,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
     } else if (mta_data->capabilities->dtype() == "float32") {
         dtype = torch::kFloat32;
     } else {
-        error->all(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
+        error->one(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
     }
 
     // transform from LAMMPS to metatomic System
@@ -684,7 +684,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
             mta_data->check_consistency
         });
     } catch (const std::exception& e) {
-        error->all(FLERR, "error evaluating the torch model: {}", e.what());
+        error->one(FLERR, "error evaluating the torch model: {}", e.what());
     }
 
     auto results = results_ivalue.toGenericDict();
@@ -836,7 +836,7 @@ void PairMetatomic::compute(int eflag, int vflag) {
         }
 
         if (vflag_atom) {
-            error->all(FLERR, "per atom virial is not implemented");
+            error->one(FLERR, "per atom virial is not implemented");
         }
     }
 }

From ab8157aa61185e7a51bcf4eb26f062cff748af1d Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 7 Nov 2025 15:47:54 +0100
Subject: [PATCH 26/37] Remove leftover debugging code

---
 src/KOKKOS/metatomic_system_kokkos.cpp | 3 ---
 1 file changed, 3 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 47a952ddf60..d5768f7bfbb 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -47,7 +47,6 @@ MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *l
     this->strain = torch::eye(3, tensor_options);
 }
 
-#include <iostream>
 #include "comm.h"
 
 template<class DeviceType>
@@ -57,8 +56,6 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomi
 
     auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
 
-    std::cout << "rank = " << comm->me << " nlocal = " << atomKK->nlocal << " nghost = " << atomKK->nghost << std::endl;
-
     {
         auto _ = MetatomicTimer("identifying ghosts and real atoms");
         /*-------------- this will be done on CPU for now ------------------------*/

From 8627e109242a74bc6da4c35ccf38061417209760 Mon Sep 17 00:00:00 2001
From: Philip Loche <philip.loche@posteo.de>
Date: Tue, 18 Nov 2025 10:37:08 +0100
Subject: [PATCH 27/37] Use the pick_output function from metatomic

---
 cmake/Modules/Packages/ML-METATOMIC.cmake |   8 +-
 src/ML-METATOMIC/pair_metatomic.cpp       | 135 ++++++++++------------
 2 files changed, 64 insertions(+), 79 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index 52d9279083a..91813509894 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -38,11 +38,11 @@ endif()
 set(METATENSOR_CORE_VERSION "0.1.17")
 set(METATENSOR_CORE_SHA256 "42119e11908239915ccc187d7ca65449b461f1d4b5af4d6df1fb613d687da76a")
 
-set(METATENSOR_TORCH_VERSION "0.8.1")
-set(METATENSOR_TORCH_SHA256 "9da124e8e09dc1859700723a76ff29aef7a216b84a19d38746cc45bf45bc599b")
+set(METATENSOR_TORCH_VERSION "0.8.2")
+set(METATENSOR_TORCH_SHA256 "0be618d0cdcfca86cd0c25f47d360b6a2410ebb09ece8d21f153e933ce64bb55")
 
-set(METATOMIC_TORCH_VERSION "0.1.5")
-set(METATOMIC_TORCH_SHA256 "8ecd1587797fe1cf6b2162ddc10cc84c558fdfd55ab225bc5de4fe15ace8fc3d")
+set(METATOMIC_TORCH_VERSION "0.1.6")
+set(METATOMIC_TORCH_SHA256 "4cb9b7bb530a98119186167c31fb00ea7ef3bcc45d593e449e7670e9313e5327")
 
 set(DOWNLOAD_METATENSOR_DEFAULT ON)
 find_package(metatensor_torch ${METATENSOR_TORCH_VERSION} QUIET)
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 6d9b22b13d7..658c0f2647a 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -47,6 +47,16 @@
 
 using namespace LAMMPS_NS;
 
+static torch::optional<std::string> normalize_variant(const char* variant_string) {
+    if (variant_string == nullptr) {
+        return torch::nullopt;
+    } else if (strcmp(variant_string, "off") == 0) {
+        return torch::nullopt;
+    } else {
+        return std::string(variant_string);
+    }
+}
+
 static double compute_volume(Domain* domain) {
     // from Thermo::compute_vol
     if (domain->dimension == 3) {
@@ -223,86 +233,66 @@ void PairMetatomic::settings(int argc, char ** argv) {
 
     // Load the model and get it's capabilities (including supported devices)
     mta_data->load_model(this->lmp, model_path, extensions_directory);
+    const auto& outputs = mta_data->capabilities->outputs();
 
     // Set and resolve the variants to use
-    mta_data->energy_key = "energy";
-    mta_data->energy_uq_key = "energy_uncertainty";
-    mta_data->nc_forces_key = "non_conservative_forces";
-    mta_data->nc_stress_key = "non_conservative_stress";
-
-    // Apply global variant (applies to all)
-    if (variant != nullptr) {
-        mta_data->energy_key += "/" + std::string(variant);
-        mta_data->energy_uq_key += "/" + std::string(variant);
-        mta_data->nc_forces_key += "/" + std::string(variant);
-        mta_data->nc_stress_key += "/" + std::string(variant);
-    }
-
-    // Apply variant/energy
-    if (variant_energy != nullptr) {
-        if (strcmp(variant_energy, "off") == 0) {
-            mta_data->energy_key = "energy";
-        } else {
-            mta_data->energy_key = "energy/" + std::string(variant_energy);
-        }
+    auto v_energy =
+        variant_energy ? normalize_variant(variant_energy) : normalize_variant(variant);
+
+    auto v_energy_uq =
+        variant_energy_uq ? normalize_variant(variant_energy_uq) : v_energy;
+
+    auto v_nc_forces =
+        variant_nc_forces ? normalize_variant(variant_nc_forces) : v_energy;
+
+    auto v_nc_stress =
+        variant_nc_stress ? normalize_variant(variant_nc_stress) : v_energy;
+
+
+    // Handle energy variant
+    try {
+        mta_data->energy_key = pick_output("energy", outputs, v_energy);
+    } catch (std::exception& e) {
+        error->one(FLERR, e.what());
     }
 
-    // Apply variant/energy_uncertainty
-    if (variant_energy_uq != nullptr) {
-        if (strcmp(variant_energy_uq, "off") == 0) {
-            mta_data->energy_uq_key = "energy_uncertainty";
-        } else {
-            mta_data->energy_uq_key = "energy_uncertainty/" + std::string(variant_energy_uq);
+    // Handle energy_uncertainty variant
+    if (do_uncertainty) {
+        try {
+            mta_data->energy_uq_key = pick_output("energy_uncertainty", outputs, v_energy_uq);
+        } catch (std::exception& e) {
+            error->one(FLERR, e.what());
         }
     }
 
     // Handle non-conservative variants
-    bool has_nc_forces = variant_nc_forces != nullptr;
-    bool has_nc_stress = variant_nc_stress != nullptr;
+    if (mta_data->non_conservative) {
+        // Error if *both* nc-force and nc-stress were provided by user AND one is Null
+        bool user_set_forces = (variant_nc_forces != nullptr);
+        bool user_set_stress = (variant_nc_stress != nullptr);
 
-    if (has_nc_forces && has_nc_stress) {
-        bool forces_none = strcmp(variant_nc_forces, "off") == 0;
-        bool stress_none = strcmp(variant_nc_stress, "off") == 0;
-        if (forces_none != stress_none) {
-            error->one(FLERR,
-                "if both 'variant/non_conservative_stress' and "
-                "'variant/non_conservative_forces' are set, they must either "
-                "both be 'off' or both not be 'off'");
-        }
-    } else if (has_nc_forces && !has_nc_stress) {
-        if (strcmp(variant_nc_forces, "off") != 0) {
-            error->one(FLERR,
-                "'variant/non_conservative_forces' is set but "
-                "'variant/non_conservative_stress' is not; "
-                "both must be set together or both be 'off'");
-        }
-    } else if (!has_nc_forces && has_nc_stress) {
-        if (strcmp(variant_nc_stress, "off") != 0) {
-            error->one(FLERR,
-                "'variant/non_conservative_stress' is set but "
-                "'variant/non_conservative_forces' is not; "
-                "both must be set together or both be 'off'");
-        }
-    }
+        if (user_set_forces && user_set_stress) {
 
-    if (has_nc_forces) {
-        if (strcmp(variant_nc_forces, "off") == 0) {
-            mta_data->nc_forces_key = "non_conservative_forces";
-        } else {
-            mta_data->nc_forces_key = "non_conservative_forces/" + std::string(variant_nc_forces);
+            bool forces_none = !normalize_variant(variant_nc_forces).has_value();
+            bool stress_none = !normalize_variant(variant_nc_stress).has_value();
+
+            if (forces_none != stress_none) {
+                error->one(FLERR,
+                    "if both 'variant/non_conservative_stress' and "
+                    "'variant/non_conservative_forces' are present, they "
+                    "must either both be 'off' or both not 'off'");
+            }
         }
-    }
 
-    if (has_nc_stress) {
-        if (strcmp(variant_nc_stress, "off") == 0) {
-            mta_data->nc_stress_key = "non_conservative_stress";
-        } else {
-            mta_data->nc_stress_key = "non_conservative_stress/" + std::string(variant_nc_stress);
+        try {
+            mta_data->nc_forces_key = pick_output("non_conservative_forces", outputs, v_nc_forces);
+            mta_data->nc_stress_key = pick_output("non_conservative_stress", outputs, v_nc_stress);
+        } catch (std::exception& e) {
+            error->one(FLERR, e.what());
         }
     }
 
     // Check that the model has the required outputs
-    const auto& outputs = mta_data->capabilities->outputs();
     auto energy_output = outputs.find(mta_data->energy_key);
     // LAMMPS assume that an energy will be available
     if (energy_output == outputs.end()) {
@@ -399,7 +389,7 @@ void PairMetatomic::settings(int argc, char ** argv) {
 void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
 
     torch::optional<std::string> requested_string;
-    std::string device_string;
+    torch::DeviceType device_type;
 
     if (requested != nullptr) {
         requested_string = std::string(requested);
@@ -408,7 +398,7 @@ void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
     }
 
     try {
-        device_string = metatomic_torch::pick_device(
+        device_type = metatomic_torch::pick_device(
             this->mta_data->capabilities->supported_devices,
             requested_string
         );
@@ -416,7 +406,7 @@ void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
         error->one(FLERR, "pair_style metatomic: {}", e.what());
     }
 
-    if (device_string == "cuda") {
+    if (device_type == torch::DeviceType::CUDA) {
         // distribute GPUs between multiple MPI processes on the same node
 
         // (1) get a MPI communicator for all processes on the current node
@@ -438,14 +428,13 @@ void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
         }
 
         // (3) split GPUs between node-local processes using round-robin allocation
-        int gpu_to_use = local_rank % torch::cuda::device_count();
-        device = torch::Device("cuda:" + std::to_string(gpu_to_use));
+        auto device_index = local_rank % torch::cuda::device_count();
+        device = torch::Device(device_type, static_cast<torch::DeviceIndex>(device_index));
     } else {
-        device = torch::Device(device_string);
+        device = torch::Device(device_type);
     }
 }
 
-
 void PairMetatomic::allocate() {
     allocated = 1;
 
@@ -488,7 +477,6 @@ double PairMetatomic::init_one(int, int) {
     return mta_data->max_cutoff;
 }
 
-
 // called on pair_coeff
 void PairMetatomic::coeff(int argc, char ** argv) {
     if (argc < 3 || strcmp(argv[0], "*") != 0 || strcmp(argv[1], "*") != 0) {
@@ -516,7 +504,6 @@ void PairMetatomic::coeff(int argc, char ** argv) {
     }
 }
 
-
 // called when the run starts
 void PairMetatomic::init_style() {
     // Require newton pair on since we need to communicate forces accumulated on
@@ -585,12 +572,10 @@ void PairMetatomic::init_style() {
     }
 }
 
-
 void PairMetatomic::init_list(int id, NeighList *ptr) {
     this->mta_list = ptr;
 }
 
-
 void PairMetatomic::compute(int eflag, int vflag) {
     if (std::getenv("LAMMPS_METATOMIC_PROFILE") != nullptr) {
         MetatomicTimer::enable(true);

From a030379a28a23fe87a63837bbf5e7b79ffbaad94 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <luthaf@luthaf.fr>
Date: Tue, 18 Nov 2025 14:37:56 +0100
Subject: [PATCH 28/37] Make sure the model has an energy_uncertainty output
 before trying to use it (#33)

---
 src/ML-METATOMIC/pair_metatomic.cpp | 36 ++++++++++++++++-------------
 1 file changed, 20 insertions(+), 16 deletions(-)

diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 658c0f2647a..e96caf9cdcd 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -236,18 +236,10 @@ void PairMetatomic::settings(int argc, char ** argv) {
     const auto& outputs = mta_data->capabilities->outputs();
 
     // Set and resolve the variants to use
-    auto v_energy =
-        variant_energy ? normalize_variant(variant_energy) : normalize_variant(variant);
-
-    auto v_energy_uq =
-        variant_energy_uq ? normalize_variant(variant_energy_uq) : v_energy;
-
-    auto v_nc_forces =
-        variant_nc_forces ? normalize_variant(variant_nc_forces) : v_energy;
-
-    auto v_nc_stress =
-        variant_nc_stress ? normalize_variant(variant_nc_stress) : v_energy;
-
+    auto v_energy = variant_energy ? normalize_variant(variant_energy) : normalize_variant(variant);
+    auto v_energy_uq = variant_energy_uq ? normalize_variant(variant_energy_uq) : v_energy;
+    auto v_nc_forces = variant_nc_forces ? normalize_variant(variant_nc_forces) : v_energy;
+    auto v_nc_stress = variant_nc_stress ? normalize_variant(variant_nc_stress) : v_energy;
 
     // Handle energy variant
     try {
@@ -258,10 +250,22 @@ void PairMetatomic::settings(int argc, char ** argv) {
 
     // Handle energy_uncertainty variant
     if (do_uncertainty) {
-        try {
-            mta_data->energy_uq_key = pick_output("energy_uncertainty", outputs, v_energy_uq);
-        } catch (std::exception& e) {
-            error->one(FLERR, e.what());
+        // the user did not disable energy uncertainty, let's check if the model
+        // supports it
+        bool has_uncertainty = false;
+        for (const auto& output: outputs) {
+            if (output.key().find("energy_uncertainty") == 0) {
+                has_uncertainty = true;
+                break;
+            }
+        }
+
+        if (has_uncertainty) {
+            try {
+                mta_data->energy_uq_key = pick_output("energy_uncertainty", outputs, v_energy_uq);
+            } catch (std::exception& e) {
+                error->one(FLERR, e.what());
+            }
         }
     }
 

From 480fcf8f3488ced6568703ba0c9a9d572b04175a Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Wed, 19 Nov 2025 09:13:25 +0100
Subject: [PATCH 29/37] Remove the option for `remap_pairs off`

It is slower and nobody was using it
---
 src/KOKKOS/metatomic_system_kokkos.cpp |  15 +--
 src/KOKKOS/metatomic_system_kokkos.h   |   3 +-
 src/ML-METATOMIC/metatomic_system.cpp  | 141 +------------------------
 src/ML-METATOMIC/metatomic_system.h    |  10 +-
 src/ML-METATOMIC/metatomic_types.cpp   |   1 -
 src/ML-METATOMIC/metatomic_types.h     |   3 -
 src/ML-METATOMIC/pair_metatomic.cpp    |  13 ---
 7 files changed, 10 insertions(+), 176 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index d5768f7bfbb..3164307bc34 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -50,8 +50,8 @@ MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *l
 #include "comm.h"
 
 template<class DeviceType>
-void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_remap_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list) {
-    auto _ = MetatomicTimer("converting kokkos neighbors with ghosts remapping");
+void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list) {
+    auto _ = MetatomicTimer("converting kokkos neighbors list");
     auto dtype = system->positions().scalar_type();
 
     auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
@@ -308,7 +308,6 @@ template<class DeviceType>
 metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lmp(
     NeighList* list,
     bool do_virial,
-    bool remap_pairs,
     torch::ScalarType dtype,
     torch::Device device
 ) {
@@ -376,13 +375,9 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
         pbc
     );
 
-    if (remap_pairs) {
-        auto* kk_list = dynamic_cast<NeighListKokkos<DeviceType>*>(list);
-        assert(kk_list != nullptr);
-        this->setup_neighbors_remap_kk(system, kk_list);
-    } else {
-        error->one(FLERR, "the kokkos version of metatomic requires remap_pairs to be true");
-    }
+    auto* kk_list = dynamic_cast<NeighListKokkos<DeviceType>*>(list);
+    assert(kk_list != nullptr);
+    this->setup_neighbors_kk(system, kk_list);
 
     return system;
 }
diff --git a/src/KOKKOS/metatomic_system_kokkos.h b/src/KOKKOS/metatomic_system_kokkos.h
index 3c64f1f4299..595c4a3263c 100644
--- a/src/KOKKOS/metatomic_system_kokkos.h
+++ b/src/KOKKOS/metatomic_system_kokkos.h
@@ -82,12 +82,11 @@ class MetatomicSystemAdaptorKokkos : public MetatomicSystemAdaptor {
     metatomic_torch::System system_from_lmp(
         NeighList* list,
         bool do_virial,
-        bool remap_pairs,
         torch::ScalarType dtype,
         torch::Device device
     ) override;
 
-    void setup_neighbors_remap_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list);
+    void setup_neighbors_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list);
 
 private:
     /// Torch device corresponding to the kokkos `DeviceType`
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 3ad6d546d98..65ab6a3a49e 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -93,8 +93,8 @@ static std::array<int32_t, 3> cell_shifts(
 }
 
 
-void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& system, NeighList *list) {
-    auto _ = MetatomicTimer("converting neighbors with ghosts remapping");
+void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, NeighList *list) {
+    auto _ = MetatomicTimer("converting neighbors list");
     auto dtype = system->positions().scalar_type();
     auto device = system->positions().device();
 
@@ -344,140 +344,9 @@ void MetatomicSystemAdaptor::setup_neighbors_remap(metatomic_torch::System& syst
     }
 }
 
-void MetatomicSystemAdaptor::setup_neighbors_no_remap(metatomic_torch::System& system, NeighList *list) {
-    auto _ = MetatomicTimer("converting neighbors without ghosts remapping");
-
-    auto dtype = system->positions().scalar_type();
-    auto device = system->positions().device();
-
-    double** x = atom->x;
-
-    for (auto& cache: caches_) {
-        {
-            auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
-
-            auto cutoff2 = cache.cutoff * cache.cutoff;
-            auto full_list = cache.options->full_list();
-
-            // convert from LAMMPS neighbors list to metatomic format
-            cache.known_samples.clear();
-            cache.samples.clear();
-            cache.distances_f32.clear();
-            cache.distances_f64.clear();
-            for (int ii=0; ii<(list->inum + list->gnum); ii++) {
-                auto atom_i = list->ilist[ii];
-
-                auto neighbors = list->firstneigh[ii];
-                for (int jj=0; jj<list->numneigh[ii]; jj++) {
-                    auto atom_j = neighbors[jj];
-
-                    if (!full_list && atom_i > atom_j) {
-                        // Remove extra pairs if the model requested half-lists
-                        continue;
-                    }
-
-                    auto distance = std::array<double, 3>{
-                        x[atom_j][0] - x[atom_i][0],
-                        x[atom_j][1] - x[atom_i][1],
-                        x[atom_j][2] - x[atom_i][2],
-                    };
-
-                    auto distance2 = (
-                        distance[0] * distance[0] +
-                        distance[1] * distance[1] +
-                        distance[2] * distance[2]
-                    );
-                    if (distance2 > cutoff2) {
-                        // LAMMPS neighbors list contains some pairs after the
-                        // cutoff, we filter them here
-                        continue;
-                    }
-
-                    auto sample = std::array<int32_t, 5>{atom_i, atom_j, 0, 0, 0};
-
-
-                    cache.samples.push_back(sample);
-
-                    if (dtype == torch::kFloat64) {
-                        cache.distances_f64.push_back(distance);
-                    } else if (dtype == torch::kFloat32) {
-                        cache.distances_f32.push_back({
-                            static_cast<float>(distance[0]),
-                            static_cast<float>(distance[1]),
-                            static_cast<float>(distance[2])
-                        });
-                    } else {
-                        // should be unreachable
-                        error->one(FLERR, "invalid dtype, this is a bug");
-                    }
-                }
-            }
-        }
-
-        int64_t n_pairs = cache.samples.size();
-        auto samples_values = torch::from_blob(
-            reinterpret_cast<int32_t*>(cache.samples.data()),
-            {n_pairs, 5},
-            torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-        );
-
-        torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
-        {
-            auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) +" pairs)");
-            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-                samples_values,
-                metatensor::assume_unique{}
-            );
-        }
-
-        auto distances_vectors = torch::Tensor();
-        if (dtype == torch::kFloat64) {
-            distances_vectors = torch::from_blob(
-                cache.distances_f64.data(),
-                {n_pairs, 3, 1},
-                torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
-            );
-        } else if (dtype == torch::kFloat32) {
-            distances_vectors = torch::from_blob(
-                cache.distances_f32.data(),
-                {n_pairs, 3, 1},
-                torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
-            );
-        } else {
-            // should be unreachable
-            error->one(FLERR, "invalid dtype, this is a bug");
-        }
-
-        {
-            auto _ = MetatomicTimer("moving neighbor data to dtype/device");
-            distances_vectors = distances_vectors.to(dtype).to(device);
-            samples = samples->to(device);
-        }
-
-        torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
-        {
-            auto _ = MetatomicTimer("creating neighbors TensorBlock");
-            neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
-                distances_vectors,
-                samples,
-                std::vector<metatensor_torch::Labels>{
-                    metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(device),
-                },
-                metatensor_torch::LabelsHolder::create({"distance"}, {{0}})->to(device)
-            );
-        }
-
-        metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-        system->add_neighbor_list(cache.options, neighbors);
-    }
-}
-
-
 metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     NeighList* list,
     bool do_virial,
-    bool remap_pairs,
     torch::ScalarType dtype,
     torch::Device device
 ) {
@@ -552,11 +421,7 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
         pbc
     );
 
-    if (remap_pairs) {
-        this->setup_neighbors_remap(system, list);
-    } else {
-        this->setup_neighbors_no_remap(system, list);
-    }
+    this->setup_neighbors(system, list);
 
     return system;
 }
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index 15c58a8bf8f..37854e83966 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -90,7 +90,6 @@ class MetatomicSystemAdaptor : public Pointers {
     virtual metatomic_torch::System system_from_lmp(
         NeighList* list,
         bool do_virial,
-        bool remap_pairs,
         torch::ScalarType dtype,
         torch::Device device
     );
@@ -104,14 +103,7 @@ class MetatomicSystemAdaptor : public Pointers {
 
  protected:
     // setup the metatomic neighbors list from the internal LAMMPS one,
-    // remapping periodic ghosts to the corresponding local atom
-    void setup_neighbors_remap(metatomic_torch::System& system, NeighList* list);
-
-    // setup the metatomic neighbors list from the internal LAMMPS one,
-    // WITHOUT remapping periodic ghosts to the corresponding local atom.
-    //
-    // This produces a larger NL but skips the cost of the remapping
-    void setup_neighbors_no_remap(metatomic_torch::System& system, NeighList* list);
+    void setup_neighbors(metatomic_torch::System& system, NeighList* list);
 
     // options for this system adaptor
     MetatomicSystemOptions options_;
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 7e95dcfb797..2867e0e3fea 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -25,7 +25,6 @@ using namespace LAMMPS_NS;
 PairMetatomicData::PairMetatomicData(std::string length_unit):
     device(torch::kCPU),
     check_consistency(false),
-    remap_pairs(true),
     non_conservative(false),
     max_cutoff(-1)
 {
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index 3eea1e3ea77..ce1ee64ef8a 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -60,9 +60,6 @@ struct PairMetatomicData {
    // should metatomic check the data LAMMPS send to the model
    // and the data the model returns?
    bool check_consistency;
-   // whether pairs should be remapped, removing pairs between ghosts if there
-   // is an equivalent pair involving at least one local atom.
-   bool remap_pairs;
    // whether non-conservative forces and stresses should be used
    bool non_conservative;
    // how far away the model needs to know about neighbors
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index e96caf9cdcd..d69b2686807 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -140,18 +140,6 @@ void PairMetatomic::settings(int argc, char ** argv) {
                 error->one(FLERR, "expected <on/off> after 'check_consistency' in pair_style metatomic, got '{}'", argv[i + 1]);
             }
 
-            i += 1;
-        } else if (strcmp(argv[i], "remap_pairs") == 0) {
-            if (i == argc - 1) {
-                error->one(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got nothing");
-            } else if (strcmp(argv[i + 1], "on") == 0) {
-                mta_data->remap_pairs = true;
-            } else if (strcmp(argv[i + 1], "off") == 0) {
-                mta_data->remap_pairs = false;
-            } else {
-                error->one(FLERR, "expected <on/off> after 'remap_pairs' in pair_style metatomic, got '{}'", argv[i + 1]);
-            }
-
             i += 1;
         } else if (strcmp(argv[i], "non_conservative") == 0) {
             if (i == argc - 1) {
@@ -643,7 +631,6 @@ void PairMetatomic::compute(int eflag, int vflag) {
     auto system = this->system_adaptor->system_from_lmp(
         mta_list,
         static_cast<bool>(vflag_global),
-        mta_data->remap_pairs,
         dtype,
         mta_data->device
     );

From 90b6debb7a83d8d8f1ba97b8aa74f070e833a232 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Wed, 19 Nov 2025 14:35:13 +0100
Subject: [PATCH 30/37] Enable mixed periodic boundary conditions

---
 examples/PACKAGES/metatomic/in.metatomic |   2 +-
 examples/PACKAGES/metatomic/nickel-lj.pt | Bin 69835 -> 70667 bytes
 src/KOKKOS/metatomic_system_kokkos.cpp   |  99 ++++++++++----
 src/ML-METATOMIC/metatomic_system.cpp    | 165 ++++++++++++++++++-----
 4 files changed, 207 insertions(+), 59 deletions(-)

diff --git a/examples/PACKAGES/metatomic/in.metatomic b/examples/PACKAGES/metatomic/in.metatomic
index dddb94422cf..8dc629822e9 100644
--- a/examples/PACKAGES/metatomic/in.metatomic
+++ b/examples/PACKAGES/metatomic/in.metatomic
@@ -12,7 +12,7 @@ mass Ni 58.693
 
 velocity all create 123 42
 
-pair_style metatomic nickel-lj.pt
+pair_style metatomic nickel-lj.pt uncertainty_threshold off
 # pair_style metatomic nickel-lj-extensions.pt extensions collected-extensions/
 pair_coeff * * 28
diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 3164307bc34..7482fa481ce 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -16,18 +16,74 @@
                          Filippo Bigi <filippo.bigi@epfl.ch>
 ------------------------------------------------------------------------- */
 #include "metatomic_system_kokkos.h"
-
 #include "metatomic_timer.h"
 
 #include "domain.h"
-#include "error.h"
-
+#include "comm.h"
 #include "atom_kokkos.h"
 
 #include <torch/cuda.h>
 
 using namespace LAMMPS_NS;
 
+/// Compute the inverse of the cell matrix of the system, accounting for
+/// non-periodic directions by setting the corresponding rows to an unit vector
+/// orthogonal to the periodic directions. This is used to compute the cell
+/// shifts of neighbor pairs.
+static torch::Tensor cell_inverse(const metatomic_torch::System& system) {
+    auto cell = system->cell().clone();
+    auto periodic = system->pbc();
+
+    // find number of periodic directions and their indices
+    int n_periodic = 0;
+    int periodic_idx_1 = -1;
+    int periodic_idx_2 = -1;
+    for (int i = 0; i < 3; ++i) {
+        if (periodic[i].item<bool>()) {
+            n_periodic += 1;
+            if (periodic_idx_1 == -1) {
+                periodic_idx_1 = i;
+            } else if (periodic_idx_2 == -1) {
+                periodic_idx_2 = i;
+            }
+        }
+    }
+
+    // adjust the box matrix to have a simple orthogonal dimension along
+    // non-periodic directions
+    if (n_periodic == 0) {
+        return torch::eye(3, cell.options());
+    } else if (n_periodic == 1) {
+        assert(periodic_idx_1 != -1);
+        // Make the two non-periodic directions orthogonal to the periodic one
+        auto a = cell[periodic_idx_1];
+        auto b = torch::tensor({0, 1, 0}, cell.options());
+        if (torch::abs(torch::dot(a / a.norm(), b)).item<double>() > 0.9) {
+            b = torch::tensor({0, 0, 1}, cell.options());
+        }
+        auto c = torch::cross(a, b);
+        c /= c.norm();
+        b = torch::cross(c, a);
+        b /= b.norm();
+
+        // Assign back to the cell picking the "non-periodic" indices without ifs
+        cell[(periodic_idx_1 + 1) % 3] = b;
+        cell[(periodic_idx_1 + 2) % 3] = c;
+    } else if (n_periodic == 2) {
+        assert(periodic_idx_1 != -1 && periodic_idx_2 != -1);
+        // Make the one non-periodic direction orthogonal to the two periodic ones
+        auto a = cell[periodic_idx_1];
+        auto b = cell[periodic_idx_2];
+        auto c = torch::cross(a, b);
+        c /= c.norm();
+
+        // Assign back to the matrix picking the "non-periodic" index without ifs
+        cell[(3 - periodic_idx_1 - periodic_idx_2)] = c;
+    }
+
+    return cell.inverse();
+}
+
 template<typename T, class DeviceType>
 using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
 
@@ -47,8 +103,6 @@ MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *l
     this->strain = torch::eye(3, tensor_options);
 }
 
-#include "comm.h"
-
 template<class DeviceType>
 void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list) {
     auto _ = MetatomicTimer("converting kokkos neighbors list");
@@ -144,7 +198,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
     );
 
     auto x = system->positions().detach();
-    auto cell_inverse = system->cell().detach().inverse();
+    auto cell_inv = cell_inverse(system);
 
     // convert from LAMMPS NL format to metatomic NL format
     auto expanded_arange = torch::arange(
@@ -213,13 +267,11 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
             auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
 
             // find filtered interatomic vectors using the original atoms
-            auto original_distances_filtered =
-                x.index_select(0, neighbors_original_id_filt)
-                - x.index_select(0, centers_original_id_filt);
+            auto original_distances_filtered = x.index_select(0, neighbors_original_id_filt) - x.index_select(0, centers_original_id_filt);
 
             // cell shifts
             auto pair_shifts = distances_filt - original_distances_filtered;
-            auto cell_shifts = pair_shifts.matmul(cell_inverse);
+            auto cell_shifts = pair_shifts.matmul(cell_inv);
             cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
 
             if (full_list) {
@@ -347,27 +399,26 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     auto system_positions = this->positions.to(dtype);
     cell = cell.to(dtype);
 
+    // Periodic boundary conditions handling.
+    auto pbc = torch::tensor(
+        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
+        torch::TensorOptions().dtype(torch::kBool).device(this->device_)
+    );
+
+    cell.index_put_(
+        {torch::logical_not(pbc)},
+        torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(this->device_))
+    );
+
     if (do_virial) {
         auto model_strain = this->strain.to(dtype);
 
-        // pretend to scale positions/cell by the strain so that
-        // it enters the computational graph.
+        // scale positions/cell by the strain so that it enters the
+        // computational graph.
         system_positions = system_positions.matmul(model_strain);
         cell = cell.matmul(model_strain);
     }
 
-    // Periodic boundary conditions handling.
-    //
-    // While Metatomic models can support mixed PBC settings, we currently
-    // assume that the system is fully periodic and we throw an error otherwise
-    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-        error->one(FLERR, "metatomic/kk currently requires a fully periodic system");
-    }
-    auto pbc = torch::tensor(
-        {domain->xperiodic, domain->yperiodic, domain->zperiodic},
-        torch::TensorOptions().dtype(torch::kBool).device(this->device_)
-    );
-
     auto system = torch::make_intrusive<metatomic_torch::SystemHolder>(
         atomic_types_,
         system_positions,
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 65ab6a3a49e..8beba20288a 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -27,6 +27,122 @@
 
 using namespace LAMMPS_NS;
 
+using vector_t = std::array<double, 3>;
+using matrix_t = std::array<std::array<double, 3>, 3>;
+
+static vector_t cross(vector_t a, vector_t b) {
+    return {
+        a[1] * b[2] - a[2] * b[1],
+        a[2] * b[0] - a[0] * b[2],
+        a[0] * b[1] - a[1] * b[0],
+    };
+}
+
+static double dot(vector_t a, vector_t b) {
+    return a[0] * b[0] + a[1] * b[1] + a[2] * b[2];
+}
+
+static vector_t normalize(vector_t a) {
+    double norm = std::sqrt(a[0]*a[0] + a[1]*a[1] + a[2]*a[2]);
+    return {a[0] / norm, a[1] / norm, a[2] / norm};
+}
+
+static double determinant(matrix_t a) {
+    return a[0][0] * (a[1][1] * a[2][2] - a[2][1] * a[1][2])
+         - a[0][1] * (a[1][0] * a[2][2] - a[1][2] * a[2][0])
+         + a[0][2] * (a[1][0] * a[2][1] - a[1][1] * a[2][0]);
+}
+
+matrix_t inverse(matrix_t a) {
+    auto det = determinant(a);
+
+    if (std::abs(det) < 1e-10) {
+        throw std::runtime_error("this matrix is not invertible");
+    }
+
+    auto inverse = matrix_t();
+    inverse[0][0] = (a[1][1] * a[2][2] - a[2][1] * a[1][2]) / det;
+    inverse[0][1] = (a[0][2] * a[2][1] - a[0][1] * a[2][2]) / det;
+    inverse[0][2] = (a[0][1] * a[1][2] - a[0][2] * a[1][1]) / det;
+    inverse[1][0] = (a[1][2] * a[2][0] - a[1][0] * a[2][2]) / det;
+    inverse[1][1] = (a[0][0] * a[2][2] - a[0][2] * a[2][0]) / det;
+    inverse[1][2] = (a[1][0] * a[0][2] - a[0][0] * a[1][2]) / det;
+    inverse[2][0] = (a[1][0] * a[2][1] - a[2][0] * a[1][1]) / det;
+    inverse[2][1] = (a[2][0] * a[0][1] - a[0][0] * a[2][1]) / det;
+    inverse[2][2] = (a[0][0] * a[1][1] - a[1][0] * a[0][1]) / det;
+    return inverse;
+}
+
+/// Compute the inverse of the cell matrix of the system, accounting for
+/// non-periodic directions by setting the corresponding rows to an unit vector
+/// orthogonal to the periodic directions. This is used to compute the cell
+/// shifts of neighbor pairs.
+static std::array<std::array<double, 3>, 3> cell_inverse(Domain* domain) {
+    auto periodic = std::array<bool, 3>{
+        static_cast<bool>(domain->xperiodic),
+        static_cast<bool>(domain->yperiodic),
+        static_cast<bool>(domain->zperiodic),
+    };
+
+    auto cell = std::array<std::array<double, 3>, 3>{{0}};
+    cell[0][0] = domain->xprd;
+    cell[1][0] = domain->xy;
+    cell[1][1] = domain->yprd;
+    cell[2][0] = domain->xz;
+    cell[2][1] = domain->yz;
+    cell[2][2] = domain->zprd;
+
+    // find number of periodic directions and their indices
+    int n_periodic = 0;
+    int periodic_idx_1 = -1;
+    int periodic_idx_2 = -1;
+    for (int i = 0; i < 3; ++i) {
+        if (periodic[i]) {
+            n_periodic += 1;
+            if (periodic_idx_1 == -1) {
+                periodic_idx_1 = i;
+            } else if (periodic_idx_2 == -1) {
+                periodic_idx_2 = i;
+            }
+        }
+    }
+
+    // adjust the box matrix to have a simple orthogonal dimension along
+    // non-periodic directions
+    if (n_periodic == 0) {
+        return {
+            std::array<double, 3>{1, 0, 0},
+            std::array<double, 3>{0, 1, 0},
+            std::array<double, 3>{0, 0, 1},
+        };
+    } else if (n_periodic == 1) {
+        assert(periodic_idx_1 != -1);
+        // Make the two non-periodic directions orthogonal to the periodic one
+        auto a = cell[periodic_idx_1];
+        auto b = std::array<double, 3>{0, 1, 0};
+        if (std::abs(dot(normalize(a), b)) > 0.9) {
+            b = std::array<double, 3>{0, 0, 1};
+        }
+        auto c = normalize(cross(a, b));
+        b = normalize(cross(c, a));
+
+        // Assign back to the cell picking the "non-periodic" indices without ifs
+        cell[(periodic_idx_1 + 1) % 3] = b;
+        cell[(periodic_idx_1 + 2) % 3] = c;
+    } else if (n_periodic == 2) {
+        assert(periodic_idx_1 != -1 && periodic_idx_2 != -1);
+        // Make the one non-periodic direction orthogonal to the two periodic ones
+        auto a = cell[periodic_idx_1];
+        auto b = cell[periodic_idx_2];
+        auto c = normalize(cross(a, b));
+
+        // Assign back to the matrix picking the "non-periodic" index without ifs
+        cell[(3 - periodic_idx_1 - periodic_idx_2)] = c;
+    }
+
+    return inverse(cell);
+}
+
 MetatomicSystemAdaptor::MetatomicSystemAdaptor(LAMMPS *lmp, MetatomicSystemOptions options):
     Pointers(lmp),
     options_(std::move(options)),
@@ -100,14 +216,7 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
 
     double** x = atom->x;
     auto total_n_atoms = atom->nlocal + atom->nghost;
-
-    auto cell_inv_tensor = system->cell().inverse().t().to(torch::kCPU).to(torch::kFloat64);
-    auto cell_inv_accessor = cell_inv_tensor.accessor<double, 2>();
-    auto cell_inv = std::array<std::array<double, 3>, 3>{{
-        {{cell_inv_accessor[0][0], cell_inv_accessor[0][1], cell_inv_accessor[0][2]}},
-        {{cell_inv_accessor[1][0], cell_inv_accessor[1][1], cell_inv_accessor[1][2]}},
-        {{cell_inv_accessor[2][0], cell_inv_accessor[2][1], cell_inv_accessor[2][2]}},
-    }};
+    auto cell_inv = cell_inverse(domain);
 
     {
         auto _ = MetatomicTimer("identifying ghosts and real atoms");
@@ -368,6 +477,7 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
         // requires_grad=true since we always need gradients w.r.t. positions
         tensor_options.requires_grad(options_.requires_grad)
     );
+    auto system_positions = this->positions.to(dtype).to(device);
 
     auto cell = torch::zeros({3, 3}, tensor_options);
     cell[0][0] = domain->xprd;
@@ -379,40 +489,27 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     cell[2][1] = domain->yz;
     cell[2][2] = domain->zprd;
 
-    auto system_positions = this->positions.to(dtype).to(device);
     cell = cell.to(dtype).to(device);
 
-    if (do_virial) {
-        auto model_strain = this->strain.to(dtype).to(device);
-
-        // pretend to scale positions/cell by the strain so that
-        // it enters the computational graph.
-        system_positions = system_positions.matmul(model_strain);
-        cell = cell.matmul(model_strain);
-    }
-
     // Periodic boundary conditions handling.
-    // While metatomic models can support mixed PBC settings, we currently
-    // assume that the system is fully periodic and we throw an error otherwise
-    if (!domain->xperiodic || !domain->yperiodic || !domain->zperiodic) {
-        error->one(FLERR, "pair_style metatomic requires a fully periodic system");
-    }
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
         torch::TensorOptions().dtype(torch::kBool).device(device)
     );
 
-    // Note that something like this:
-    //     cell.index_put_(
-    //         {torch::logical_not(pbc)},
-    //         torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(device))
-    //     );
-    //
-    // would allow creating System with non-periodic directions, but we're using
-    // the inverse of the cell matrix to filter the neighbor list, and the cell
-    // matrix becomes singular if any of its rows are zero. This requires some
-    // changes in the neighbor list filtering code to handle non-periodic
-    // directions.
+    cell.index_put_(
+        {torch::logical_not(pbc)},
+        torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(device))
+    );
+
+    if (do_virial) {
+        auto model_strain = this->strain.to(dtype).to(device);
+
+        // scale positions/cell by the strain so that it enters the
+        // computational graph.
+        system_positions = system_positions.matmul(model_strain);
+        cell = cell.matmul(model_strain);
+    }
 
     auto system = torch::make_intrusive<metatomic_torch::SystemHolder>(
         atomic_types_.to(device),

From 78056b4d748ec3d57b410f4ef87afe167432bff4 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 28 Nov 2025 13:20:11 +0100
Subject: [PATCH 31/37] Remove periodic images from the system we pass to
 metatomic

Many ML models are very slow when running on all atoms in the system,
and because we remap the pairs, periodic images end up as isolated atoms
for which we throw away the prediction.

Doing some more processing on the LAMMPS side only adds minimal overhead
while removing many potential atomic centers and making the ML models
a lot faster.
---
 examples/PACKAGES/metatomic/in.metatomic |   3 +-
 src/KOKKOS/metatomic_system_kokkos.cpp   |  90 +++++----------
 src/KOKKOS/pair_metatomic_kokkos.cpp     |  50 ++++++--
 src/ML-METATOMIC/metatomic_system.cpp    | 140 +++++++++++++----------
 src/ML-METATOMIC/metatomic_system.h      |  27 +++--
 src/ML-METATOMIC/pair_metatomic.cpp      |  23 ++--
 6 files changed, 181 insertions(+), 152 deletions(-)

diff --git a/examples/PACKAGES/metatomic/in.metatomic b/examples/PACKAGES/metatomic/in.metatomic
index 8dc629822e9..d2afd161e51 100644
--- a/examples/PACKAGES/metatomic/in.metatomic
+++ b/examples/PACKAGES/metatomic/in.metatomic
@@ -7,8 +7,7 @@ region box block 0 2 0 2 0 2
 create_box 1 box
 create_atoms 1 box
 
-labelmap atom 1 Ni
-mass Ni 58.693
+mass 1 58.693
 
 velocity all create 123 42
 
diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 7482fa481ce..3abe5070471 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -110,61 +110,18 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
 
     auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
 
-    {
-        auto _ = MetatomicTimer("identifying ghosts and real atoms");
-        /*-------------- this will be done on CPU for now ------------------------*/
-        // The hashmap in the following code is not easy to implement in either Kokkos or torch
-        // The cost of this section seems to be very low anyway
-
-        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
-        // atoms which are periodic images of local atoms back to the local atoms.
-        //
-        // Metatomic expects pairs corresponding to periodic atoms to be between
-        // the main atoms, but using the actual distance vector between the atom and
-        // the ghost.
-        original_atom_id_.clear();
-        original_atom_id_.reserve(total_n_atoms);
-
-        // identify all local atom by their LAMMPS atom tag.
-        local_atoms_tags_.clear();
-        for (int i=0; i<atom->nlocal; i++) {
-            original_atom_id_.emplace_back(i);
-            local_atoms_tags_.emplace(atom->tag[i], i);
-        }
-
-        // now loop over ghosts & map them back to the main cell if needed
-        ghost_atoms_tags_.clear();
-        for (int i=atom->nlocal; i<total_n_atoms; i++) {
-            auto tag = atom->tag[i];
-            auto it = local_atoms_tags_.find(tag);
-            if (it != local_atoms_tags_.end()) {
-                // this is the periodic image of an atom already owned by this domain
-                original_atom_id_.emplace_back(it->second);
-            } else {
-                // this can either be a periodic image of an atom owned by another
-                // domain, or directly an atom from another domain. Since we can not
-                // really distinguish between these, we take the first atom as the
-                // "main" one and remap all atoms with the same tag to the first one
-                auto it = ghost_atoms_tags_.find(tag);
-                if (it != ghost_atoms_tags_.end()) {
-                    // we already found this atom elsewhere in the system
-                    original_atom_id_.emplace_back(it->second);
-                } else {
-                    // this is the first time we are seeing this atom
-                    original_atom_id_.emplace_back(i);
-                    ghost_atoms_tags_.emplace(tag, i);
-                }
-            }
-        }
-    }
-    /*----------- end of "this will be done on CPU for now" --------------*/
-
     auto original_id = torch::from_blob(
         original_atom_id_.data(),
         {total_n_atoms},
         torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
     ).to(this->device_);
 
+    auto lmp_to_mta = torch::from_blob(
+        lmp_to_mta_.data(),
+        {total_n_atoms},
+        torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
+    ).to(this->device_);
+
     auto neighbors_kk = list->d_neighbors;
     auto max_number_of_neighbors = list->maxneighs;
 
@@ -197,7 +154,9 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
         torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
     );
 
-    auto x = system->positions().detach();
+    auto k_x = atomKK->k_x.view<DeviceType>();
+    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
+    auto x = torch::from_blob(k_x.data(), {total_n_atoms, 3}, tensor_options);
     auto cell_inv = cell_inverse(system);
 
     // convert from LAMMPS NL format to metatomic NL format
@@ -306,8 +265,8 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
 
             // make sure all the sample are unique
             samples_values = torch::concatenate({
-                centers_original_id_filt_cur.unsqueeze(-1),
-                neighbors_original_id_filt_cur.unsqueeze(-1),
+                lmp_to_mta.index_select(0, centers_original_id_filt_cur).unsqueeze(-1),
+                lmp_to_mta.index_select(0, neighbors_original_id_filt_cur).unsqueeze(-1),
                 cell_shifts_cur
             }, /*dim=*/1);
 
@@ -380,11 +339,7 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     auto k_x = atomKK->k_x.view<DeviceType>();
     auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
 
-    this->positions = torch::from_blob(
-        k_x.data(), {total_n_atoms, 3},
-        // requires_grad=true since we always need gradients w.r.t. positions
-        tensor_options.requires_grad(options_.requires_grad)
-    );
+    this->positions = torch::from_blob(k_x.data(), {total_n_atoms, 3}, tensor_options);
 
     auto cell = torch::zeros({3, 3}, tensor_options);
     cell[0][0] = domain->xprd;
@@ -396,9 +351,6 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     cell[2][1] = domain->yz;
     cell[2][2] = domain->zprd;
 
-    auto system_positions = this->positions.to(dtype);
-    cell = cell.to(dtype);
-
     // Periodic boundary conditions handling.
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
@@ -407,9 +359,25 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
 
     cell.index_put_(
         {torch::logical_not(pbc)},
-        torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(this->device_))
+        torch::tensor({0.0}, tensor_options)
     );
 
+    this->guess_periodic_ghosts();
+
+    // Only keep the atoms which are not periodic images of other atoms
+    auto mta_to_lmp_tensor = torch::from_blob(
+        mta_to_lmp.data(),
+        {static_cast<int64_t>(mta_to_lmp.size())},
+        torch::TensorOptions().dtype(torch::kInt).device(torch::kCPU)
+    ).to(this->device_);
+    this->atomic_types_ = this->atomic_types_.index_select(0, mta_to_lmp_tensor);
+    this->positions = this->positions.index_select(0, mta_to_lmp_tensor);
+
+    this->positions.set_requires_grad(options_.requires_grad);
+
+    auto system_positions = this->positions.to(dtype).to(device);
+    cell = cell.to(dtype);
+
     if (do_virial) {
         auto model_strain = this->strain.to(dtype);
 
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index 6857056bd48..abcab878278 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -122,27 +122,53 @@ void PairMetatomicKokkos<DeviceType>::store_forces(const at::Tensor& forces_tens
     auto forces = forces_tensor.contiguous();
 
     auto forces_lammps_kk = this->atomKK->k_f.template view<DeviceType>();
-    auto forces_metatensor_kk = UnmanagedView<double**, DeviceType>(
+    auto forces_mta_kk = UnmanagedView<double**, DeviceType>(
         forces.template data_ptr<double>(),
         forces.size(0), 3
     );
 
-    int num_forces_to_update;
-    if (mta_data->non_conservative) {
-        num_forces_to_update = atomKK->nlocal;
-    } else {
-        num_forces_to_update = atomKK->nlocal + atomKK->nghost;
-    }
-
     double scale = this->scale;  // the GPU can't access the `this` pointer
     Kokkos::parallel_for(
-        num_forces_to_update,
+        atomKK->nlocal,
         KOKKOS_LAMBDA(size_t i) {
-            forces_lammps_kk(i, 0) += scale * forces_metatensor_kk(i, 0);
-            forces_lammps_kk(i, 1) += scale * forces_metatensor_kk(i, 1);
-            forces_lammps_kk(i, 2) += scale * forces_metatensor_kk(i, 2);
+            forces_lammps_kk(i, 0) += scale * forces_mta_kk(i, 0);
+            forces_lammps_kk(i, 1) += scale * forces_mta_kk(i, 1);
+            forces_lammps_kk(i, 2) += scale * forces_mta_kk(i, 2);
         }
     );
+
+    // in non-conservative mode we do not need to update forces on ghost atoms
+    if (!mta_data->non_conservative) {
+        using HostUnmanaged = UnmanagedView<int*, LMPHostType>;
+        using DeviceUnmanaged = UnmanagedView<int*, DeviceType>;
+        using DeviceView = Kokkos::View<int*, Kokkos::LayoutRight, DeviceType>;
+
+
+        auto& mta_to_lmp = this->system_adaptor->mta_to_lmp;
+        DeviceUnmanaged mta_to_lmp_kk;
+        DeviceView mta_to_lmp_device;
+        if constexpr (std::is_same_v<typename HostUnmanaged::memory_space, typename DeviceUnmanaged::memory_space>) {
+            mta_to_lmp_kk = DeviceUnmanaged(mta_to_lmp.data(), mta_to_lmp.size());
+        } else {
+            // make a copy of mta_to_lmp on device
+            mta_to_lmp_device = DeviceView("mta_to_lmp_kk", mta_to_lmp.size());
+            Kokkos::deep_copy(
+                mta_to_lmp_device,
+                HostUnmanaged(mta_to_lmp.data(), mta_to_lmp.size())
+            );
+            mta_to_lmp_kk = DeviceUnmanaged(mta_to_lmp_device.data(), mta_to_lmp.size());
+        }
+
+        Kokkos::parallel_for(
+            Kokkos::RangePolicy(atomKK->nlocal, forces.size(0)),
+            KOKKOS_LAMBDA(size_t i) {
+                auto lmp_index = mta_to_lmp_kk[i];
+                forces_lammps_kk(lmp_index, 0) += scale * forces_mta_kk(i, 0);
+                forces_lammps_kk(lmp_index, 1) += scale * forces_mta_kk(i, 1);
+                forces_lammps_kk(lmp_index, 2) += scale * forces_mta_kk(i, 2);
+            }
+        );
+    }
 }
 
 
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 8beba20288a..8aac3fb5a3b 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -208,6 +208,65 @@ static std::array<int32_t, 3> cell_shifts(
     return {shift_a, shift_b, shift_c};
 }
 
+void MetatomicSystemAdaptor::guess_periodic_ghosts() {
+    auto _ = MetatomicTimer("identifying periodic ghosts");
+    auto total_n_atoms = atom->nlocal + atom->nghost;
+
+    // Collect the local atom id of all local & ghosts atoms, mapping ghosts
+    // atoms which are periodic images of local atoms back to the local atoms.
+    //
+    // metatomic expects pairs corresponding to periodic atoms to be between
+    // the main atoms, but using the actual distance vector between the atom and
+    // the ghost.
+    original_atom_id_.clear();
+    original_atom_id_.reserve(total_n_atoms);
+
+    lmp_to_mta_.clear();
+    lmp_to_mta_.reserve(total_n_atoms);
+
+    mta_to_lmp.clear();
+    mta_to_lmp.reserve(total_n_atoms);
+
+    // identify all local atom by their LAMMPS atom tag.
+    local_atoms_tags_.clear();
+    for (int i=0; i<atom->nlocal; i++) {
+        original_atom_id_.emplace_back(i);
+        lmp_to_mta_.emplace_back(i);
+        mta_to_lmp.emplace_back(i);
+        local_atoms_tags_.emplace(atom->tag[i], i);
+    }
+
+    // now loop over ghosts & map them back to the main cell if needed
+    ghost_atoms_tags_.clear();
+    for (int i=atom->nlocal; i<total_n_atoms; i++) {
+        auto tag = atom->tag[i];
+        auto it = local_atoms_tags_.find(tag);
+        if (it != local_atoms_tags_.end()) {
+            // this is the periodic image of an atom already owned by this domain
+            original_atom_id_.emplace_back(it->second);
+            lmp_to_mta_.emplace_back(-1);
+        } else {
+            // this can either be a periodic image of an atom owned by another
+            // domain, or directly an atom from another domain. Since we can not
+            // really distinguish between these, we take the first atom as the
+            // "main" one and remap all atoms with the same tag to the first one
+            auto it = ghost_atoms_tags_.find(tag);
+            if (it != ghost_atoms_tags_.end()) {
+                // we already found this atom elsewhere in the system
+                original_atom_id_.emplace_back(it->second);
+                lmp_to_mta_.emplace_back(-1);
+            } else {
+                // this is the first time we are seeing this atom
+                original_atom_id_.emplace_back(i);
+                ghost_atoms_tags_.emplace(tag, i);
+
+                lmp_to_mta_.emplace_back(mta_to_lmp.size());
+                mta_to_lmp.emplace_back(i);
+            }
+        }
+    }
+}
+
 
 void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, NeighList *list) {
     auto _ = MetatomicTimer("converting neighbors list");
@@ -218,51 +277,6 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
     auto total_n_atoms = atom->nlocal + atom->nghost;
     auto cell_inv = cell_inverse(domain);
 
-    {
-        auto _ = MetatomicTimer("identifying ghosts and real atoms");
-
-        // Collect the local atom id of all local & ghosts atoms, mapping ghosts
-        // atoms which are periodic images of local atoms back to the local atoms.
-        //
-        // metatomic expects pairs corresponding to periodic atoms to be between
-        // the main atoms, but using the actual distance vector between the atom and
-        // the ghost.
-        original_atom_id_.clear();
-        original_atom_id_.reserve(total_n_atoms);
-
-        // identify all local atom by their LAMMPS atom tag.
-        local_atoms_tags_.clear();
-        for (int i=0; i<atom->nlocal; i++) {
-            original_atom_id_.emplace_back(i);
-            local_atoms_tags_.emplace(atom->tag[i], i);
-        }
-
-        // now loop over ghosts & map them back to the main cell if needed
-        ghost_atoms_tags_.clear();
-        for (int i=atom->nlocal; i<total_n_atoms; i++) {
-            auto tag = atom->tag[i];
-            auto it = local_atoms_tags_.find(tag);
-            if (it != local_atoms_tags_.end()) {
-                // this is the periodic image of an atom already owned by this domain
-                original_atom_id_.emplace_back(it->second);
-            } else {
-                // this can either be a periodic image of an atom owned by another
-                // domain, or directly an atom from another domain. Since we can not
-                // really distinguish between these, we take the first atom as the
-                // "main" one and remap all atoms with the same tag to the first one
-                auto it = ghost_atoms_tags_.find(tag);
-                if (it != ghost_atoms_tags_.end()) {
-                    // we already found this atom elsewhere in the system
-                    original_atom_id_.emplace_back(it->second);
-                } else {
-                    // this is the first time we are seeing this atom
-                    original_atom_id_.emplace_back(i);
-                    ghost_atoms_tags_.emplace(tag, i);
-                }
-            }
-        }
-    }
-
     for (auto& cache: caches_) {
         {
             auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
@@ -364,8 +378,8 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
                     }
 
                     auto sample = std::array<int32_t, 5>{
-                        original_atom_i,
-                        original_atom_j,
+                        lmp_to_mta_[original_atom_i],
+                        lmp_to_mta_[original_atom_j],
                         shift[0],
                         shift[1],
                         shift[2],
@@ -472,12 +486,7 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU);
 
     // atom->x contains "real" and then ghost atoms, in that order
-    this->positions = torch::from_blob(
-        *x, {total_n_atoms, 3},
-        // requires_grad=true since we always need gradients w.r.t. positions
-        tensor_options.requires_grad(options_.requires_grad)
-    );
-    auto system_positions = this->positions.to(dtype).to(device);
+    this->positions = torch::from_blob(*x, {total_n_atoms, 3}, tensor_options);
 
     auto cell = torch::zeros({3, 3}, tensor_options);
     cell[0][0] = domain->xprd;
@@ -489,18 +498,29 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
     cell[2][1] = domain->yz;
     cell[2][2] = domain->zprd;
 
-    cell = cell.to(dtype).to(device);
-
     // Periodic boundary conditions handling.
     auto pbc = torch::tensor(
         {domain->xperiodic, domain->yperiodic, domain->zperiodic},
-        torch::TensorOptions().dtype(torch::kBool).device(device)
+        torch::TensorOptions().dtype(torch::kBool).device(torch::kCPU)
     );
 
-    cell.index_put_(
-        {torch::logical_not(pbc)},
-        torch::tensor({0.0}, torch::TensorOptions().dtype(dtype).device(device))
+    cell.index_put_({torch::logical_not(pbc)}, torch::tensor({0.0}, tensor_options));
+
+    this->guess_periodic_ghosts();
+
+    // Only keep the atoms which are not periodic images of other atoms
+    auto mta_to_lmp_tensor = torch::from_blob(
+        mta_to_lmp.data(),
+        {static_cast<int64_t>(mta_to_lmp.size())},
+        torch::TensorOptions().dtype(torch::kInt).device(torch::kCPU)
     );
+    this->atomic_types_ = this->atomic_types_.index_select(0, mta_to_lmp_tensor);
+    this->positions = this->positions.index_select(0, mta_to_lmp_tensor);
+
+    this->positions.set_requires_grad(options_.requires_grad);
+
+    auto system_positions = this->positions.to(dtype).to(device);
+    cell = cell.to(dtype).to(device);
 
     if (do_virial) {
         auto model_strain = this->strain.to(dtype).to(device);
@@ -515,7 +535,7 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
         atomic_types_.to(device),
         system_positions,
         cell,
-        pbc
+        pbc.to(device)
     );
 
     this->setup_neighbors(system, list);
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index 37854e83966..790014d4738 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -101,10 +101,17 @@ class MetatomicSystemAdaptor : public Pointers {
     // conversion) to access its gradient
     torch::Tensor positions;
 
+    // LAMMPS atom id for all atoms in the metatomic system.
+    std::vector<int> mta_to_lmp;
+
  protected:
-    // setup the metatomic neighbors list from the internal LAMMPS one,
+    // setup the metatomic neighbors lists from the internal LAMMPS one,
     void setup_neighbors(metatomic_torch::System& system, NeighList* list);
 
+    // Some ghosts atoms correspond to periodic images of other atoms, we need
+    // to identify them to avoid duplicated pairs in the neighbor lists.
+    void guess_periodic_ghosts();
+
     // options for this system adaptor
     MetatomicSystemOptions options_;
 
@@ -112,13 +119,19 @@ class MetatomicSystemAdaptor : public Pointers {
     std::vector<MetatomicNeighborsData> caches_;
     // allocation cache for the atomic types in the system
     torch::Tensor atomic_types_;
-    // allocation cache holding the "original atom" id for all atoms in the
-    // system. This is the same as the atom id for all local atoms. For ghost
-    // atoms, this is either the id of the corresponding local atom if the ghost
-    // is a periodic image of a local atom, the id of the first ghost we found
-    // with a given atom tag if the ghost is a periodic image of another ghost;
-    // or the id of the ghost in all other cases.
+
+    // Original atom id for all atoms in the LAMMPS system.
+    //
+    // This is the same as the atom id for all local atoms. For ghost atoms,
+    // this is either the id of the corresponding local atom if the ghost is a
+    // periodic image of a local atom, the id of the first ghost we found with a
+    // given atom tag if the ghost is a periodic image of another ghost; or the
+    // id of the ghost in all other cases.
     std::vector<int> original_atom_id_;
+    // Metatomic atom id for all atoms in the LAMMPS system.
+    // Contains `atoms->nlocal + atoms->nghost` elements
+    std::vector<int> lmp_to_mta_;
+
     // allocation cache holding the map from atom tag to atom id for local
     // atoms.
     std::unordered_map<tagint, int> local_atoms_tags_;
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index d69b2686807..ec48e3305ad 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -593,7 +593,6 @@ void PairMetatomic::compute(int eflag, int vflag) {
             }
             mta_data->energy_output->per_atom = true;
         } else {
-            assert(eflag_global);
             mta_data->energy_output->per_atom = false;
         }
 
@@ -764,11 +763,12 @@ void PairMetatomic::compute(int eflag, int vflag) {
                 assert(samples_values.sizes() == mta_data->selected_atoms_values.sizes());
 
                 auto energies = energy_detached.accessor<double, 2>();
+                const auto& mta_to_lmp = this->system_adaptor->mta_to_lmp;
                 for (int64_t i=0; i<energy_samples->count(); i++) {
                     assert(samples[i][0] == 0);
                     // handle potentially out of order samples in
                     // the per-atom energy tensor
-                    auto atom_i = samples[i][1];
+                    auto atom_i = mta_to_lmp[samples[i][1]];
                     assert(atom_i < atom->nlocal + atom->nghost);
                     eatom[atom_i] += this->scale * energies[i][0];
                 }
@@ -822,17 +822,20 @@ void PairMetatomic::pre_compute() {}
 void PairMetatomic::store_forces(const at::Tensor& forces_tensor) {
     assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
 
-    int num_forces_to_update;
-    if (mta_data->non_conservative) {
-        num_forces_to_update = atom->nlocal;
-    } else {
-        num_forces_to_update = atom->nlocal + atom->nghost;
-    }
-
     auto forces = forces_tensor.accessor<double, 2>();
-    for (int i=0; i<num_forces_to_update; i++) {
+    for (int i=0; i<atom->nlocal; i++) {
         atom->f[i][0] += this->scale * forces[i][0];
         atom->f[i][1] += this->scale * forces[i][1];
         atom->f[i][2] += this->scale * forces[i][2];
     }
+
+    // in non-conservative mode we do not need to update forces on ghost atoms
+    if (!mta_data->non_conservative) {
+        const auto& mta_to_lmp = this->system_adaptor->mta_to_lmp;
+        for (int i=atom->nlocal; i<forces.size(0); i++) {
+            atom->f[mta_to_lmp[i]][0] += this->scale * forces[i][0];
+            atom->f[mta_to_lmp[i]][1] += this->scale * forces[i][1];
+            atom->f[mta_to_lmp[i]][2] += this->scale * forces[i][2];
+        }
+    }
 }

From 10abedd1078c6f5e86c345ecb6bbc12a385ca904 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Fri, 28 Nov 2025 10:28:22 +0100
Subject: [PATCH 32/37] Properly skip pairs when processing the neighbor list

This removes the need to check for pair duplicate before
using them, making the NL adapter 4x faster
---
 src/KOKKOS/metatomic_system_kokkos.cpp | 357 +++++++++++++------------
 src/ML-METATOMIC/metatomic_system.cpp  |  89 +++---
 src/ML-METATOMIC/metatomic_system.h    |  23 +-
 3 files changed, 234 insertions(+), 235 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 3abe5070471..944ac616528 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -110,183 +110,190 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
 
     auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
 
-    auto original_id = torch::from_blob(
-        original_atom_id_.data(),
-        {total_n_atoms},
-        torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-    ).to(this->device_);
-
-    auto lmp_to_mta = torch::from_blob(
-        lmp_to_mta_.data(),
-        {total_n_atoms},
-        torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-    ).to(this->device_);
-
-    auto neighbors_kk = list->d_neighbors;
-    auto max_number_of_neighbors = list->maxneighs;
-
-    auto neighbors = torch::zeros(
-        {total_n_atoms, max_number_of_neighbors},
-        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    );
-    // mask neighbors_kk with NEIGHMASK. Torch doesn't have this functionality, we do it in Kokkos
-    auto neighbors_kk_masked = UnmanagedView<int32_t**, DeviceType>(
-        neighbors.template data_ptr<int32_t>(),
-        total_n_atoms,
-        max_number_of_neighbors
-    );
-    Kokkos::parallel_for(
-        Kokkos::MDRangePolicy({0, 0}, {total_n_atoms, max_number_of_neighbors}),
-        KOKKOS_LAMBDA(size_t i, size_t j) {
-            neighbors_kk_masked(i, j) = neighbors_kk(i, j) & NEIGHMASK;
-        }
-    );
-
-    // Convert NL-related data to torch tensors
-    auto numneigh = torch::from_blob(
-        list->d_numneigh.data(),
-        {total_n_atoms},
-        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    );
-    auto ilist = torch::from_blob(
-        list->d_ilist.data(),
-        {total_n_atoms},
-        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    );
-
-    auto k_x = atomKK->k_x.view<DeviceType>();
-    auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
-    auto x = torch::from_blob(k_x.data(), {total_n_atoms, 3}, tensor_options);
-    auto cell_inv = cell_inverse(system);
-
-    // convert from LAMMPS NL format to metatomic NL format
-    auto expanded_arange = torch::arange(
-        max_number_of_neighbors,
-        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    ).unsqueeze(0).expand({total_n_atoms, -1});
-    auto neighbor_2d_mask = expanded_arange < numneigh.unsqueeze(1);
-
-    auto expanded_arange_other_dim = torch::arange(
-        total_n_atoms,
-        torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    ).unsqueeze(1).expand({-1, max_number_of_neighbors});
-    auto index_for_ilist = expanded_arange_other_dim.masked_select(neighbor_2d_mask);
-
-    auto centers_id = ilist.index_select(0, index_for_ilist);
-    auto neighbors_id = neighbors.masked_select(neighbor_2d_mask);
-
-    // change centers and neighbors to the original atom ids
-    auto centers_original_id = original_id.index_select(0, centers_id);
-    auto neighbors_original_id = original_id.index_select(0, neighbors_id);
-
-    // The following code is a direct translation of the code in the non-Kokkos
-    // version (MetatomicSystemAdaptor::setup_neighbors_remap), but rewritten
-    // in torch to use the GPU
-    for (auto& cache: caches_) {
-        // current values of various tensors, these change depending on full/half setting
-        torch::Tensor centers_id_cur;
-        torch::Tensor neighbors_id_cur;
-        torch::Tensor centers_original_id_cur;
-        torch::Tensor neighbors_original_id_cur;
-
-        // filtered tensors, i.e. only containing pairs actually below the cutoff
-        torch::Tensor centers_original_id_filt_cur;
-        torch::Tensor neighbors_original_id_filt_cur;
-        torch::Tensor distances_filt_cur;
-        torch::Tensor cell_shifts_cur;
-
-        // other tensors that need to live across multiple timed sections
-        torch::Tensor samples_indices;
-        torch::Tensor samples_values;
-        {
-            auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
-            // half list mask, if necessary
-            auto full_list = cache.options->full_list();
-
-            if (full_list) {
-                centers_id_cur = centers_id;
-                neighbors_id_cur = neighbors_id;
-                centers_original_id_cur = centers_original_id;
-                neighbors_original_id_cur = neighbors_original_id;
-            } else {
-                auto half_list_mask = centers_original_id <= neighbors_original_id;
-                centers_id_cur = centers_id.masked_select(half_list_mask);
-                neighbors_id_cur = neighbors_id.masked_select(half_list_mask);
-                centers_original_id_cur = centers_original_id.masked_select(half_list_mask);
-                neighbors_original_id_cur = neighbors_original_id.masked_select(half_list_mask);
-            }
-
-            // distance mask
-            auto distances = x.index_select(0, neighbors_id_cur) - x.index_select(0, centers_id_cur);
-            auto cutoff_mask = torch::sum(distances.pow(2), 1) < cache.cutoff*cache.cutoff;
-
-            // index everything with the mask
-            auto centers_original_id_filt = centers_original_id_cur.masked_select(cutoff_mask);
-            auto neighbors_original_id_filt = neighbors_original_id_cur.masked_select(cutoff_mask);
-            auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
-
-            // find filtered interatomic vectors using the original atoms
-            auto original_distances_filtered = x.index_select(0, neighbors_original_id_filt) - x.index_select(0, centers_original_id_filt);
-
-            // cell shifts
-            auto pair_shifts = distances_filt - original_distances_filtered;
-            auto cell_shifts = pair_shifts.matmul(cell_inv);
-            cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
-
-            if (full_list) {
-                centers_original_id_filt_cur = centers_original_id_filt;
-                neighbors_original_id_filt_cur = neighbors_original_id_filt;
-                distances_filt_cur = distances_filt;
-                cell_shifts_cur = cell_shifts;
-            } else {
-                auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
-                auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
-                auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
-                // reproduce this mask (from MetatomicSystemAdaptor::setup_neighbors_remap) with torch:
-                // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
-                auto edge_mask = (
-                    (torch::sum(cell_shifts, 1) == 0) & (
-                        (cell_shifts.index({torch::indexing::Slice(), 2}) < 0) | (
-                            cell_shifts.index({torch::indexing::Slice(), 2}) == 0 &
-                            cell_shifts.index({torch::indexing::Slice(), 1}) < 0
-                        )
-                    )
-                );
-                auto final_mask = torch::logical_not(
-                    half_list_cell_mask | (
-                        pair_with_image_mask & (negative_half_space_mask | edge_mask)
-                    )
-                );
-                centers_original_id_filt_cur = centers_original_id_filt.masked_select(final_mask);
-                neighbors_original_id_filt_cur = neighbors_original_id_filt.masked_select(final_mask);
-                distances_filt_cur = distances_filt.index({final_mask, torch::indexing::Slice()});
-                cell_shifts_cur = cell_shifts.index({final_mask, torch::indexing::Slice()});
-            }
-
-            // make sure all the sample are unique
-            samples_values = torch::concatenate({
-                lmp_to_mta.index_select(0, centers_original_id_filt_cur).unsqueeze(-1),
-                lmp_to_mta.index_select(0, neighbors_original_id_filt_cur).unsqueeze(-1),
-                cell_shifts_cur
-            }, /*dim=*/1);
-
-            auto [samples_values_unique, samples_inverse, _counts] = torch::unique_dim(
-                samples_values, /*dim=*/0, /*sorted=*/true, /*return_inverse=*/true, /*return_counts=*/false
-            );
-            samples_values = samples_values_unique;
-
-            auto permutation = torch::arange(samples_inverse.size(0), samples_inverse.options());
-            samples_inverse = samples_inverse.flip({0});
-            permutation = permutation.flip({0});
-
-            samples_indices = torch::empty(samples_values.size(0), samples_inverse.options());
-            samples_indices.scatter_(0, samples_inverse, permutation);
-        }
+    // auto original_id = torch::from_blob(
+    //     original_atom_id_.data(),
+    //     {total_n_atoms},
+    //     torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
+    // ).to(this->device_);
+
+    // auto lmp_to_mta = torch::from_blob(
+    //     lmp_to_mta_.data(),
+    //     {total_n_atoms},
+    //     torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
+    // ).to(this->device_);
+
+    // auto neighbors_kk = list->d_neighbors;
+    // auto max_number_of_neighbors = list->maxneighs;
+
+    // auto neighbors = torch::zeros(
+    //     {total_n_atoms, max_number_of_neighbors},
+    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    // );
+    // // mask neighbors_kk with NEIGHMASK. Torch doesn't have this functionality, we do it in Kokkos
+    // auto neighbors_kk_masked = UnmanagedView<int32_t**, DeviceType>(
+    //     neighbors.template data_ptr<int32_t>(),
+    //     total_n_atoms,
+    //     max_number_of_neighbors
+    // );
+    // Kokkos::parallel_for(
+    //     Kokkos::MDRangePolicy({0, 0}, {total_n_atoms, max_number_of_neighbors}),
+    //     KOKKOS_LAMBDA(size_t i, size_t j) {
+    //         neighbors_kk_masked(i, j) = neighbors_kk(i, j) & NEIGHMASK;
+    //     }
+    // );
+
+    // // Convert NL-related data to torch tensors
+    // auto numneigh = torch::from_blob(
+    //     list->d_numneigh.data(),
+    //     {total_n_atoms},
+    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    // );
+    // auto ilist = torch::from_blob(
+    //     list->d_ilist.data(),
+    //     {total_n_atoms},
+    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    // );
+
+    // auto k_x = atomKK->k_x.view<DeviceType>();
+    // auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
+    // auto x = torch::from_blob(k_x.data(), {total_n_atoms, 3}, tensor_options);
+    // auto cell_inv = cell_inverse(system);
+
+    // // convert from LAMMPS NL format to metatomic NL format
+    // auto expanded_arange = torch::arange(
+    //     max_number_of_neighbors,
+    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    // ).unsqueeze(0).expand({total_n_atoms, -1});
+    // auto neighbor_2d_mask = expanded_arange < numneigh.unsqueeze(1);
+
+    // auto expanded_arange_other_dim = torch::arange(
+    //     total_n_atoms,
+    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    // ).unsqueeze(1).expand({-1, max_number_of_neighbors});
+    // auto index_for_ilist = expanded_arange_other_dim.masked_select(neighbor_2d_mask);
+
+    // auto centers_id = ilist.index_select(0, index_for_ilist);
+    // auto neighbors_id = neighbors.masked_select(neighbor_2d_mask);
+
+    // // change centers and neighbors to the original atom ids
+    // auto centers_original_id = original_id.index_select(0, centers_id);
+    // auto neighbors_original_id = original_id.index_select(0, neighbors_id);
+
+    for (auto& nl: nl_requests_) {
+        // // current values of various tensors, these change depending on full/half setting
+        // torch::Tensor centers_id_cur;
+        // torch::Tensor neighbors_id_cur;
+        // torch::Tensor centers_original_id_cur;
+        // torch::Tensor neighbors_original_id_cur;
+
+        // // filtered tensors, i.e. only containing pairs actually below the cutoff
+        // torch::Tensor centers_original_id_filt_cur;
+        // torch::Tensor neighbors_original_id_filt_cur;
+        // torch::Tensor distances_filt_cur;
+        // torch::Tensor cell_shifts_cur;
+
+        // // other tensors that need to live across multiple timed sections
+        // torch::Tensor samples_indices;
+        // torch::Tensor samples_values;
+        // {
+        //     auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
+        //     // half list mask, if necessary
+        //     auto full_list = nl.options->full_list();
+
+        //     if (full_list) {
+        //         centers_id_cur = centers_id;
+        //         neighbors_id_cur = neighbors_id;
+        //         centers_original_id_cur = centers_original_id;
+        //         neighbors_original_id_cur = neighbors_original_id;
+        //     } else {
+        //         auto half_list_mask = centers_original_id <= neighbors_original_id;
+        //         centers_id_cur = centers_id.masked_select(half_list_mask);
+        //         neighbors_id_cur = neighbors_id.masked_select(half_list_mask);
+        //         centers_original_id_cur = centers_original_id.masked_select(half_list_mask);
+        //         neighbors_original_id_cur = neighbors_original_id.masked_select(half_list_mask);
+        //     }
+
+        //     // distance mask
+        //     auto distances = x.index_select(0, neighbors_id_cur) - x.index_select(0, centers_id_cur);
+        //     auto cutoff_mask = torch::sum(distances.pow(2), 1) < nl.cutoff * nl.cutoff;
+
+        //     // index everything with the mask
+        //     auto centers_original_id_filt = centers_original_id_cur.masked_select(cutoff_mask);
+        //     auto neighbors_original_id_filt = neighbors_original_id_cur.masked_select(cutoff_mask);
+        //     auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
+
+        //     // find filtered interatomic vectors using the original atoms
+        //     auto original_distances_filtered = x.index_select(0, neighbors_original_id_filt) - x.index_select(0, centers_original_id_filt);
+
+        //     // cell shifts
+        //     auto pair_shifts = distances_filt - original_distances_filtered;
+        //     auto cell_shifts = pair_shifts.matmul(cell_inv);
+        //     cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
+
+        //     if (full_list) {
+        //         centers_original_id_filt_cur = centers_original_id_filt;
+        //         neighbors_original_id_filt_cur = neighbors_original_id_filt;
+        //         distances_filt_cur = distances_filt;
+        //         cell_shifts_cur = cell_shifts;
+        //     } else {
+        //         auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
+        //         auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
+        //         auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
+        //         // reproduce this mask (from MetatomicSystemAdaptor::setup_neighbors_remap) with torch:
+        //         // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
+        //         auto edge_mask = (
+        //             (torch::sum(cell_shifts, 1) == 0) & (
+        //                 (cell_shifts.index({torch::indexing::Slice(), 2}) < 0) | (
+        //                     cell_shifts.index({torch::indexing::Slice(), 2}) == 0 &
+        //                     cell_shifts.index({torch::indexing::Slice(), 1}) < 0
+        //                 )
+        //             )
+        //         );
+        //         auto final_mask = torch::logical_not(
+        //             half_list_cell_mask | (
+        //                 pair_with_image_mask & (negative_half_space_mask | edge_mask)
+        //             )
+        //         );
+        //         centers_original_id_filt_cur = centers_original_id_filt.masked_select(final_mask);
+        //         neighbors_original_id_filt_cur = neighbors_original_id_filt.masked_select(final_mask);
+        //         distances_filt_cur = distances_filt.index({final_mask, torch::indexing::Slice()});
+        //         cell_shifts_cur = cell_shifts.index({final_mask, torch::indexing::Slice()});
+        //     }
+
+        //     // make sure all the sample are unique
+        //     samples_values = torch::concatenate({
+        //         lmp_to_mta.index_select(0, centers_original_id_filt_cur).unsqueeze(-1),
+        //         lmp_to_mta.index_select(0, neighbors_original_id_filt_cur).unsqueeze(-1),
+        //         cell_shifts_cur
+        //     }, /*dim=*/1);
+
+        //     auto [samples_values_unique, samples_inverse, _counts] = torch::unique_dim(
+        //         samples_values, /*dim=*/0, /*sorted=*/true, /*return_inverse=*/true, /*return_counts=*/false
+        //     );
+        //     samples_values = samples_values_unique;
+
+        //     auto permutation = torch::arange(samples_inverse.size(0), samples_inverse.options());
+        //     samples_inverse = samples_inverse.flip({0});
+        //     permutation = permutation.flip({0});
+
+        //     samples_indices = torch::empty(samples_values.size(0), samples_inverse.options());
+        //     samples_indices.scatter_(0, samples_inverse, permutation);
+        // }
+
+        int64_t n_pairs = 0;
+
+
+        auto samples_values = torch::from_blob(
+            nullptr, {n_pairs, 5}, torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+        );
+
+        auto distances = torch::from_blob(
+            nullptr, {n_pairs, 3}, torch::TensorOptions().dtype(dtype).device(this->device_)
+        );
 
         // wrap into metatensor data structures
         torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
         {
-            auto n_pairs = samples_values.size(0);
             auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
             samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
                 std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
@@ -300,7 +307,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
             auto _ = MetatomicTimer("creating neighbors TensorBlock");
 
             neighbors = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
-                distances_filt_cur.index_select(0, samples_indices).unsqueeze(-1),
+                distances,
                 samples,
                 std::vector<metatensor_torch::Labels>{
                     metatensor_torch::LabelsHolder::create({"xyz"}, {{0}, {1}, {2}})->to(this->device_),
@@ -310,7 +317,7 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
         }
 
         metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-        system->add_neighbor_list(cache.options, neighbors);
+        system->add_neighbor_list(nl.options, neighbors);
     }
 }
 
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 8aac3fb5a3b..499d1a709bd 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -146,7 +146,7 @@ static std::array<std::array<double, 3>, 3> cell_inverse(Domain* domain) {
 MetatomicSystemAdaptor::MetatomicSystemAdaptor(LAMMPS *lmp, MetatomicSystemOptions options):
     Pointers(lmp),
     options_(std::move(options)),
-    caches_(),
+    nl_requests_(),
     atomic_types_(torch::zeros({0}, torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)))
 {
     auto tensor_options = torch::TensorOptions()
@@ -174,10 +174,9 @@ void MetatomicSystemAdaptor::add_nl_request(double cutoff, metatomic_torch::Neig
         );
     }
 
-    caches_.push_back({
+    nl_requests_.push_back({
         cutoff,
         request,
-        /*known_samples = */ {},
         /*samples = */ {},
         /*distances_f64 = */ {},
         /*distances_f32 = */ {},
@@ -277,34 +276,46 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
     auto total_n_atoms = atom->nlocal + atom->nghost;
     auto cell_inv = cell_inverse(domain);
 
-    for (auto& cache: caches_) {
+    for (auto& nl: nl_requests_) {
         {
             auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
 
-            auto cutoff2 = cache.cutoff * cache.cutoff;
-            auto full_list = cache.options->full_list();
+            auto cutoff2 = nl.cutoff * nl.cutoff;
+            auto full_list = nl.options->full_list();
 
             // convert from LAMMPS neighbors list to metatomic format
-            cache.known_samples.clear();
-            cache.samples.clear();
-            cache.distances_f32.clear();
-            cache.distances_f64.clear();
+            nl.samples.clear();
+            nl.distances_f32.clear();
+            nl.distances_f64.clear();
             for (int ii=0; ii<(list->inum + list->gnum); ii++) {
                 auto atom_i = list->ilist[ii];
                 assert(atom_i < total_n_atoms);
                 auto original_atom_i = original_atom_id_[atom_i];
+                auto i_is_original = (atom_i == original_atom_i);
 
                 auto neighbors = list->firstneigh[ii];
                 for (int jj=0; jj<list->numneigh[ii]; jj++) {
                     auto atom_j = neighbors[jj] & NEIGHMASK;
                     assert(atom_j < total_n_atoms);
                     auto original_atom_j = original_atom_id_[atom_j];
+                    auto j_is_original = (atom_j == original_atom_j);
 
                     if (!full_list && original_atom_i > original_atom_j) {
                         // Remove extra pairs if the model requested half-lists
                         continue;
                     }
 
+                    if (!i_is_original && !j_is_original) {
+                        // both atoms are periodic ghosts, skip the pair
+                        continue;
+                    }
+
+                    if (!i_is_original && j_is_original) {
+                        // this pair will be accounted for when we will process
+                        // atom_j as the central atom
+                        continue;
+                    }
+
                     auto distance = std::array<double, 3>{
                         x[atom_j][0] - x[atom_i][0],
                         x[atom_j][1] - x[atom_i][1],
@@ -385,32 +396,26 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
                         shift[2],
                     };
 
-                    // only add the pair if it is not already known. The same pair
-                    // can occur multiple time between two periodic ghosts shifted
-                    // around by the same amount, but we only want one of these pairs.
-                    if (cache.known_samples.insert(sample).second) {
-                        cache.samples.push_back(sample);
-
-                        if (dtype == torch::kFloat64) {
-                            cache.distances_f64.push_back(distance);
-                        } else if (dtype == torch::kFloat32) {
-                            cache.distances_f32.push_back({
-                                static_cast<float>(distance[0]),
-                                static_cast<float>(distance[1]),
-                                static_cast<float>(distance[2])
-                            });
-                        } else {
-                            // should be unreachable
-                            error->one(FLERR, "invalid dtype, this is a bug");
-                        }
+                    nl.samples.push_back(sample);
+                    if (dtype == torch::kFloat64) {
+                        nl.distances_f64.push_back(distance);
+                    } else if (dtype == torch::kFloat32) {
+                        nl.distances_f32.push_back({
+                            static_cast<float>(distance[0]),
+                            static_cast<float>(distance[1]),
+                            static_cast<float>(distance[2])
+                        });
+                    } else {
+                        // should be unreachable
+                        error->one(FLERR, "invalid dtype, this is a bug");
                     }
                 }
             }
         }
 
-        int64_t n_pairs = cache.samples.size();
+        int64_t n_pairs = nl.samples.size();
         auto samples_values = torch::from_blob(
-            reinterpret_cast<int32_t*>(cache.samples.data()),
+            reinterpret_cast<int32_t*>(nl.samples.data()),
             {n_pairs, 5},
             torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
         );
@@ -418,23 +423,31 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
         torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
         {
             auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
-            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-                samples_values,
-                metatensor::assume_unique{}
-            );
+            if (options_.check_consistency) {
+                // pairs should be unique, but I'm not 100% sure yet
+                samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                    std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                    samples_values
+                );
+            } else {
+                samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                    std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                    samples_values,
+                    metatensor::assume_unique{}
+                );
+            }
         }
 
         auto distances_vectors = torch::Tensor();
         if (dtype == torch::kFloat64) {
             distances_vectors = torch::from_blob(
-                cache.distances_f64.data(),
+                nl.distances_f64.data(),
                 {n_pairs, 3, 1},
                 torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)
             );
         } else if (dtype == torch::kFloat32) {
             distances_vectors = torch::from_blob(
-                cache.distances_f32.data(),
+                nl.distances_f32.data(),
                 {n_pairs, 3, 1},
                 torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU)
             );
@@ -463,7 +476,7 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
         }
 
         metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-        system->add_neighbor_list(cache.options, neighbors);
+        system->add_neighbor_list(nl.options, neighbors);
     }
 }
 
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index 790014d4738..c870a7e133f 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -16,7 +16,6 @@
 
 #include <vector>
 #include <array>
-#include <unordered_set>
 
 #include "pointers.h"
 #include "pair.h"
@@ -44,22 +43,6 @@ struct MetatomicNeighborsData {
     // single neighbors sample containing [i, j, S_a, S_b, S_c]
     using sample_t = std::array<int32_t, 5>;
 
-    struct SampleHasher {
-        static void hash_combine(std::size_t& seed, const int32_t& v) {
-            seed ^= std::hash<int32_t>()(v) + 0x9e3779b9 + (seed<<6) + (seed>>2);
-        }
-
-        size_t operator()(const sample_t& s) const {
-            size_t hash = 0;
-            hash_combine(hash, s[0]);
-            hash_combine(hash, s[1]);
-            hash_combine(hash, s[2]);
-            hash_combine(hash, s[3]);
-            hash_combine(hash, s[4]);
-            return hash;
-        }
-    };
-
     // cutoff for this NL in LAMMPS units
     double cutoff;
     // options of the NL as requested by the model
@@ -68,10 +51,6 @@ struct MetatomicNeighborsData {
     // Below are cached allocations for the LAMMPS -> metatomic NL translation
     // TODO: report memory usage for these?
 
-    // we keep the set of samples twice: once in `known_samples` to remove
-    // duplicated pairs, and once in `samples` in a format that can be
-    // used to create a torch::Tensor.
-    std::unordered_set<sample_t, SampleHasher> known_samples;
     std::vector<sample_t> samples;
     // pairs distances vectors
     std::vector<std::array<double, 3>> distances_f64;
@@ -116,7 +95,7 @@ class MetatomicSystemAdaptor : public Pointers {
     MetatomicSystemOptions options_;
 
     // allocations caches for all the NL requested by the model
-    std::vector<MetatomicNeighborsData> caches_;
+    std::vector<MetatomicNeighborsData> nl_requests_;
     // allocation cache for the atomic types in the system
     torch::Tensor atomic_types_;
 

From 4a617daa6b379b4290127acaebfe36d544e3fa0c Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Tue, 2 Dec 2025 15:35:43 +0100
Subject: [PATCH 33/37] Re-implement NL filtering in pure kokkos

---
 src/KOKKOS/metatomic_system_kokkos.cpp | 559 ++++++++++++++-----------
 src/KOKKOS/metatomic_system_kokkos.h   |  26 ++
 src/KOKKOS/pair_metatomic_kokkos.cpp   |   7 -
 src/KOKKOS/pair_metatomic_kokkos.h     |   1 -
 src/ML-METATOMIC/metatomic_system.cpp  |  11 +-
 src/ML-METATOMIC/metatomic_system.h    |  10 +-
 src/ML-METATOMIC/pair_metatomic.cpp    |   2 -
 src/ML-METATOMIC/pair_metatomic.h      |   3 -
 8 files changed, 353 insertions(+), 266 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index 944ac616528..aae90262e98 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -15,74 +15,23 @@
    Contributing authors: Guillaume Fraux <guillaume.fraux@epfl.ch>
                          Filippo Bigi <filippo.bigi@epfl.ch>
 ------------------------------------------------------------------------- */
+
 #include "metatomic_system_kokkos.h"
+#include "memory_kokkos.h"
 #include "metatomic_timer.h"
 
-#include "domain.h"
-#include "comm.h"
+#include "atom_masks.h"
 #include "atom_kokkos.h"
+#include "comm.h"
+#include "domain.h"
+#include "error.h"
 
 #include <torch/cuda.h>
 
 using namespace LAMMPS_NS;
 
-/// Compute the inverse of the cell matrix of the system, accounting for
-/// non-periodic directions by setting the corresponding rows to an unit vector
-/// orthogonal to the periodic directions. This is used to compute the cell
-/// shifts of neighbor pairs.
-static torch::Tensor cell_inverse(const metatomic_torch::System& system) {
-    auto cell = system->cell().clone();
-    auto periodic = system->pbc();
-
-    // find number of periodic directions and their indices
-    int n_periodic = 0;
-    int periodic_idx_1 = -1;
-    int periodic_idx_2 = -1;
-    for (int i = 0; i < 3; ++i) {
-        if (periodic[i].item<bool>()) {
-            n_periodic += 1;
-            if (periodic_idx_1 == -1) {
-                periodic_idx_1 = i;
-            } else if (periodic_idx_2 == -1) {
-                periodic_idx_2 = i;
-            }
-        }
-    }
-
-    // adjust the box matrix to have a simple orthogonal dimension along
-    // non-periodic directions
-    if (n_periodic == 0) {
-        return torch::eye(3, cell.options());
-    } else if (n_periodic == 1) {
-        assert(periodic_idx_1 != -1);
-        // Make the two non-periodic directions orthogonal to the periodic one
-        auto a = cell[periodic_idx_1];
-        auto b = torch::tensor({0, 1, 0}, cell.options());
-        if (torch::abs(torch::dot(a / a.norm(), b)).item<double>() > 0.9) {
-            b = torch::tensor({0, 0, 1}, cell.options());
-        }
-        auto c = torch::cross(a, b);
-        c /= c.norm();
-        b = torch::cross(c, a);
-        b /= b.norm();
-
-        // Assign back to the cell picking the "non-periodic" indices without ifs
-        cell[(periodic_idx_1 + 1) % 3] = b;
-        cell[(periodic_idx_1 + 2) % 3] = c;
-    } else if (n_periodic == 2) {
-        assert(periodic_idx_1 != -1 && periodic_idx_2 != -1);
-        // Make the one non-periodic direction orthogonal to the two periodic ones
-        auto a = cell[periodic_idx_1];
-        auto b = cell[periodic_idx_2];
-        auto c = torch::cross(a, b);
-        c /= c.norm();
-
-        // Assign back to the matrix picking the "non-periodic" index without ifs
-        cell[(3 - periodic_idx_1 - periodic_idx_2)] = c;
-    }
-
-    return cell.inverse();
-}
+template<typename T, class DeviceType>
+using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
 
 template<typename T, class DeviceType>
 using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
@@ -103,203 +52,322 @@ MetatomicSystemAdaptorKokkos<DeviceType>::MetatomicSystemAdaptorKokkos(LAMMPS *l
     this->strain = torch::eye(3, tensor_options);
 }
 
+template<class DeviceType>
+void MetatomicSystemAdaptorKokkos<DeviceType>::add_nl_request(double cutoff, metatomic_torch::NeighborListOptions request) {
+    if (cutoff > options_.interaction_range) {
+        error->one(FLERR,
+            "Invalid metatomic model: one of the requested neighbor lists "
+            "has a cutoff ({}) larger than the model interaction range ({})",
+            cutoff, options_.interaction_range
+        );
+    } else if (cutoff < 0 || !std::isfinite(cutoff)) {
+        error->one(FLERR,
+            "model requested an invalid cutoff for neighbors list: {} "
+            "(cutoff in model units is {})",
+            cutoff, request->cutoff()
+        );
+    }
+
+    nl_requests_kk_.push_back({
+        cutoff,
+        request,
+        /*samples = */ {},
+        /*distances_f64 = */ {},
+        /*distances_f32 = */ {},
+    });
+}
+
+
 template<class DeviceType>
 void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list) {
     auto _ = MetatomicTimer("converting kokkos neighbors list");
-    auto dtype = system->positions().scalar_type();
 
+    auto dtype = system->positions().scalar_type();
     auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
+    auto max_number_of_neighbors = list->maxneighs;
+
+    auto original_id = UnmanagedView<int*, LMPHostType>(
+        original_atom_id_.data(),
+        original_atom_id_.size()
+    );
+    auto d_original_id = Kokkos::View<int*, Kokkos::LayoutRight, LMPDeviceType>("", original_atom_id_.size());
+    Kokkos::deep_copy(d_original_id, original_id);
 
-    // auto original_id = torch::from_blob(
-    //     original_atom_id_.data(),
-    //     {total_n_atoms},
-    //     torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-    // ).to(this->device_);
-
-    // auto lmp_to_mta = torch::from_blob(
-    //     lmp_to_mta_.data(),
-    //     {total_n_atoms},
-    //     torch::TensorOptions().dtype(torch::kInt32).device(torch::kCPU)
-    // ).to(this->device_);
-
-    // auto neighbors_kk = list->d_neighbors;
-    // auto max_number_of_neighbors = list->maxneighs;
-
-    // auto neighbors = torch::zeros(
-    //     {total_n_atoms, max_number_of_neighbors},
-    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    // );
-    // // mask neighbors_kk with NEIGHMASK. Torch doesn't have this functionality, we do it in Kokkos
-    // auto neighbors_kk_masked = UnmanagedView<int32_t**, DeviceType>(
-    //     neighbors.template data_ptr<int32_t>(),
-    //     total_n_atoms,
-    //     max_number_of_neighbors
-    // );
-    // Kokkos::parallel_for(
-    //     Kokkos::MDRangePolicy({0, 0}, {total_n_atoms, max_number_of_neighbors}),
-    //     KOKKOS_LAMBDA(size_t i, size_t j) {
-    //         neighbors_kk_masked(i, j) = neighbors_kk(i, j) & NEIGHMASK;
-    //     }
-    // );
-
-    // // Convert NL-related data to torch tensors
-    // auto numneigh = torch::from_blob(
-    //     list->d_numneigh.data(),
-    //     {total_n_atoms},
-    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    // );
-    // auto ilist = torch::from_blob(
-    //     list->d_ilist.data(),
-    //     {total_n_atoms},
-    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    // );
-
-    // auto k_x = atomKK->k_x.view<DeviceType>();
-    // auto tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(this->device_);
-    // auto x = torch::from_blob(k_x.data(), {total_n_atoms, 3}, tensor_options);
-    // auto cell_inv = cell_inverse(system);
-
-    // // convert from LAMMPS NL format to metatomic NL format
-    // auto expanded_arange = torch::arange(
-    //     max_number_of_neighbors,
-    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    // ).unsqueeze(0).expand({total_n_atoms, -1});
-    // auto neighbor_2d_mask = expanded_arange < numneigh.unsqueeze(1);
-
-    // auto expanded_arange_other_dim = torch::arange(
-    //     total_n_atoms,
-    //     torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
-    // ).unsqueeze(1).expand({-1, max_number_of_neighbors});
-    // auto index_for_ilist = expanded_arange_other_dim.masked_select(neighbor_2d_mask);
-
-    // auto centers_id = ilist.index_select(0, index_for_ilist);
-    // auto neighbors_id = neighbors.masked_select(neighbor_2d_mask);
-
-    // // change centers and neighbors to the original atom ids
-    // auto centers_original_id = original_id.index_select(0, centers_id);
-    // auto neighbors_original_id = original_id.index_select(0, neighbors_id);
-
-    for (auto& nl: nl_requests_) {
-        // // current values of various tensors, these change depending on full/half setting
-        // torch::Tensor centers_id_cur;
-        // torch::Tensor neighbors_id_cur;
-        // torch::Tensor centers_original_id_cur;
-        // torch::Tensor neighbors_original_id_cur;
-
-        // // filtered tensors, i.e. only containing pairs actually below the cutoff
-        // torch::Tensor centers_original_id_filt_cur;
-        // torch::Tensor neighbors_original_id_filt_cur;
-        // torch::Tensor distances_filt_cur;
-        // torch::Tensor cell_shifts_cur;
-
-        // // other tensors that need to live across multiple timed sections
-        // torch::Tensor samples_indices;
-        // torch::Tensor samples_values;
-        // {
-        //     auto _ = MetatomicTimer("filtering LAMMPS neighbor list");
-        //     // half list mask, if necessary
-        //     auto full_list = nl.options->full_list();
-
-        //     if (full_list) {
-        //         centers_id_cur = centers_id;
-        //         neighbors_id_cur = neighbors_id;
-        //         centers_original_id_cur = centers_original_id;
-        //         neighbors_original_id_cur = neighbors_original_id;
-        //     } else {
-        //         auto half_list_mask = centers_original_id <= neighbors_original_id;
-        //         centers_id_cur = centers_id.masked_select(half_list_mask);
-        //         neighbors_id_cur = neighbors_id.masked_select(half_list_mask);
-        //         centers_original_id_cur = centers_original_id.masked_select(half_list_mask);
-        //         neighbors_original_id_cur = neighbors_original_id.masked_select(half_list_mask);
-        //     }
-
-        //     // distance mask
-        //     auto distances = x.index_select(0, neighbors_id_cur) - x.index_select(0, centers_id_cur);
-        //     auto cutoff_mask = torch::sum(distances.pow(2), 1) < nl.cutoff * nl.cutoff;
-
-        //     // index everything with the mask
-        //     auto centers_original_id_filt = centers_original_id_cur.masked_select(cutoff_mask);
-        //     auto neighbors_original_id_filt = neighbors_original_id_cur.masked_select(cutoff_mask);
-        //     auto distances_filt = distances.index({cutoff_mask, torch::indexing::Slice()});
-
-        //     // find filtered interatomic vectors using the original atoms
-        //     auto original_distances_filtered = x.index_select(0, neighbors_original_id_filt) - x.index_select(0, centers_original_id_filt);
-
-        //     // cell shifts
-        //     auto pair_shifts = distances_filt - original_distances_filtered;
-        //     auto cell_shifts = pair_shifts.matmul(cell_inv);
-        //     cell_shifts = torch::round(cell_shifts).to(torch::kInt32);
-
-        //     if (full_list) {
-        //         centers_original_id_filt_cur = centers_original_id_filt;
-        //         neighbors_original_id_filt_cur = neighbors_original_id_filt;
-        //         distances_filt_cur = distances_filt;
-        //         cell_shifts_cur = cell_shifts;
-        //     } else {
-        //         auto half_list_cell_mask = centers_original_id_filt > neighbors_original_id_filt;
-        //         auto pair_with_image_mask = centers_original_id_filt == neighbors_original_id_filt;
-        //         auto negative_half_space_mask = torch::sum(cell_shifts, 1) < 0;
-        //         // reproduce this mask (from MetatomicSystemAdaptor::setup_neighbors_remap) with torch:
-        //         // if ((shift[0] + shift[1] + shift[2] == 0) && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0)))
-        //         auto edge_mask = (
-        //             (torch::sum(cell_shifts, 1) == 0) & (
-        //                 (cell_shifts.index({torch::indexing::Slice(), 2}) < 0) | (
-        //                     cell_shifts.index({torch::indexing::Slice(), 2}) == 0 &
-        //                     cell_shifts.index({torch::indexing::Slice(), 1}) < 0
-        //                 )
-        //             )
-        //         );
-        //         auto final_mask = torch::logical_not(
-        //             half_list_cell_mask | (
-        //                 pair_with_image_mask & (negative_half_space_mask | edge_mask)
-        //             )
-        //         );
-        //         centers_original_id_filt_cur = centers_original_id_filt.masked_select(final_mask);
-        //         neighbors_original_id_filt_cur = neighbors_original_id_filt.masked_select(final_mask);
-        //         distances_filt_cur = distances_filt.index({final_mask, torch::indexing::Slice()});
-        //         cell_shifts_cur = cell_shifts.index({final_mask, torch::indexing::Slice()});
-        //     }
-
-        //     // make sure all the sample are unique
-        //     samples_values = torch::concatenate({
-        //         lmp_to_mta.index_select(0, centers_original_id_filt_cur).unsqueeze(-1),
-        //         lmp_to_mta.index_select(0, neighbors_original_id_filt_cur).unsqueeze(-1),
-        //         cell_shifts_cur
-        //     }, /*dim=*/1);
-
-        //     auto [samples_values_unique, samples_inverse, _counts] = torch::unique_dim(
-        //         samples_values, /*dim=*/0, /*sorted=*/true, /*return_inverse=*/true, /*return_counts=*/false
-        //     );
-        //     samples_values = samples_values_unique;
-
-        //     auto permutation = torch::arange(samples_inverse.size(0), samples_inverse.options());
-        //     samples_inverse = samples_inverse.flip({0});
-        //     permutation = permutation.flip({0});
-
-        //     samples_indices = torch::empty(samples_values.size(0), samples_inverse.options());
-        //     samples_indices.scatter_(0, samples_inverse, permutation);
-        // }
-
-        int64_t n_pairs = 0;
+    auto lmp_to_mta = UnmanagedView<int*, LMPHostType>(
+        lmp_to_mta_.data(),
+        lmp_to_mta_.size()
+    );
+    auto d_lmp_to_mta = Kokkos::View<int*, Kokkos::LayoutRight, LMPDeviceType>("", lmp_to_mta_.size());
+    Kokkos::deep_copy(d_lmp_to_mta, lmp_to_mta);
 
 
-        auto samples_values = torch::from_blob(
-            nullptr, {n_pairs, 5}, torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
+    auto cell_inv = this->cell_inverse();
+    auto d_cell_inv = Kokkos::View<double**, Kokkos::LayoutRight, LMPDeviceType>("cell_inv", 3, 3);
+    Kokkos::deep_copy(
+        d_cell_inv,
+        UnmanagedView<double**, LMPHostType>(reinterpret_cast<double*>(cell_inv.data()), 3, 3)
+    );
+
+    auto x = atomKK->k_x.view<DeviceType>();
+    auto cell_shifts = KOKKOS_LAMBDA(
+        const Kokkos::View<double**, Kokkos::LayoutRight, LMPDeviceType>& cell_inv,
+        const double pair_shift[3],
+        int32_t shift_out[3]
+    ) {
+        shift_out[0] = static_cast<int32_t>(std::round(
+            cell_inv(0, 0) * pair_shift[0] +
+            cell_inv(0, 1) * pair_shift[1] +
+            cell_inv(0, 2) * pair_shift[2]
+        ));
+        shift_out[1] = static_cast<int32_t>(std::round(
+            cell_inv(1, 0) * pair_shift[0] +
+            cell_inv(1, 1) * pair_shift[1] +
+            cell_inv(1, 2) * pair_shift[2]
+        ));
+        shift_out[2] = static_cast<int32_t>(std::round(
+            cell_inv(2, 0) * pair_shift[0] +
+            cell_inv(2, 1) * pair_shift[1] +
+            cell_inv(2, 2) * pair_shift[2]
+        ));
+    };
+
+    for (auto& nl: nl_requests_kk_) {
+        auto cutoff2 = nl.cutoff * nl.cutoff;
+        auto full_list = nl.options->full_list();
+
+        auto cutoff_ratio = nl.cutoff / options_.interaction_range;
+        size_t max_n_pairs = total_n_atoms * list->maxneighs;
+        // Allocate for a much smaller number of pairs to avoid wasting memory
+        // (especially when the interaction range is much larger than the NL
+        // cutoff)
+        auto pairs_capacity = std::max(
+            std::max(
+                static_cast<size_t>(max_n_pairs * cutoff_ratio / 1000),
+                100ul
+            ),
+            nl.samples.extent(0)
         );
 
-        auto distances = torch::from_blob(
-            nullptr, {n_pairs, 3}, torch::TensorOptions().dtype(dtype).device(this->device_)
+        // actual number of pairs we found
+        auto n_pairs = Kokkos::DualView<int64_t, LMPDeviceType>("n_pairs");
+        auto d_n_pairs = n_pairs.view_device();
+        auto h_n_pairs = n_pairs.view_host();
+
+        auto processed_all_pairs = Kokkos::DualView<bool, LMPDeviceType>("processed_all_pairs");
+        auto d_processed_all_pairs = processed_all_pairs.view_device();
+        auto h_processed_all_pairs = processed_all_pairs.view_host();
+
+        Kokkos::deep_copy(h_processed_all_pairs, false);
+        processed_all_pairs.template modify<LMPHostType>();
+        processed_all_pairs.template sync<LMPDeviceType>();
+
+        while (!h_processed_all_pairs()) {
+            {
+                auto _ = MetatomicTimer("allocating caches for kokkos neighbors list (capacity for " + std::to_string(pairs_capacity) + " pairs)");
+                if (nl.samples.extent(0) < pairs_capacity) {
+                    MemoryKokkos::realloc_kokkos(nl.samples, "metatomic:samples", pairs_capacity, 5);
+                }
+
+                if (dtype == torch::kFloat64) {
+                    if (nl.distances_f64.extent(0) < pairs_capacity) {
+                        MemoryKokkos::realloc_kokkos(nl.distances_f64, "metatomic:distances_f64", pairs_capacity, 3);
+                    }
+                } else if (dtype == torch::kFloat32) {
+                    if (nl.distances_f32.extent(0) < pairs_capacity) {
+                        MemoryKokkos::realloc_kokkos(nl.distances_f32, "metatomic:distances_f32", pairs_capacity, 3);
+                    }
+                } else {
+                    // should be unreachable
+                    error->one(FLERR, "invalid dtype, this is a bug");
+                }
+            }
+
+            auto _ = MetatomicTimer("filtering kokkos neighbors list");
+
+            Kokkos::deep_copy(h_n_pairs, 0);
+            n_pairs.template modify<LMPHostType>();
+            n_pairs.template sync<LMPDeviceType>();
+
+            Kokkos::deep_copy(h_processed_all_pairs, true);
+            processed_all_pairs.template modify<LMPHostType>();
+            processed_all_pairs.template sync<LMPDeviceType>();
+
+            Kokkos::parallel_for(
+                Kokkos::MDRangePolicy<DeviceType, Kokkos::Rank<2>>(
+                    {0, 0},
+                    {list->inum + list->gnum, max_number_of_neighbors}
+                ),
+                KOKKOS_LAMBDA(size_t ii, size_t jj) {
+                    if (jj >= list->d_numneigh[ii]) {
+                        return;
+                    }
+
+                    auto atom_i = list->d_ilist[ii];
+                    auto original_atom_i = d_original_id[atom_i];
+                    auto i_is_original = (atom_i == original_atom_i);
+
+                    auto atom_j = list->d_neighbors(ii, jj) & NEIGHMASK;
+                    auto original_atom_j = d_original_id[atom_j];
+                    auto j_is_original = (atom_j == original_atom_j);
+
+                    if (!full_list && original_atom_i > original_atom_j) {
+                        // Remove extra pairs if the model requested half-lists
+                        return;
+                    }
+
+                    if (!i_is_original && !j_is_original) {
+                        // both atoms are periodic ghosts, skip the pair
+                        return;
+                    }
+
+                    if (!i_is_original && j_is_original) {
+                        // this pair will be accounted for when we will process
+                        // atom_j as the central atom
+                        return;
+                    }
+
+                    double distance[3] = {
+                        x(atom_j, 0) - x(atom_i, 0),
+                        x(atom_j, 1) - x(atom_i, 1),
+                        x(atom_j, 2) - x(atom_i, 2),
+                    };
+
+                    auto distance2 = (
+                        distance[0] * distance[0] +
+                        distance[1] * distance[1] +
+                        distance[2] * distance[2]
+                    );
+                    if (distance2 > cutoff2) {
+                        // LAMMPS neighbors list contains some pairs after the
+                        // cutoff, we filter them here
+                        return;
+                    }
+
+                    // Compute the cell shift for the pair.
+                    double shift_i[3] = {
+                        x(atom_i, 0) - x(original_atom_i, 0),
+                        x(atom_i, 1) - x(original_atom_i, 1),
+                        x(atom_i, 2) - x(original_atom_i, 2),
+                    };
+                    double shift_j[3] = {
+                        x(atom_j, 0) - x(original_atom_j, 0),
+                        x(atom_j, 1) - x(original_atom_j, 1),
+                        x(atom_j, 2) - x(original_atom_j, 2),
+                    };
+                    double pair_shift[3] = {
+                        shift_j[0] - shift_i[0],
+                        shift_j[1] - shift_i[1],
+                        shift_j[2] - shift_i[2],
+                    };
+
+                    int32_t shift[3] = {0, 0, 0};
+                    if (pair_shift[0] != 0 || pair_shift[1] != 0 || pair_shift[2] != 0) {
+                        cell_shifts(d_cell_inv, pair_shift, shift);
+
+                        if (!full_list && original_atom_i == original_atom_j) {
+                            // If a half neighbors list has been requested, do
+                            // not include the same pair between an atom and
+                            // it's periodic image twice with opposite cell
+                            // shifts (e.g. [1, -1, 1] and [-1, 1, -1]).
+                            //
+                            // Instead we pick pairs in the positive plan of
+                            // shifts.
+                            if (shift[0] + shift[1] + shift[2] < 0) {
+                                // drop shifts on the negative half-space
+                                return;
+                            }
+
+                            if ((shift[0] + shift[1] + shift[2] == 0)
+                                && (shift[2] < 0 || (shift[2] == 0 && shift[1] < 0))) {
+                                // drop shifts in the negative half plane or the
+                                // negative shift[1] axis.
+                                //
+                                // See below for a graphical representation: we are
+                                // keeping the shifts indicated with `O` and
+                                // dropping the ones indicated with `X`
+                                //
+                                //  O O O │ O O O
+                                //  O O O │ O O O
+                                //  O O O │ O O O
+                                // ─X─X─X─┼─O─O─O─
+                                //  X X X │ X X X
+                                //  X X X │ X X X
+                                //  X X X │ X X X
+                                return;
+                            }
+                        }
+                    }
+
+                    auto pair_i = Kokkos::atomic_fetch_add(&d_n_pairs(), 1);
+                    if (pair_i >= nl.samples.extent(0)) {
+                        // stop and re-allocate larger arrays
+                        d_processed_all_pairs() = false;
+                        return;
+                    }
+
+                    nl.samples(pair_i, 0) = d_lmp_to_mta[original_atom_i];
+                    nl.samples(pair_i, 1) = d_lmp_to_mta[original_atom_j];
+                    nl.samples(pair_i, 2) = shift[0];
+                    nl.samples(pair_i, 3) = shift[1];
+                    nl.samples(pair_i, 4) = shift[2];
+                    if (dtype == torch::kFloat64) {
+                        nl.distances_f64(pair_i, 0) = distance[0];
+                        nl.distances_f64(pair_i, 1) = distance[1];
+                        nl.distances_f64(pair_i, 2) = distance[2];
+                    } else {
+                        assert(dtype == torch::kFloat32);
+                        nl.distances_f32(pair_i, 0) = static_cast<float>(distance[0]);
+                        nl.distances_f32(pair_i, 1) = static_cast<float>(distance[1]);
+                        nl.distances_f32(pair_i, 2) = static_cast<float>(distance[2]);
+                    }
+                }
+            );
+
+            processed_all_pairs.template modify<LMPDeviceType>();
+            processed_all_pairs.template sync<LMPHostType>();
+            if (!h_processed_all_pairs()) {
+                pairs_capacity *= 2;
+            }
+        }
+
+        n_pairs.template modify<LMPDeviceType>();
+        n_pairs.template sync<LMPHostType>();
+
+        auto samples_values = torch::from_blob(
+            nl.samples.data(), {h_n_pairs(), 5}, torch::TensorOptions().dtype(torch::kInt32).device(this->device_)
         );
 
+        torch::Tensor distances;
+        if (dtype == torch::kFloat64) {
+            distances = torch::from_blob(
+                nl.distances_f64.data(), {h_n_pairs(), 3, 1}, torch::TensorOptions().dtype(dtype).device(this->device_)
+            );
+        } else if (dtype == torch::kFloat32) {
+            distances = torch::from_blob(
+                nl.distances_f32.data(), {h_n_pairs(), 3, 1}, torch::TensorOptions().dtype(dtype).device(this->device_)
+            );
+        } else {
+            // should be unreachable
+            error->one(FLERR, "invalid dtype, this is a bug");
+        }
+
         // wrap into metatensor data structures
         torch::intrusive_ptr<metatensor_torch::LabelsHolder> samples;
         {
-            auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(n_pairs) + " pairs)");
-            samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
-                std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
-                samples_values,
-                metatensor::assume_unique{}
-            );
+            auto _ = MetatomicTimer("creating samples Labels (" +  std::to_string(h_n_pairs()) + " pairs)");
+
+            if (options_.check_consistency) {
+                samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                    std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                    samples_values
+                );
+            } else {
+                samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+                    std::vector<std::string>{"first_atom", "second_atom", "cell_shift_a", "cell_shift_b", "cell_shift_c"},
+                    samples_values,
+                    metatensor::assume_unique{}
+                );
+            }
         }
 
         torch::intrusive_ptr<metatensor_torch::TensorBlockHolder> neighbors;
@@ -316,8 +384,11 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
             );
         }
 
-        metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
-        system->add_neighbor_list(nl.options, neighbors);
+        {
+            auto _ = MetatomicTimer("registering neighbors in System");
+            metatomic_torch::register_autograd_neighbors(system, neighbors, options_.check_consistency);
+            system->add_neighbor_list(nl.options, neighbors);
+        }
     }
 }
 
@@ -369,6 +440,8 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
         torch::tensor({0.0}, tensor_options)
     );
 
+    // make sure to sync the updated tags to host
+    atomKK->sync(ExecutionSpaceFromDevice<LMPHostType>::space, TAG_MASK);
     this->guess_periodic_ghosts();
 
     // Only keep the atoms which are not periodic images of other atoms
diff --git a/src/KOKKOS/metatomic_system_kokkos.h b/src/KOKKOS/metatomic_system_kokkos.h
index 595c4a3263c..77de60ffa24 100644
--- a/src/KOKKOS/metatomic_system_kokkos.h
+++ b/src/KOKKOS/metatomic_system_kokkos.h
@@ -72,12 +72,35 @@ template<> struct KokkosDeviceToTorch<Kokkos::Threads> {
 
 /* ---------------------------------------------------------------------- */
 
+// data for metatomic neighbors lists
+struct MetatomicNeighborsDataKokkos {
+    // single neighbors sample containing [i, j, S_a, S_b, S_c]
+    using sample_t = std::array<int32_t, 5>;
+
+    // cutoff for this NL in LAMMPS units
+    double cutoff;
+    // options of the NL as requested by the model
+    metatomic_torch::NeighborListOptions options;
+
+    // Below are cached allocations for the LAMMPS -> metatomic NL translation
+    // TODO: report memory usage for these?
+
+    Kokkos::View<int32_t**, Kokkos::LayoutRight, LMPDeviceType> samples;
+    // pairs distances vectors
+    Kokkos::View<double**, Kokkos::LayoutRight, LMPDeviceType> distances_f64;
+    Kokkos::View<float**, Kokkos::LayoutRight, LMPDeviceType> distances_f32;
+};
+
 template<class DeviceType>
 class MetatomicSystemAdaptorKokkos : public MetatomicSystemAdaptor {
 public:
     MetatomicSystemAdaptorKokkos(LAMMPS *lmp, MetatomicSystemOptions options);
     ~MetatomicSystemAdaptorKokkos() override {}
 
+    void add_nl_request(
+        double cutoff, metatomic_torch::NeighborListOptions request
+    ) override;
+
     // Create a metatensor system matching the LAMMPS-Kokkos system data
     metatomic_torch::System system_from_lmp(
         NeighList* list,
@@ -91,6 +114,9 @@ class MetatomicSystemAdaptorKokkos : public MetatomicSystemAdaptor {
 private:
     /// Torch device corresponding to the kokkos `DeviceType`
     torch::Device device_;
+
+    // allocations caches for all the NL requested by the model
+    std::vector<MetatomicNeighborsDataKokkos> nl_requests_kk_;
 };
 
 }    // namespace LAMMPS_NS
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index abcab878278..6eedafe7837 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -109,12 +109,6 @@ void PairMetatomicKokkos<DeviceType>::pick_device(torch::Device& device, const c
     }
 }
 
-template<class DeviceType>
-void PairMetatomicKokkos<DeviceType>::pre_compute() {
-    /// Declare what we need to read from the atomKK object and what we will modify
-    this->atomKK->sync(ExecutionSpaceFromDevice<DeviceType>::space, datamask_read);
-    this->atomKK->modified(ExecutionSpaceFromDevice<DeviceType>::space, datamask_modify);
-}
 
 template<class DeviceType>
 void PairMetatomicKokkos<DeviceType>::store_forces(const at::Tensor& forces_tensor) {
@@ -143,7 +137,6 @@ void PairMetatomicKokkos<DeviceType>::store_forces(const at::Tensor& forces_tens
         using DeviceUnmanaged = UnmanagedView<int*, DeviceType>;
         using DeviceView = Kokkos::View<int*, Kokkos::LayoutRight, DeviceType>;
 
-
         auto& mta_to_lmp = this->system_adaptor->mta_to_lmp;
         DeviceUnmanaged mta_to_lmp_kk;
         DeviceView mta_to_lmp_device;
diff --git a/src/KOKKOS/pair_metatomic_kokkos.h b/src/KOKKOS/pair_metatomic_kokkos.h
index 11b5abdbc9a..6bd7e457c87 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.h
+++ b/src/KOKKOS/pair_metatomic_kokkos.h
@@ -50,7 +50,6 @@ class PairMetatomicKokkos : public PairMetatomic {
 
     void init_style() override;
 
-    void pre_compute() override;
     void store_forces(const at::Tensor& forces_tensor) override;
 
 private:
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 499d1a709bd..1c975eba067 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -73,11 +73,7 @@ matrix_t inverse(matrix_t a) {
     return inverse;
 }
 
-/// Compute the inverse of the cell matrix of the system, accounting for
-/// non-periodic directions by setting the corresponding rows to an unit vector
-/// orthogonal to the periodic directions. This is used to compute the cell
-/// shifts of neighbor pairs.
-static std::array<std::array<double, 3>, 3> cell_inverse(Domain* domain) {
+std::array<std::array<double, 3>, 3> MetatomicSystemAdaptor::cell_inverse() {
     auto periodic = std::array<bool, 3>{
         static_cast<bool>(domain->xperiodic),
         static_cast<bool>(domain->yperiodic),
@@ -273,8 +269,7 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
     auto device = system->positions().device();
 
     double** x = atom->x;
-    auto total_n_atoms = atom->nlocal + atom->nghost;
-    auto cell_inv = cell_inverse(domain);
+    auto cell_inv = this->cell_inverse();
 
     for (auto& nl: nl_requests_) {
         {
@@ -289,14 +284,12 @@ void MetatomicSystemAdaptor::setup_neighbors(metatomic_torch::System& system, Ne
             nl.distances_f64.clear();
             for (int ii=0; ii<(list->inum + list->gnum); ii++) {
                 auto atom_i = list->ilist[ii];
-                assert(atom_i < total_n_atoms);
                 auto original_atom_i = original_atom_id_[atom_i];
                 auto i_is_original = (atom_i == original_atom_i);
 
                 auto neighbors = list->firstneigh[ii];
                 for (int jj=0; jj<list->numneigh[ii]; jj++) {
                     auto atom_j = neighbors[jj] & NEIGHMASK;
-                    assert(atom_j < total_n_atoms);
                     auto original_atom_j = original_atom_id_[atom_j];
                     auto j_is_original = (atom_j == original_atom_j);
 
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index c870a7e133f..6e3270a2878 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -63,7 +63,9 @@ class MetatomicSystemAdaptor : public Pointers {
 
     virtual ~MetatomicSystemAdaptor();
 
-    void add_nl_request(double cutoff, metatomic_torch::NeighborListOptions request);
+    virtual void add_nl_request(
+        double cutoff, metatomic_torch::NeighborListOptions request
+    );
 
     // Create a metatomic system matching the LAMMPS system data
     virtual metatomic_torch::System system_from_lmp(
@@ -91,6 +93,12 @@ class MetatomicSystemAdaptor : public Pointers {
     // to identify them to avoid duplicated pairs in the neighbor lists.
     void guess_periodic_ghosts();
 
+    /// Compute the inverse of the cell matrix of the system, accounting for
+    /// non-periodic directions by setting the corresponding rows to an unit vector
+    /// orthogonal to the periodic directions. This is used to compute the cell
+    /// shifts of neighbor pairs.
+    std::array<std::array<double, 3>, 3> cell_inverse();
+
     // options for this system adaptor
     MetatomicSystemOptions options_;
 
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index ec48e3305ad..88cc83bb5a2 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -817,8 +817,6 @@ void PairMetatomic::compute(int eflag, int vflag) {
     }
 }
 
-void PairMetatomic::pre_compute() {}
-
 void PairMetatomic::store_forces(const at::Tensor& forces_tensor) {
     assert(forces_tensor.is_cpu() && forces_tensor.scalar_type() == torch::kFloat64);
 
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
index e3f5f637ae4..50d49f26042 100644
--- a/src/ML-METATOMIC/pair_metatomic.h
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -65,9 +65,6 @@ class PairMetatomic : public Pair {
     // store the forces from the model in LAMMPS data structures
     virtual void store_forces(const at::Tensor& forces_tensor);
 
-    // called one at the beginning of `compute`
-    virtual void pre_compute();
-
 protected:
     // get the set of devices both available on the current machine and supported
     // by the model

From 755ad80d04799fa27b11f858259de82f67df1c20 Mon Sep 17 00:00:00 2001
From: frostedoyster <bigi.f@libero.it>
Date: Tue, 9 Dec 2025 07:39:09 +0100
Subject: [PATCH 34/37] Eliminate GPU references to class

---
 src/KOKKOS/metatomic_system_kokkos.cpp | 12 +++++++-----
 1 file changed, 7 insertions(+), 5 deletions(-)

diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index aae90262e98..ac7aca455fb 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -192,21 +192,23 @@ void MetatomicSystemAdaptorKokkos<DeviceType>::setup_neighbors_kk(metatomic_torc
             processed_all_pairs.template modify<LMPHostType>();
             processed_all_pairs.template sync<LMPDeviceType>();
 
+            auto d_numneigh = list->d_numneigh;
+            auto d_ilist = list->d_ilist;
+            auto d_neighbors = list->d_neighbors;
+
             Kokkos::parallel_for(
                 Kokkos::MDRangePolicy<DeviceType, Kokkos::Rank<2>>(
                     {0, 0},
                     {list->inum + list->gnum, max_number_of_neighbors}
                 ),
                 KOKKOS_LAMBDA(size_t ii, size_t jj) {
-                    if (jj >= list->d_numneigh[ii]) {
+                    if (jj >= d_numneigh[ii]) {
                         return;
                     }
-
-                    auto atom_i = list->d_ilist[ii];
+                    auto atom_i = d_ilist[ii];
                     auto original_atom_i = d_original_id[atom_i];
                     auto i_is_original = (atom_i == original_atom_i);
-
-                    auto atom_j = list->d_neighbors(ii, jj) & NEIGHMASK;
+                    auto atom_j = d_neighbors(ii, jj) & NEIGHMASK;
                     auto original_atom_j = d_original_id[atom_j];
                     auto j_is_original = (atom_j == original_atom_j);
 

From 89ab4299af859ef13db78273ed71f8cdc76f3da2 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <guillaume.fraux@epfl.ch>
Date: Wed, 7 Jan 2026 12:08:15 +0100
Subject: [PATCH 35/37] Update metatomic dependencies versions

---
 cmake/Modules/Packages/ML-METATOMIC.cmake | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/cmake/Modules/Packages/ML-METATOMIC.cmake b/cmake/Modules/Packages/ML-METATOMIC.cmake
index 91813509894..95da625afc9 100644
--- a/cmake/Modules/Packages/ML-METATOMIC.cmake
+++ b/cmake/Modules/Packages/ML-METATOMIC.cmake
@@ -35,14 +35,14 @@ endif()
 
 ################ definition of metatensor and metatomic targets ################
 
-set(METATENSOR_CORE_VERSION "0.1.17")
-set(METATENSOR_CORE_SHA256 "42119e11908239915ccc187d7ca65449b461f1d4b5af4d6df1fb613d687da76a")
+set(METATENSOR_CORE_VERSION "0.1.19")
+set(METATENSOR_CORE_SHA256 "2d319186057cf6da8fe39cc4f961baccce59c4486223113ce554632ae7765e26")
 
 set(METATENSOR_TORCH_VERSION "0.8.2")
 set(METATENSOR_TORCH_SHA256 "0be618d0cdcfca86cd0c25f47d360b6a2410ebb09ece8d21f153e933ce64bb55")
 
-set(METATOMIC_TORCH_VERSION "0.1.6")
-set(METATOMIC_TORCH_SHA256 "4cb9b7bb530a98119186167c31fb00ea7ef3bcc45d593e449e7670e9313e5327")
+set(METATOMIC_TORCH_VERSION "0.1.7")
+set(METATOMIC_TORCH_SHA256 "726f5711b70c4b8cc80d9bc6c3ce6f3449f31d20acc644ab68dab083aa4ea572")
 
 set(DOWNLOAD_METATENSOR_DEFAULT ON)
 find_package(metatensor_torch ${METATENSOR_TORCH_VERSION} QUIET)

From a68a13972252327d7870fa998f2362633aceb095 Mon Sep 17 00:00:00 2001
From: Johannes Spies <13813209+johannes-spies@users.noreply.github.com>
Date: Thu, 8 Jan 2026 17:27:46 +0100
Subject: [PATCH 36/37] Implement fix metatomic for ML models predicting
 position/velocities such as FlashMD (#21)

Co-authored-by: frostedoyster <bigi.f@libero.it>
Co-authored-by: Guillaume Fraux <guillaume.fraux@epfl.ch>
---
 examples/PACKAGES/metatomic/.gitignore        |   3 +
 examples/PACKAGES/metatomic/get-flashmd.py    |  18 +
 examples/PACKAGES/metatomic/in.fix_metatomic  |  25 +
 .../metatomic/in.kokkos.fix_metatomic         |  31 +
 ...kos.metatomic => in.kokkos.pair_metatomic} |   1 +
 .../{in.metatomic => in.pair_metatomic}       |   0
 src/KOKKOS/fix_metatomic_kokkos.cpp           | 544 +++++++++++++++
 src/KOKKOS/fix_metatomic_kokkos.h             |  54 ++
 src/KOKKOS/metatomic_system_kokkos.cpp        | 137 +++-
 src/KOKKOS/metatomic_system_kokkos.h          |   6 +
 src/KOKKOS/pair_metatomic_kokkos.cpp          |  24 +-
 src/ML-METATOMIC/fix_metatomic.cpp            | 629 ++++++++++++++++++
 src/ML-METATOMIC/fix_metatomic.h              |  80 +++
 src/ML-METATOMIC/metatomic_system.cpp         | 128 ++++
 src/ML-METATOMIC/metatomic_system.h           |   7 +
 src/ML-METATOMIC/metatomic_types.cpp          |   9 +-
 src/ML-METATOMIC/metatomic_types.h            |  36 +-
 src/ML-METATOMIC/pair_metatomic.cpp           |   1 -
 src/ML-METATOMIC/pair_metatomic.h             |   7 -
 19 files changed, 1688 insertions(+), 52 deletions(-)
 create mode 100644 examples/PACKAGES/metatomic/get-flashmd.py
 create mode 100644 examples/PACKAGES/metatomic/in.fix_metatomic
 create mode 100644 examples/PACKAGES/metatomic/in.kokkos.fix_metatomic
 rename examples/PACKAGES/metatomic/{in.kokkos.metatomic => in.kokkos.pair_metatomic} (99%)
 rename examples/PACKAGES/metatomic/{in.metatomic => in.pair_metatomic} (100%)
 create mode 100644 src/KOKKOS/fix_metatomic_kokkos.cpp
 create mode 100644 src/KOKKOS/fix_metatomic_kokkos.h
 create mode 100644 src/ML-METATOMIC/fix_metatomic.cpp
 create mode 100644 src/ML-METATOMIC/fix_metatomic.h

diff --git a/examples/PACKAGES/metatomic/.gitignore b/examples/PACKAGES/metatomic/.gitignore
index d848bd9194f..7fe67cc6781 100644
--- a/examples/PACKAGES/metatomic/.gitignore
+++ b/examples/PACKAGES/metatomic/.gitignore
@@ -1,2 +1,5 @@
 collected-extensions/
 nickel-lj-extensions.pt
+
+flashmd-energy-model.pt
+flashmd-dynamics-model.pt
diff --git a/examples/PACKAGES/metatomic/get-flashmd.py b/examples/PACKAGES/metatomic/get-flashmd.py
new file mode 100644
index 00000000000..12d80c23830
--- /dev/null
+++ b/examples/PACKAGES/metatomic/get-flashmd.py
@@ -0,0 +1,18 @@
+# /// script
+# dependencies = [
+#   "flashmd == 0.2.*",
+# ]
+# ///
+
+# Run this script to get the a pre-trained flashmd model for `fix metatomic`
+#
+# Usage: python get-flashmd.py in a virtual environment with
+# https://github.com/lab-cosmo/flashmd installed or `uv run get-flashmd.py`
+
+import flashmd
+
+
+energy_model, flashmd_model = flashmd.get_pretrained("pet-omatpes", time_step=16)
+
+energy_model.save("flashmd-energy-model.pt")
+flashmd_model.save("flashmd-dynamics-model.pt")
diff --git a/examples/PACKAGES/metatomic/in.fix_metatomic b/examples/PACKAGES/metatomic/in.fix_metatomic
new file mode 100644
index 00000000000..5c9bc85f929
--- /dev/null
+++ b/examples/PACKAGES/metatomic/in.fix_metatomic
@@ -0,0 +1,25 @@
+units metal
+atom_style atomic
+boundary p p p
+
+lattice fcc 4.05
+region box block 0 3 0 3 0 3
+create_box 1 box
+create_atoms 1 box
+
+mass 1 26.9815386
+
+velocity all create 800.0 12345 mom yes rot yes dist gaussian
+
+# pair_style metatomic flashmd-energy-model.pt
+# pair_coeff * * 13
+
+timestep 0.016
+
+fix 0 all metatomic flashmd-dynamics-model.pt types 13
+fix 1 all langevin 700.0 700.0 0.1 12345
+
+thermo 10
+thermo_style custom step temp pe ke etotal
+
+run 100
diff --git a/examples/PACKAGES/metatomic/in.kokkos.fix_metatomic b/examples/PACKAGES/metatomic/in.kokkos.fix_metatomic
new file mode 100644
index 00000000000..d1506502ada
--- /dev/null
+++ b/examples/PACKAGES/metatomic/in.kokkos.fix_metatomic
@@ -0,0 +1,31 @@
+# Use the correct kokkos settings. `neigh half` does not imply the use of a half
+# neighbor list, only a change in how contributions are summed together.
+# cf https://github.com/lammps/lammps/pull/4412
+package kokkos newton on neigh half
+
+units metal
+atom_style atomic/kk
+boundary p p p
+
+lattice fcc 4.05
+region box block 0 3 0 3 0 3
+create_box 1 box
+create_atoms 1 box
+
+mass 1 26.9815386
+
+velocity all create 800.0 12345 mom yes rot yes dist gaussian
+
+# pair_style metatomic/kk flashmd-energy-model.pt
+# pair_coeff * * 13
+
+timestep 0.016
+
+fix 0 all metatomic/kk flashmd-dynamics-model.pt types 13
+# fix 1 all langevin 700.0 700.0 0.1 12345
+
+thermo 10
+thermo_style custom step temp pe ke etotal
+
+run_style verlet/kk
+run 100
diff --git a/examples/PACKAGES/metatomic/in.kokkos.metatomic b/examples/PACKAGES/metatomic/in.kokkos.pair_metatomic
similarity index 99%
rename from examples/PACKAGES/metatomic/in.kokkos.metatomic
rename to examples/PACKAGES/metatomic/in.kokkos.pair_metatomic
index df872b5318a..3b4be5bd662 100644
--- a/examples/PACKAGES/metatomic/in.kokkos.metatomic
+++ b/examples/PACKAGES/metatomic/in.kokkos.pair_metatomic
@@ -1,3 +1,4 @@
+
 # Use the correct kokkos settings. `neigh half` does not imply the use of a half
 # neighbor list, only a change in how contributions are summed together.
 # cf https://github.com/lammps/lammps/pull/4412
diff --git a/examples/PACKAGES/metatomic/in.metatomic b/examples/PACKAGES/metatomic/in.pair_metatomic
similarity index 100%
rename from examples/PACKAGES/metatomic/in.metatomic
rename to examples/PACKAGES/metatomic/in.pair_metatomic
diff --git a/src/KOKKOS/fix_metatomic_kokkos.cpp b/src/KOKKOS/fix_metatomic_kokkos.cpp
new file mode 100644
index 00000000000..d1eb76557ab
--- /dev/null
+++ b/src/KOKKOS/fix_metatomic_kokkos.cpp
@@ -0,0 +1,544 @@
+// clang-format off
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Fix metatomic/kk: Kokkos version of ML-driven position and momentum prediction
+
+   This is the Kokkos-enabled version of fix metatomic. It uses Kokkos views
+   for data access and the MetatomicSystemAdaptorKokkos for efficient data
+   transfer between LAMMPS and the ML model.
+------------------------------------------------------------------------- */
+
+#include "fix_metatomic_kokkos.h"
+
+#include "error.h"
+#include "neigh_request.h"
+#include "atom_masks.h"
+#include "group.h"
+#include "force.h"
+#include "update.h"
+#include "neighbor_kokkos.h"
+
+#include "atom_kokkos.h"
+#include "metatomic_system_kokkos.h"
+#include "metatomic_types.h"
+
+#include <algorithm>
+#include <cctype>
+
+using namespace LAMMPS_NS;
+using namespace FixConst;
+
+// LAMMPS uses `LAMMPS_NS::tagint` and `int` for tags and neighbor lists, respectively.
+// For the moment, we require both to be int32_t for this interface
+static_assert(std::is_same_v<LAMMPS_NS::tagint, int32_t>, "Error: LAMMPS_NS::tagint must be int32_t to compile fix metatomic/kk");
+static_assert(std::is_same_v<int, int32_t>, "Error: int must be int32_t to compile fix metatomic/kk");
+
+template<typename T, class DeviceType>
+using UnmanagedView = Kokkos::View<T, Kokkos::LayoutRight, DeviceType, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+FixMetatomicKokkos<DeviceType>::FixMetatomicKokkos(LAMMPS *lmp, int narg, char **arg): FixMetatomic(lmp, narg, arg) {
+  kokkosable = 1;
+  atomKK = (AtomKokkos *) atom;
+  execution_space = ExecutionSpaceFromDevice<DeviceType>::space;
+
+  datamask_read = X_MASK | V_MASK | F_MASK | MASK_MASK | RMASS_MASK | TYPE_MASK;
+  datamask_modify = X_MASK | V_MASK | F_MASK;
+}
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+FixMetatomicKokkos<DeviceType>::~FixMetatomicKokkos() {}
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+void FixMetatomicKokkos<DeviceType>::init() {
+    FixMetatomic::init();
+
+    auto request = neighbor->find_request(this);
+    request->set_kokkos_host(
+        std::is_same_v<DeviceType, LMPHostType> &&
+        !std::is_same_v<DeviceType, LMPDeviceType>
+    );
+    request->set_kokkos_device(std::is_same_v<DeviceType, LMPDeviceType>);
+
+    // copy type mapping from host to device, to be able to give a device pointer
+    // to MetatomicSystemAdaptorKokkos
+    auto type_mapping_kk_host = UnmanagedView<int32_t*, LMPHostType>(this->type_mapping, atom->ntypes + 1);
+    this->type_mapping_kk = Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType>("type_mapping_kk", atom->ntypes + 1);
+    Kokkos::deep_copy(this->type_mapping_kk, type_mapping_kk_host);
+
+    auto options = MetatomicSystemOptions{
+        this->type_mapping_kk.data(),
+        mta_data->max_cutoff,
+        mta_data->check_consistency,
+        /* requires_grad */ false,
+    };
+
+    // override the system adaptor with the kokkos version
+    this->system_adaptor = std::make_unique<MetatomicSystemAdaptorKokkos<DeviceType>>(lmp, options);
+
+    // request NL with the new adaptor
+    auto requested_nl = mta_data->model->run_method("requested_neighbor_lists");
+    for (const auto& ivalue: requested_nl.toList()) {
+        auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
+        auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
+        assert(cutoff <= mta_data->max_cutoff);
+
+        this->system_adaptor->add_nl_request(cutoff, options);
+    }
+
+    // Sync mass data to device
+    atomKK->k_mass.modify_host();
+    atomKK->k_mass.sync<DeviceType>();
+}
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+void FixMetatomicKokkos<DeviceType>::pick_device(c10::Device& device, const char* requested) {
+    // Pick device based on Kokkos execution space
+    device = KokkosDeviceToTorch<DeviceType>::convert();
+
+    if (requested != nullptr) {
+        auto requested_str = std::string(requested);
+        std::transform(requested_str.begin(), requested_str.end(), requested_str.begin(), ::tolower);
+        if (c10::DeviceTypeName(device.type(), /*lower_case=*/true) != requested_str) {
+            error->all(FLERR,
+                "requested device '{}' does not match the device being used by kokkos '{}', "
+                "use the non-kokkos version of this fix to use a different "
+                "device for the model and LAMMPS",
+                requested, device.str()
+            );
+        }
+    }
+}
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+void FixMetatomicKokkos<DeviceType>::initial_integrate(int /*vflag*/) {
+    // ML-driven position and momentum updates using Kokkos
+    // This is the main integration step where the ML model predicts new positions and momenta
+
+    // Get views to atom data on device
+    auto x = atomKK->k_x.view<DeviceType>();
+    auto v = atomKK->k_v.view<DeviceType>();
+    auto f = atomKK->k_f.view<DeviceType>();
+    auto rmass = atomKK->k_rmass.view<DeviceType>();
+    auto mass = atomKK->k_mass.view<DeviceType>();
+    auto type = atomKK->k_type.view<DeviceType>();
+    auto mask = atomKK->k_mask.view<DeviceType>();
+
+    auto groupbit = this->groupbit;
+
+    // Sync data to execution space and immediately claim ownership
+    // This prevents output->write() from causing data corruption on next timestep
+    atomKK->sync(execution_space, datamask_read);
+    atomKK->modified(execution_space, datamask_modify);
+
+    int nlocal = atomKK->nlocal;
+    if (igroup == atomKK->firstgroup) {
+        nlocal = atomKK->nfirst;
+    }
+
+    // Apply velocity corrections from forces added after `post_force`.
+    //
+    // This handles stochastic forces from Langevin thermostats by applying only
+    // the incremental force to velocities. The remaining half-step is done in
+    // final_integrate(); this is the first O in an OBABO integrator.
+    double dtf = 0.5 * update->dt * force->ftm2v;
+    bool use_rmass = rmass.data() != nullptr;
+    Kokkos::parallel_for(
+        nlocal,
+        KOKKOS_LAMBDA(int i) {
+            if (mask[i] & groupbit) {
+                double mass_i = use_rmass ? rmass[i] : mass[type[i]];
+                double dtfm = dtf / mass_i;
+
+                v(i, 0) += f(i, 0) * dtfm;
+                v(i, 1) += f(i, 1) * dtfm;
+                v(i, 2) += f(i, 2) * dtfm;
+            }
+        }
+    );
+
+    // Determine dtype for the model
+    auto dtype = torch::kFloat64;
+    if (mta_data->capabilities->dtype() == "float64") {
+        dtype = torch::kFloat64;
+    } else if (mta_data->capabilities->dtype() == "float32") {
+        dtype = torch::kFloat32;
+    } else {
+        error->all(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
+    }
+
+    // The v (and x) data is about to be read by torch to create the metatomic System,
+    // we need to synchronize to make sure kokkos kernels finished their execution
+    Kokkos::fence();
+
+    // Transform from LAMMPS to metatomic System using Kokkos adaptor
+    auto system = this->system_adaptor->system_from_lmp(
+        mta_list,
+        static_cast<bool>(vflag_global),
+        dtype,
+        mta_data->device
+    );
+
+    // add the required additional inputs
+    this->system_adaptor->add_masses(system, 1.0);
+    this->system_adaptor->add_momenta(system, this->momentum_conversion_factor);
+
+    // Configure selected atoms for evaluation
+    // Only run the calculation for atoms in the current group
+    mta_data->selected_atoms_values.resize_({group->count(igroup), 2});
+    auto selected_atoms_kk = UnmanagedView<int32_t**, DeviceType>(
+        mta_data->selected_atoms_values.data_ptr<int32_t>(),
+        mta_data->selected_atoms_values.size(0),
+        2
+    );
+    auto d_atom_i = Kokkos::View<int32_t, LMPDeviceType>("atom_i");
+    Kokkos::deep_copy(d_atom_i, 0);
+    Kokkos::parallel_for(
+        nlocal,
+        KOKKOS_LAMBDA(size_t i) {
+            if (mask[i] & groupbit) {
+                selected_atoms_kk(i, 0) = 0; // system index
+                auto atom_i = Kokkos::atomic_fetch_add(&d_atom_i(), 1);
+                selected_atoms_kk(i, 1) = atom_i;
+            }
+        }
+    );
+
+    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system", "atom"}, mta_data->selected_atoms_values
+    );
+    mta_data->evaluation_options->set_selected_atoms(selected_atoms);
+
+    // Call the ML model to predict new positions and momenta
+    torch::IValue result_ivalue;
+    try {
+        result_ivalue = mta_data->model->forward({
+            std::vector<metatomic_torch::System>{system},
+            mta_data->evaluation_options,
+            mta_data->check_consistency
+        });
+    } catch (const std::exception& e) {
+        error->all(FLERR, "error evaluating the torch model: {}", e.what());
+    }
+
+    // Extract results from the model output
+    auto result = result_ivalue.toGenericDict();
+
+    // Extract predicted positions (keep on device)
+    auto positions_map = result.at("positions").toCustomClass<metatensor_torch::TensorMapHolder>();
+    auto positions_block = metatensor_torch::TensorMapHolder::block_by_id(positions_map, 0);
+    auto positions = positions_block->values().squeeze(-1).to(mta_data->device).to(torch::kFloat64).contiguous();
+    auto positions_samples = positions_block->samples()->values().contiguous();
+    assert(positions_block->samples()->size() == 2);
+    assert(positions_block->samples()->names()[0] == "system");
+    assert(positions_block->samples()->names()[1] == "atom");
+
+
+    // Extract predicted momenta (keep on device)
+    auto momenta_map = result.at("momenta").toCustomClass<metatensor_torch::TensorMapHolder>();
+    auto momenta_block = metatensor_torch::TensorMapHolder::block_by_id(momenta_map, 0);
+    auto momenta = momenta_block->values().squeeze(-1).to(mta_data->device).to(torch::kFloat64);
+
+    // we use the positions samples to map back to LAMMPS atoms, so we need to
+    // check that the samples are the same for momenta
+    assert(*momenta_block->samples() == *positions_block->samples());
+
+    // Convert momenta back from model units to LAMMPS velocity units
+    momenta = momenta / this->momentum_conversion_factor;
+    momenta = momenta.contiguous();
+
+    // The torch data is about to be read by kokkos to update the LAMMPS variables,
+    // we need to synchronize to make sure the torch operations finished their execution
+    if (mta_data->device.type() == torch::kCUDA) {
+        torch::cuda::synchronize();
+    }
+
+    // Wrap torch tensors with UnmanagedView for device access
+    auto positions_kk = UnmanagedView<double**, DeviceType>(
+        positions.template data_ptr<double>(),
+        positions.size(0), 3
+    );
+    auto positions_samples_kk = UnmanagedView<int32_t**, DeviceType>(
+        positions_samples.data_ptr<int32_t>(),
+        positions_samples.size(0),
+        positions_samples.size(1)
+    );
+
+    auto momenta_kk = UnmanagedView<double**, DeviceType>(
+        momenta.template data_ptr<double>(),
+        momenta.size(0), 3
+    );
+
+    auto system_adaptor_kk = dynamic_cast<MetatomicSystemAdaptorKokkos<DeviceType>*>(this->system_adaptor.get());
+    assert(system_adaptor_kk != nullptr);
+    auto mta_to_lmp_kk = UnmanagedView<int32_t*, DeviceType>(
+        system_adaptor_kk->mta_to_lmp_tensor.template data_ptr<int32_t>(),
+        system_adaptor_kk->mta_to_lmp_tensor.size(0)
+    );
+
+    // Prepare masses view for device access
+    // Copy masses to device if needed
+    typename AT::t_kkfloat_1d masses_kk;
+    if (rmass.data()) {
+        masses_kk = rmass;
+    } else {
+        // Create a per-atom mass array from type-based masses
+        masses_kk = typename AT::t_kkfloat_1d("fix_metatomic:masses", nlocal);
+        Kokkos::parallel_for(nlocal,
+            KOKKOS_LAMBDA(int i) { masses_kk[i] = mass[type[i]]; }
+        );
+    }
+
+    // Helper reducers to avoid repetitive parallel_reduce calls
+    auto reduce_mass = [&](void) -> double {
+        double out = 0.0;
+        Kokkos::parallel_reduce(
+            nlocal,
+            KOKKOS_LAMBDA(int i, double &sum) {
+                if (mask[i] & groupbit) {
+                    sum += masses_kk[i];
+                }
+            },
+            out
+        );
+        return out;
+    };
+
+    auto reduce_pos_component = [&](int comp) -> double {
+        double out = 0.0;
+        Kokkos::parallel_reduce(
+            nlocal,
+            KOKKOS_LAMBDA(int i, double &sum) {
+                if (mask[i] & groupbit) {
+                    double mi = masses_kk[i];
+                    sum += mi * x(i, comp);
+                }
+            },
+            out
+        );
+        return out;
+    };
+
+    auto reduce_vel_component = [&](int comp) -> double {
+        double out = 0.0;
+        Kokkos::parallel_reduce(
+            nlocal,
+            KOKKOS_LAMBDA(int i, double &sum) {
+                if (mask[i] & groupbit) {
+                    double mi = masses_kk[i];
+                    sum += mi * v(i, comp);
+                }
+            },
+            out
+        );
+        return out;
+    };
+
+    // Compute total mass and mass-weighted sums before update
+    double total_mass = reduce_mass();
+
+    double com_old_x_sum = reduce_pos_component(0);
+    double com_old_y_sum = reduce_pos_component(1);
+    double com_old_z_sum = reduce_pos_component(2);
+
+    double com_vel_old_x_sum = reduce_vel_component(0);
+    double com_vel_old_y_sum = reduce_vel_component(1);
+    double com_vel_old_z_sum = reduce_vel_component(2);
+
+    Kokkos::parallel_for(
+        positions.size(0),
+        KOKKOS_LAMBDA(int i) {
+            auto atom_i = mta_to_lmp_kk[positions_samples_kk(i, 1)];
+            assert(atom_i < nlocal);
+            if (mask[atom_i] & groupbit) {
+                // Update positions with ML predictions
+                x(atom_i, 0) = positions_kk(i, 0);
+                x(atom_i, 1) = positions_kk(i, 1);
+                x(atom_i, 2) = positions_kk(i, 2);
+
+                // Update velocities from predicted momenta
+                double mass_i = masses_kk[atom_i];
+                v(atom_i, 0) = momenta_kk(i, 0) / mass_i;
+                v(atom_i, 1) = momenta_kk(i, 1) / mass_i;
+                v(atom_i, 2) = momenta_kk(i, 2) / mass_i;
+            }
+        }
+    );
+
+    // Compute mass-weighted sums after update
+    double com_new_x_sum = reduce_pos_component(0);
+    double com_new_y_sum = reduce_pos_component(1);
+    double com_new_z_sum = reduce_pos_component(2);
+
+    double com_vel_new_x_sum = reduce_vel_component(0);
+    double com_vel_new_y_sum = reduce_vel_component(1);
+    double com_vel_new_z_sum = reduce_vel_component(2);
+
+    // Normalize to get COM positions and velocities (if mass > 0)
+    std::array<double, 3> com_old;
+    std::array<double, 3> com_velocity_old;
+    std::array<double, 3> com_new;
+    std::array<double, 3> com_velocity_new;
+
+    if (total_mass > 0.0) {
+        com_old[0] = com_old_x_sum / total_mass;
+        com_old[1] = com_old_y_sum / total_mass;
+        com_old[2] = com_old_z_sum / total_mass;
+
+        com_velocity_old[0] = com_vel_old_x_sum / total_mass;
+        com_velocity_old[1] = com_vel_old_y_sum / total_mass;
+        com_velocity_old[2] = com_vel_old_z_sum / total_mass;
+
+        com_new[0] = com_new_x_sum / total_mass;
+        com_new[1] = com_new_y_sum / total_mass;
+        com_new[2] = com_new_z_sum / total_mass;
+
+        com_velocity_new[0] = com_vel_new_x_sum / total_mass;
+        com_velocity_new[1] = com_vel_new_y_sum / total_mass;
+        com_velocity_new[2] = com_vel_new_z_sum / total_mass;
+    }
+
+    // Compute adjustments to preserve COM motion:
+    // pos_adjust = com_old - com_new + com_velocity_old * dt
+    // vel_adjust = com_velocity_old - com_velocity_new
+    double pos_adj0 = 0.0, pos_adj1 = 0.0, pos_adj2 = 0.0;
+    double vel_adj0 = 0.0, vel_adj1 = 0.0, vel_adj2 = 0.0;
+
+    if (total_mass > 0.0) {
+        pos_adj0 = com_old[0] - com_new[0] + com_velocity_old[0] * update->dt;
+        pos_adj1 = com_old[1] - com_new[1] + com_velocity_old[1] * update->dt;
+        pos_adj2 = com_old[2] - com_new[2] + com_velocity_old[2] * update->dt;
+
+        vel_adj0 = com_velocity_old[0] - com_velocity_new[0];
+        vel_adj1 = com_velocity_old[1] - com_velocity_new[1];
+        vel_adj2 = com_velocity_old[2] - com_velocity_new[2];
+    }
+
+    // Apply COM adjustments in a second pass
+    Kokkos::parallel_for(
+        nlocal,
+        KOKKOS_LAMBDA(int i) {
+            if (mask[i] & groupbit) {
+                x(i, 0) += pos_adj0;
+                x(i, 1) += pos_adj1;
+                x(i, 2) += pos_adj2;
+
+                v(i, 0) += vel_adj0;
+                v(i, 1) += vel_adj1;
+                v(i, 2) += vel_adj2;
+            }
+        }
+    );
+}
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+void FixMetatomicKokkos<DeviceType>::post_force(int /*vflag*/) {
+    // Set the forces that comes from pair_style, bond_style, etc. to zero.
+    //
+    // This way we can isolate any forces that are added after this point (e.g.
+    // Langevin thermostat forces) and add them during final_integrate().
+    //
+    // Crucially, this means that fix metatomic needs to be the first fix in the
+    // post_force() sequence, i.e., the user must have it before any other fix
+    // that adds forces in the input script.
+    atomKK->sync(execution_space, F_MASK | MASK_MASK);
+    atomKK->modified(execution_space, F_MASK);
+    auto f = atomKK->k_f.template view<DeviceType>();
+    auto mask = atomKK->k_mask.template view<DeviceType>();
+
+    auto groupbit = this->groupbit;
+
+    int nlocal = atomKK->nlocal;
+    if (igroup == atomKK->firstgroup) {
+        nlocal = atomKK->nfirst;
+    }
+
+    Kokkos::parallel_for(
+        nlocal,
+        KOKKOS_LAMBDA(int i) {
+            if (mask[i] & groupbit) {
+                f(i, 0) = 0.0;
+                f(i, 1) = 0.0;
+                f(i, 2) = 0.0;
+            }
+        }
+    );
+}
+
+/* ---------------------------------------------------------------------- */
+
+template<class DeviceType>
+void FixMetatomicKokkos<DeviceType>::final_integrate() {
+    // Apply velocity corrections from forces added after post_force.
+    // This handles stochastic forces from Langevin thermostats by applying only
+    // the incremental force to velocities. The first half-step is done in
+    // initial_integrate(); this is the second O in an OBABO integrator.
+
+    auto v = atomKK->k_v.template view<DeviceType>();
+    auto f = atomKK->k_f.template view<DeviceType>();
+    auto rmass = atomKK->k_rmass.template view<DeviceType>();
+    auto mass = atomKK->k_mass.template view<DeviceType>();
+    auto type = atomKK->k_type.template view<DeviceType>();
+    auto mask = atomKK->k_mask.template view<DeviceType>();
+
+    // Sync data and mark velocities as modified
+    atomKK->sync(execution_space, V_MASK | F_MASK | MASK_MASK | RMASS_MASK | TYPE_MASK);
+    atomKK->modified(execution_space, V_MASK);
+
+    auto groupbit = this->groupbit;
+
+    int nlocal = atomKK->nlocal;
+    if (igroup == atomKK->firstgroup) {
+        nlocal = atomKK->nfirst;
+    }
+
+    double dtf = 0.5 * update->dt * force->ftm2v;
+    bool use_rmass = rmass.data() != nullptr;
+    Kokkos::parallel_for(
+        nlocal,
+        KOKKOS_LAMBDA(int i) {
+            if (mask[i] & groupbit) {
+                double mass_i = use_rmass ? rmass[i] : mass[type[i]];
+                double dtfm = dtf / mass_i;
+
+                // Apply any force added by other fixes to velocities
+                v(i, 0) += f(i, 0) * dtfm;
+                v(i, 1) += f(i, 1) * dtfm;
+                v(i, 2) += f(i, 2) * dtfm;
+            }
+        }
+    );
+}
+
+/* ---------------------------------------------------------------------- */
+
+namespace LAMMPS_NS {
+template class FixMetatomicKokkos<LMPDeviceType>;
+#ifdef LMP_KOKKOS_GPU
+template class FixMetatomicKokkos<LMPHostType>;
+#endif
+}
diff --git a/src/KOKKOS/fix_metatomic_kokkos.h b/src/KOKKOS/fix_metatomic_kokkos.h
new file mode 100644
index 00000000000..9345d2e98c8
--- /dev/null
+++ b/src/KOKKOS/fix_metatomic_kokkos.h
@@ -0,0 +1,54 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifdef FIX_CLASS
+// clang-format off
+FixStyle(metatomic/kk, FixMetatomicKokkos<LMPDeviceType>);
+// clang-format on
+#else
+
+#ifndef LMP_FIX_METATOMIC_KOKKOS_H
+#define LMP_FIX_METATOMIC_KOKKOS_H
+
+#include "fix_metatomic.h"
+#include "kokkos_type.h"
+
+namespace LAMMPS_NS {
+
+template<class DeviceType>
+class MetatomicSystemAdaptorKokkos;
+
+template<class DeviceType>
+class FixMetatomicKokkos : public FixMetatomic {
+public:
+   typedef ArrayTypes<DeviceType> AT;
+
+   FixMetatomicKokkos(class LAMMPS *, int, char **);
+   ~FixMetatomicKokkos();
+
+   void init() override;
+   void initial_integrate(int) override;
+   void post_force(int) override;
+   void final_integrate() override;
+
+private:
+   void pick_device(c10::Device& device, const char* requested) override;
+
+   // Kokkos view for type mapping
+   Kokkos::View<int32_t*, Kokkos::LayoutRight, DeviceType> type_mapping_kk;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
+#endif
diff --git a/src/KOKKOS/metatomic_system_kokkos.cpp b/src/KOKKOS/metatomic_system_kokkos.cpp
index ac7aca455fb..8f9f306138e 100644
--- a/src/KOKKOS/metatomic_system_kokkos.cpp
+++ b/src/KOKKOS/metatomic_system_kokkos.cpp
@@ -445,15 +445,15 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     // make sure to sync the updated tags to host
     atomKK->sync(ExecutionSpaceFromDevice<LMPHostType>::space, TAG_MASK);
     this->guess_periodic_ghosts();
-
-    // Only keep the atoms which are not periodic images of other atoms
-    auto mta_to_lmp_tensor = torch::from_blob(
+    this->mta_to_lmp_tensor = torch::from_blob(
         mta_to_lmp.data(),
         {static_cast<int64_t>(mta_to_lmp.size())},
         torch::TensorOptions().dtype(torch::kInt).device(torch::kCPU)
     ).to(this->device_);
-    this->atomic_types_ = this->atomic_types_.index_select(0, mta_to_lmp_tensor);
-    this->positions = this->positions.index_select(0, mta_to_lmp_tensor);
+
+    // Only keep the atoms which are not periodic images of other atoms
+    this->atomic_types_ = this->atomic_types_.index_select(0, this->mta_to_lmp_tensor);
+    this->positions = this->positions.index_select(0, this->mta_to_lmp_tensor);
 
     this->positions.set_requires_grad(options_.requires_grad);
 
@@ -483,6 +483,133 @@ metatomic_torch::System MetatomicSystemAdaptorKokkos<DeviceType>::system_from_lm
     return system;
 }
 
+template<class DeviceType>
+void MetatomicSystemAdaptorKokkos<DeviceType>::add_masses(metatomic_torch::System& system, double unit_conversion) {
+    auto rmass = atomKK->k_rmass.view<DeviceType>();
+    auto mass = atomKK->k_mass.view<DeviceType>();
+    auto type = atomKK->k_type.view<DeviceType>();
+
+    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
+
+    auto device = system->device();
+    auto dtype = system->scalar_type();
+
+    // Gather masses in a tensor - create directly on device
+    auto float_tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(device);
+    torch::Tensor masses;
+    if (rmass.data()) {
+        // Per-atom masses: create tensor directly from device pointer
+        masses = torch::from_blob(
+            rmass.data(), {total_n_atoms},
+            float_tensor_options.requires_grad(false)
+        );
+    } else {
+        // Type-based masses: map from atom type to mass on device
+        masses = torch::empty({total_n_atoms}, float_tensor_options);
+        auto masses_kk = UnmanagedView<double*, DeviceType>(
+            masses.data_ptr<double>(), total_n_atoms
+        );
+        Kokkos::parallel_for(total_n_atoms, KOKKOS_LAMBDA(int i) {
+            masses_kk[i] = mass[type[i]];
+        });
+    }
+
+    masses = masses.index_select(0, this->mta_to_lmp_tensor);
+    masses = masses * unit_conversion;
+
+    auto keys = metatensor_torch::LabelsHolder::single()->to(device);
+
+    auto label_tensor_options = torch::TensorOptions().dtype(torch::kInt32).device(device);
+    auto samples_values = torch::column_stack({
+        torch::zeros(system->size(), label_tensor_options).unsqueeze(1),
+        torch::arange(system->size(), label_tensor_options).unsqueeze(1)
+    });
+    auto samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system","atom"},
+        samples_values,
+        metatensor::assume_unique{}
+    );
+
+    auto properties = metatensor_torch::LabelsHolder::single()->to(device);
+
+    auto block = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+        masses.to(dtype).unsqueeze(-1),
+        samples,
+        std::vector<metatensor_torch::Labels>{},
+        properties
+    );
+    auto tensor = torch::make_intrusive<metatensor_torch::TensorMapHolder>(
+        keys,
+        std::vector<metatensor_torch::TensorBlock>{block}
+    );
+
+    system->add_data("masses", tensor, /*override=*/true);
+}
+
+
+template<class DeviceType>
+void MetatomicSystemAdaptorKokkos<DeviceType>::add_momenta(metatomic_torch::System& system, double unit_conversion) {
+    auto v = atomKK->k_v.view<DeviceType>();
+    auto rmass = atomKK->k_rmass.view<DeviceType>();
+    auto mass = atomKK->k_mass.view<DeviceType>();
+    auto type = atomKK->k_type.view<DeviceType>();
+
+    auto total_n_atoms = atomKK->nlocal + atomKK->nghost;
+
+    auto device = system->device();
+    auto dtype = system->scalar_type();
+
+    // Gather momenta in a tensor - create directly on device
+    auto float_tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(device);
+
+    torch::Tensor momenta = torch::empty({total_n_atoms, 3}, float_tensor_options);
+    auto momenta_kk = UnmanagedView<double**, DeviceType>(
+        momenta.data_ptr<double>(), total_n_atoms, 3
+    );
+    Kokkos::parallel_for(total_n_atoms, KOKKOS_LAMBDA(int i) {
+        auto m_i = rmass.data() ? rmass[i] : mass[type[i]];
+        momenta_kk(i, 0) = m_i * v(i, 0);
+        momenta_kk(i, 1) = m_i * v(i, 1);
+        momenta_kk(i, 2) = m_i * v(i, 2);
+    });
+
+    momenta = momenta.index_select(0, this->mta_to_lmp_tensor);
+    momenta = momenta * unit_conversion;
+
+    auto keys = metatensor_torch::LabelsHolder::single()->to(device);
+
+    auto label_tensor_options = torch::TensorOptions().dtype(torch::kInt32).device(device);
+    auto samples_values = torch::column_stack({
+        torch::zeros(system->size(), label_tensor_options).unsqueeze(1),
+        torch::arange(system->size(), label_tensor_options).unsqueeze(1)
+    });
+    auto samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system","atom"},
+        samples_values,
+        metatensor::assume_unique{}
+    );
+
+    auto component_values = torch::arange(3, label_tensor_options).unsqueeze(1);
+    auto component = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"xyz"}, component_values
+    );
+
+    auto properties = metatensor_torch::LabelsHolder::single()->to(device);
+
+    auto block = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+        momenta.to(dtype).unsqueeze(-1),
+        samples,
+        std::vector<metatensor_torch::Labels>{component},
+        properties
+    );
+    auto tensor = torch::make_intrusive<metatensor_torch::TensorMapHolder>(
+        keys,
+        std::vector<metatensor_torch::TensorBlock>{block}
+    );
+
+    system->add_data("momenta", tensor, /*override=*/true);
+}
+
 namespace LAMMPS_NS {
 template class MetatomicSystemAdaptorKokkos<LMPDeviceType>;
 #ifdef LMP_KOKKOS_GPU
diff --git a/src/KOKKOS/metatomic_system_kokkos.h b/src/KOKKOS/metatomic_system_kokkos.h
index 77de60ffa24..a8a4656dc87 100644
--- a/src/KOKKOS/metatomic_system_kokkos.h
+++ b/src/KOKKOS/metatomic_system_kokkos.h
@@ -109,8 +109,14 @@ class MetatomicSystemAdaptorKokkos : public MetatomicSystemAdaptor {
         torch::Device device
     ) override;
 
+    void add_masses(metatomic_torch::System& system, double unit_conversion) override;
+    void add_momenta(metatomic_torch::System& system, double unit_conversion) override;
+
     void setup_neighbors_kk(metatomic_torch::System& system, NeighListKokkos<DeviceType>* list);
 
+    // keep the mapping from metatomic to LAMMPS atom ids as a tensor on device
+    torch::Tensor mta_to_lmp_tensor;
+
 private:
     /// Torch device corresponding to the kokkos `DeviceType`
     torch::Device device_;
diff --git a/src/KOKKOS/pair_metatomic_kokkos.cpp b/src/KOKKOS/pair_metatomic_kokkos.cpp
index 6eedafe7837..5420b9f66ed 100644
--- a/src/KOKKOS/pair_metatomic_kokkos.cpp
+++ b/src/KOKKOS/pair_metatomic_kokkos.cpp
@@ -133,24 +133,12 @@ void PairMetatomicKokkos<DeviceType>::store_forces(const at::Tensor& forces_tens
 
     // in non-conservative mode we do not need to update forces on ghost atoms
     if (!mta_data->non_conservative) {
-        using HostUnmanaged = UnmanagedView<int*, LMPHostType>;
-        using DeviceUnmanaged = UnmanagedView<int*, DeviceType>;
-        using DeviceView = Kokkos::View<int*, Kokkos::LayoutRight, DeviceType>;
-
-        auto& mta_to_lmp = this->system_adaptor->mta_to_lmp;
-        DeviceUnmanaged mta_to_lmp_kk;
-        DeviceView mta_to_lmp_device;
-        if constexpr (std::is_same_v<typename HostUnmanaged::memory_space, typename DeviceUnmanaged::memory_space>) {
-            mta_to_lmp_kk = DeviceUnmanaged(mta_to_lmp.data(), mta_to_lmp.size());
-        } else {
-            // make a copy of mta_to_lmp on device
-            mta_to_lmp_device = DeviceView("mta_to_lmp_kk", mta_to_lmp.size());
-            Kokkos::deep_copy(
-                mta_to_lmp_device,
-                HostUnmanaged(mta_to_lmp.data(), mta_to_lmp.size())
-            );
-            mta_to_lmp_kk = DeviceUnmanaged(mta_to_lmp_device.data(), mta_to_lmp.size());
-        }
+        auto system_adaptor_kk = dynamic_cast<MetatomicSystemAdaptorKokkos<DeviceType>*>(this->system_adaptor.get());
+        assert(system_adaptor_kk != nullptr);
+        auto mta_to_lmp_kk = UnmanagedView<int32_t*, DeviceType>(
+            system_adaptor_kk->mta_to_lmp_tensor.template data_ptr<int32_t>(),
+            system_adaptor_kk->mta_to_lmp_tensor.size(0)
+        );
 
         Kokkos::parallel_for(
             Kokkos::RangePolicy(atomKK->nlocal, forces.size(0)),
diff --git a/src/ML-METATOMIC/fix_metatomic.cpp b/src/ML-METATOMIC/fix_metatomic.cpp
new file mode 100644
index 00000000000..ab8c95fbcd7
--- /dev/null
+++ b/src/ML-METATOMIC/fix_metatomic.cpp
@@ -0,0 +1,629 @@
+// clang-format off
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+/* ----------------------------------------------------------------------
+   Fix metatomic: ML-driven position and momentum prediction
+
+   This fix implements machine learning-driven molecular dynamics where a
+   trained model predicts atomic positions and momenta at each timestep.
+
+   The integration scheme:
+   1. initial_integrate: ML model predicts new positions and momenta
+   2. post_force: Snapshot forces (includes e.g. any added stochastic forces)
+   3. final_integrate: Apply force corrections to velocities
+------------------------------------------------------------------------- */
+#include "metatomic_types.h"
+#include "metatomic_system.h"
+
+#include "fix_metatomic.h"
+
+#include "atom.h"
+#include "memory.h"
+#include "modify.h"
+#include "error.h"
+#include "group.h"
+#include "force.h"
+#include "update.h"
+#include "neighbor.h"
+#include "neigh_list.h"
+#include "neigh_request.h"
+#include "comm.h"
+
+#include <vector>
+#include <algorithm>
+
+#include <metatomic/torch.hpp>
+#include <metatensor/torch.hpp>
+
+using namespace LAMMPS_NS;
+using namespace FixConst;
+
+/* ---------------------------------------------------------------------- */
+
+FixMetatomic::FixMetatomic(LAMMPS *lmp, int narg, char **arg): Fix(lmp, narg, arg) {
+    time_integrate = 1;  // this tells LAMMPS that this fix advances simulation time
+    dynamic_group_allow = 0;  // we don't allow dynamic groups for now
+
+    // Check for multiple MPI processes - not currently supported
+    if (comm->nprocs > 1) {
+        error->all(FLERR, "fix metatomic does not support multiple MPI processes yet");
+    }
+
+    // Determine unit system for the ML model
+    // Currently only 'metal' units are fully supported for momenta
+    std::string energy_unit;
+    std::string length_unit;
+    if (strcmp(update->unit_style, "metal") == 0) {
+        length_unit = "angstrom";
+        this->momentum_conversion_factor = 10.1805057179 / 1000.0;
+    } else if (strcmp(update->unit_style, "real") == 0) {
+        length_unit = "angstrom";
+        this->momentum_conversion_factor = 10.1805057179;
+    } else if (strcmp(update->unit_style, "si") == 0) {
+        length_unit = "m";
+        this->momentum_conversion_factor = 10.1805057179 / 1.6605390666e-22;
+    } else {
+        error->all(FLERR, "unsupported units '{}' for fix metatomic", update->unit_style);
+    }
+
+    // For now, only metal units are fully tested and supported
+    if (strcmp(update->unit_style, "metal") != 0) {
+        error->all(FLERR, "fix metatomic currently only supports 'metal' units");
+    }
+
+    if (narg < 4) {
+        error->all(FLERR,
+            "Illegal fix metatomic command: expected at least 4 arguments "
+            "(fix ID group-ID metatomic model_path ...); got %d", narg
+        );
+    }
+
+    bool types_are_set = false;
+    this->model_path = arg[3];
+    this->requested_device = std::nullopt;
+    this->extensions_directory = std::nullopt;
+    std::vector<int> parsed_types;
+
+    int iarg = 4;
+    while (iarg < narg) {
+        if (strcmp(arg[iarg], "types") == 0) {
+            types_are_set = true;
+            // Require exactly atom->ntypes integer values after the "types" keyword.
+            iarg++;
+            if (iarg + atom->ntypes > narg) {
+                error->all(FLERR,
+                    "Illegal fix metatomic command: expected %d type values "
+                    "after 'types'", atom->ntypes
+                );
+            }
+            for (int ti = 0; ti < atom->ntypes; ++ti) {
+                int type = -1;
+                const char *argstr = arg[iarg + ti];
+                try {
+                    type = std::stoi(argstr);
+                } catch (const std::invalid_argument &) {
+                    error->all(FLERR,
+                        "Illegal fix metatomic command: expected integer for type %d, "
+                        "got '%s'", ti + 1, argstr
+                    );
+                } catch (const std::out_of_range &) {
+                    error->all(FLERR,
+                        "Illegal fix metatomic command: type value out of range "
+                        "for argument '%s'", argstr
+                    );
+                }
+                if (type <= 0) {
+                    error->all(FLERR, "Illegal fix metatomic command: type %d should be > 0", type);
+                }
+                parsed_types.push_back(type);
+            }
+            iarg += atom->ntypes;
+        } else if (strcmp(arg[iarg], "device") == 0) {
+            if (iarg + 1 >= narg) {
+                error->all(FLERR,
+                    "Illegal fix metatomic command: 'device' expects an argument "
+                    "specifying the device (e.g. cpu, cuda, mps)"
+                );
+            }
+            this->requested_device = std::string(arg[iarg + 1]);
+            iarg += 2;
+        } else if (strcmp(arg[iarg], "extensions_directory") == 0) {
+            if (iarg + 1 >= narg) {
+                error->all(FLERR,
+                    "Illegal fix metatomic command: 'extensions_directory' expects "
+                    "an argument specifying the directory path"
+                );
+            }
+            this->extensions_directory = std::string(arg[iarg + 1]);
+            iarg += 2;
+        } else {
+            error->all(FLERR,
+                "Illegal fix metatomic command: unrecognized option '%s' (expected "
+                "'types', 'device', or `extensions_directory`)", arg[iarg]
+            );
+        }
+    }
+
+    if (!types_are_set) {
+        error->all(FLERR, "Illegal fix metatomic command: no types specified");
+    }
+
+    // Allocate and fill the type-mapping (1-based indexing)
+    type_mapping = memory->create(type_mapping, atom->ntypes + 1, "fix_metatomic:type_mapping");
+    for (int i = 1; i <= atom->ntypes; i++) {
+        type_mapping[i] = parsed_types[i - 1];
+    }
+
+    this->mta_data = new FixMetatomicData(std::move(length_unit));
+
+    // FlashMD needs position change delta-q and momenta p
+    auto positions = torch::make_intrusive<metatomic_torch::ModelOutputHolder>(
+        /*quantity =*/ "length",
+        /*unit =*/ length_unit,
+        /*per_atom =*/ true,
+        /*explicit_gradients =*/ std::vector<std::string>{},
+        /*description =*/ ""
+    );
+    this->mta_data->evaluation_options->outputs.insert("positions", positions);
+
+    auto momenta = torch::make_intrusive<metatomic_torch::ModelOutputHolder>(
+        /*quantity =*/ "momentum",
+        /*unit =*/ "(eV*u)^(1/2)",
+        /*per_atom =*/ true,
+        /*explicit_gradients =*/ std::vector<std::string>{},
+        /*description =*/ ""
+    );
+    this->mta_data->evaluation_options->outputs.insert("momenta", momenta);
+}
+
+FixMetatomic::~FixMetatomic() {
+    memory->destroy(type_mapping);
+}
+
+/* ---------------------------------------------------------------------- */
+
+int FixMetatomic::setmask() {
+    return INITIAL_INTEGRATE | POST_FORCE | FINAL_INTEGRATE;
+}
+
+/* ---------------------------------------------------------------------- */
+
+void FixMetatomic::init() {
+    int fix_metatomic_index = -1;
+    const auto& fixes = modify->get_fix_list();
+    auto it = std::find(fixes.begin(), fixes.end(), this);
+    if (it != fixes.end()) {
+        fix_metatomic_index = int(it - fixes.begin());
+    }
+    if (fix_metatomic_index != 0) {
+        error->all(FLERR, "fix metatomic should be defined as the first fix (before any other fix)");
+    }
+
+    if (comm->nprocs > 1) {
+        error->all(FLERR,"fix metatomic currently does not support multiple processes");
+    }
+
+    if (!type_mapping) {
+        error->all(FLERR, "fix metatomic internal error: type_mapping not initialized");
+    }
+
+    mta_data->load_model(
+        this->lmp,
+        this->model_path.c_str(),
+        this->extensions_directory ? this->extensions_directory->c_str() : nullptr
+    );
+
+    double model_timestep = mta_data->model->attr("module").toModule().attr("timestep").toTensor().item<double>();
+    model_timestep = model_timestep * 1e-3;  // fs to ps (metal units)
+    if (std::abs(update->dt - model_timestep) > 1e-5 * model_timestep) {
+        error->all(FLERR,
+            "fix metatomic timestep (dt = {}) does not match the model's expected timestep ({}). "
+            "Please set the timestep to match the model.",
+            update->dt, model_timestep);
+    }
+
+    // Select the device to use based on the model's preference, the user choice
+    // and what's available.
+    this->pick_device(
+        mta_data->device,
+        this->requested_device ? this->requested_device->c_str() : nullptr
+    );
+
+    // move all data to the correct device
+    mta_data->model->to(mta_data->device);
+    mta_data->selected_atoms_values = mta_data->selected_atoms_values.to(mta_data->device);
+
+    auto message = "Running simulation on " + mta_data->device.str() + " device with " + mta_data->capabilities->dtype() + " data";
+    if (screen) {
+        fprintf(screen, "%s\n", message.c_str());
+    }
+    if (logfile) {
+        fprintf(logfile,"%s\n", message.c_str());
+    }
+
+    // get the model's interaction range
+    auto range = mta_data->capabilities->engine_interaction_range(mta_data->evaluation_options->length_unit());
+    if (range < 0) {
+        error->all(FLERR, "interaction_range is negative for this model");
+    } else if (!std::isfinite(range)) {
+        if (comm->nprocs > 1) {
+            error->all(FLERR,
+                "interaction_range is infinite for this model, "
+                "using multiple MPI domains is not supported"
+            );
+        }
+
+        // determine the maximal cutoff in the NL
+        auto requested_nl = mta_data->model->run_method("requested_neighbor_lists");
+        for (const auto& ivalue: requested_nl.toList()) {
+            auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
+            auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
+
+            mta_data->max_cutoff = std::max(mta_data->max_cutoff, cutoff);
+        }
+    } else {
+        mta_data->max_cutoff = range;
+    }
+
+    // Initialize metatensor system object
+    auto options = MetatomicSystemOptions{
+        this->type_mapping,
+        mta_data->max_cutoff,
+        mta_data->check_consistency,
+        /* requires_grad */ false,
+    };
+    this->system_adaptor = std::make_unique<MetatomicSystemAdaptor>(lmp, options);
+
+    // We ask LAMMPS for a full neighbor lists because we need to know about
+    // ALL pairs, even if options->full_list() is false. We will then filter
+    // the pairs to only include each pair once where needed.
+    auto request = neighbor->add_request(this, NeighConst::REQ_FULL | NeighConst::REQ_GHOST);
+    request->set_cutoff(mta_data->max_cutoff);
+
+    auto mincut = mta_data->max_cutoff + neighbor->skin;
+    if (comm->get_comm_cutoff() < mincut) {
+        if (comm->me == 0) {
+            error->warning(FLERR,
+                "Increasing communication cutoff to {:.8} for fix metatomic",
+                mincut
+            );
+        }
+        comm->cutghostuser = mincut;
+    }
+
+    // Translate from the metatomic neighbor lists requests to LAMMPS neighbor
+    // lists requests.
+    auto requested_nl = mta_data->model->run_method("requested_neighbor_lists");
+    for (const auto& ivalue: requested_nl.toList()) {
+        auto options = ivalue.get().toCustomClass<metatomic_torch::NeighborListOptionsHolder>();
+        auto cutoff = options->engine_cutoff(mta_data->evaluation_options->length_unit());
+        assert(cutoff <= mta_data->max_cutoff);
+
+        this->system_adaptor->add_nl_request(cutoff, options);
+    }
+}
+
+void FixMetatomic::pick_device(c10::Device& device, const char* requested) {
+    torch::optional<std::string> requested_string;
+    torch::DeviceType device_type;
+
+    if (requested != nullptr) {
+        requested_string = std::string(requested);
+    } else {
+        requested_string = torch::nullopt;
+    }
+
+    try {
+        device_type = metatomic_torch::pick_device(
+            this->mta_data->capabilities->supported_devices,
+            requested_string
+        );
+    } catch (const c10::Error& e) {
+        error->one(FLERR, "fix metatomic: {}", e.what());
+    }
+
+    if (device_type == torch::DeviceType::CUDA) {
+        // distribute GPUs between multiple MPI processes on the same node
+
+        // (1) get a MPI communicator for all processes on the current node
+        MPI_Comm local;
+        MPI_Comm_split_type(world, MPI_COMM_TYPE_SHARED, 0, MPI_INFO_NULL, &local);
+        // (2) get the rank of this MPI process on the current node
+        int local_rank;
+        MPI_Comm_rank(local, &local_rank);
+
+        int size;
+        MPI_Comm_size(local, &size);
+        if (size < torch::cuda::device_count()) {
+            if (comm->me == 0) {
+                error->warning(FLERR,
+                    "found {} CUDA-capable GPUs, but only {} MPI processes on the current node; the remaining GPUs will not be used",
+                    torch::cuda::device_count(), size
+                );
+            }
+        }
+
+        // (3) split GPUs between node-local processes using round-robin allocation
+        auto device_index = local_rank % torch::cuda::device_count();
+        device = torch::Device(device_type, static_cast<torch::DeviceIndex>(device_index));
+    } else {
+        device = torch::Device(device_type);
+    }
+}
+
+void FixMetatomic::init_list(int id, NeighList *ptr) {
+    mta_list = ptr;
+}
+
+void FixMetatomic::initial_integrate(int /*vflag*/) {
+    // This function performs ML-driven position and momentum updates
+    // It uses a trained model to predict new positions and momenta at each timestep
+
+    double** x = atom->x;
+    double** v = atom->v;
+    double** f = atom->f;
+    double* rmass = atom->rmass;
+
+    int nlocal = atom->nlocal;
+
+    double *mass = atom->mass;
+    int *type = atom->type;
+    int *mask = atom->mask;
+    if (igroup == atom->firstgroup) {
+        nlocal = atom->nfirst;
+    }
+
+    // Apply velocity corrections from forces added after post_force
+    // This handles stochastic forces from Langevin thermostats by applying only the
+    // incremental force (f_current - f_snapshot) to velocities. The remaining half-step
+    // is done in final_integrate(); this is the first O in an OBABO integrator.
+    double dtf = 0.5 * update->dt * force->ftm2v;
+    double m_i;
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            // Apply any force added by other fixes to velocities
+            // rmass is per-atom mass (if used), otherwise use type-based mass
+            m_i = rmass ? rmass[i] : mass[type[i]];
+            v[i][0] += f[i][0] * dtf / m_i;
+            v[i][1] += f[i][1] * dtf / m_i;
+            v[i][2] += f[i][2] * dtf / m_i;
+        }
+    }
+
+    auto dtype = torch::kFloat64;
+    if (mta_data->capabilities->dtype() == "float64") {
+        dtype = torch::kFloat64;
+    } else if (mta_data->capabilities->dtype() == "float32") {
+        dtype = torch::kFloat32;
+    } else {
+        error->all(FLERR, "the model requested an unsupported dtype '{}'", mta_data->capabilities->dtype());
+    }
+
+    // transform from LAMMPS to metatomic System
+    auto system = this->system_adaptor->system_from_lmp(
+        mta_list,
+        static_cast<bool>(vflag_global),
+        dtype,
+        mta_data->device
+    );
+
+    // add the required additional inputs
+    this->system_adaptor->add_masses(system, 1.0);
+    this->system_adaptor->add_momenta(system, this->momentum_conversion_factor);
+
+    // Configure selected atoms for evaluation
+    // Only run the calculation for atoms in the current group
+    mta_data->selected_atoms_values.resize_({group->count(igroup), 2});
+    mta_data->selected_atoms_values.index_put_({torch::indexing::Slice(), 0}, 0);
+    int64_t idx = 0;
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            mta_data->selected_atoms_values.index_put_({idx, 1}, i);
+            idx++;
+        }
+    }
+
+    auto selected_atoms = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system", "atom"}, mta_data->selected_atoms_values
+    );
+    mta_data->evaluation_options->set_selected_atoms(selected_atoms);
+
+    // Call the ML model to predict new positions and momenta
+    torch::IValue result_ivalue;
+    try {
+        result_ivalue = mta_data->model->forward({
+            std::vector<metatomic_torch::System>{system},
+            mta_data->evaluation_options,
+            mta_data->check_consistency
+        });
+    } catch (const std::exception& e) {
+        error->all(FLERR, "error evaluating the torch model: {}", e.what());
+    }
+
+    // Extract results from the model output
+    auto result = result_ivalue.toGenericDict();
+
+    // Extract predicted positions
+    auto positions_map = result.at("positions").toCustomClass<metatensor_torch::TensorMapHolder>();
+    auto positions_block = metatensor_torch::TensorMapHolder::block_by_id(positions_map, 0);
+    auto positions = positions_block->values().squeeze(-1).to(torch::kCPU).to(torch::kFloat64);
+    auto positions_samples = positions_block->samples()->values().to(torch::kCPU).contiguous();
+    assert(positions_block->samples()->size() == 2);
+    assert(positions_block->samples()->names()[0] == "system");
+    assert(positions_block->samples()->names()[1] == "atom");
+
+    // Extract predicted momenta
+    auto momenta_map = result.at("momenta").toCustomClass<metatensor_torch::TensorMapHolder>();
+    auto momenta_block = metatensor_torch::TensorMapHolder::block_by_id(momenta_map, 0);
+    auto momenta = momenta_block->values().squeeze(-1).to(torch::kCPU).to(torch::kFloat64);
+
+    // we use the positions samples to map back to LAMMPS atoms, so we need to
+    // check that the samples are the same for momenta
+    assert(*momenta_block->samples() == *positions_block->samples());
+
+    // Convert momenta back from model units to LAMMPS velocity units
+    // This reverses the unit conversion applied before the model call
+    momenta = momenta / this->momentum_conversion_factor;
+
+    // Get old center of mass (and its velocity) before updating positions and velocities
+    std::array<double, 3> com_old = {0.0, 0.0, 0.0};
+    std::array<double, 3> com_velocity_old = {0.0, 0.0, 0.0};
+    double total_mass = 0.0;
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            double m_i = rmass ? rmass[i] : mass[type[i]];
+            com_old[0] += x[i][0] * m_i;
+            com_old[1] += x[i][1] * m_i;
+            com_old[2] += x[i][2] * m_i;
+            com_velocity_old[0] += v[i][0] * m_i;
+            com_velocity_old[1] += v[i][1] * m_i;
+            com_velocity_old[2] += v[i][2] * m_i;
+            total_mass += m_i;
+        }
+    }
+    if (total_mass > 0.0) {
+        com_old[0] /= total_mass;
+        com_old[1] /= total_mass;
+        com_old[2] /= total_mass;
+        com_velocity_old[0] /= total_mass;
+        com_velocity_old[1] /= total_mass;
+        com_velocity_old[2] /= total_mass;
+    }
+
+    // Apply ML predictions to LAMMPS atoms
+    auto positions_accessor = positions.accessor<double, 2>();
+    auto momenta_accessor = momenta.accessor<double, 2>();
+    auto positions_samples_accessor = positions_samples.accessor<int32_t, 2>();
+    auto& mta_to_lmp = this->system_adaptor->mta_to_lmp;
+    for (int64_t i = 0; i < positions.size(0); i++) {
+        auto atom_i = mta_to_lmp[positions_samples_accessor[i][1]];
+        assert(atom_i < nlocal);
+        if (mask[atom_i] & groupbit) {
+            double m_i = rmass ? rmass[atom_i] : mass[type[atom_i]];
+
+            // Update positions with ML predictions
+            x[atom_i][0] = positions_accessor[i][0];
+            x[atom_i][1] = positions_accessor[i][1];
+            x[atom_i][2] = positions_accessor[i][2];
+
+            // Update velocities from predicted momenta
+            v[atom_i][0] = momenta_accessor[i][0] / m_i;
+            v[atom_i][1] = momenta_accessor[i][1] / m_i;
+            v[atom_i][2] = momenta_accessor[i][2] / m_i;
+        }
+    }
+
+    std::array<double, 3> com_new = {0.0, 0.0, 0.0};
+    std::array<double, 3> com_velocity_new = {0.0, 0.0, 0.0};
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            double m_i = rmass ? rmass[i] : mass[type[i]];
+            com_new[0] += x[i][0] * m_i;
+            com_new[1] += x[i][1] * m_i;
+            com_new[2] += x[i][2] * m_i;
+            com_velocity_new[0] += v[i][0] * m_i;
+            com_velocity_new[1] += v[i][1] * m_i;
+            com_velocity_new[2] += v[i][2] * m_i;
+        }
+    }
+    if (total_mass > 0.0) {
+        com_new[0] /= total_mass;
+        com_new[1] /= total_mass;
+        com_new[2] /= total_mass;
+        com_velocity_new[0] /= total_mass;
+        com_velocity_new[1] /= total_mass;
+        com_velocity_new[2] /= total_mass;
+    }
+
+    // Adjust positions and velocities to preserve center of mass motion, namely
+    // conservation of momentum of the center of mass and uniform linear motion of the
+    // center of mass.
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            // Update positions with ML predictions
+            x[i][0] = x[i][0] - com_new[0] + com_old[0] + com_velocity_old[0] * update->dt;
+            x[i][1] = x[i][1] - com_new[1] + com_old[1] + com_velocity_old[1] * update->dt;
+            x[i][2] = x[i][2] - com_new[2] + com_old[2] + com_velocity_old[2] * update->dt;
+            v[i][0] = v[i][0] - com_velocity_new[0] + com_velocity_old[0];
+            v[i][1] = v[i][1] - com_velocity_new[1] + com_velocity_old[1];
+            v[i][2] = v[i][2] - com_velocity_new[2] + com_velocity_old[2];
+        }
+    }
+}
+
+void FixMetatomic::post_force(int /*vflag*/) {
+    // Set the forces that comes from pair_style, bond_style, etc. to zero.
+    //
+    // This way we can isolate any forces that are added after this point (e.g.
+    // Langevin thermostat forces) and add them during final_integrate().
+    //
+    // Crucially, this means that fix metatomic needs to be the first fix in the
+    // post_force() sequence, i.e., the user must have it before any other fix
+    // that adds forces in the input script.
+
+    double **f = atom->f;
+    int *mask = atom->mask;
+
+    int nlocal = atom->nlocal;
+    if (igroup == atom->firstgroup) {
+        nlocal = atom->nfirst;
+    }
+
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            f[i][0] = 0.0;
+            f[i][1] = 0.0;
+            f[i][2] = 0.0;
+        }
+    }
+}
+
+void FixMetatomic::final_integrate() {
+    // Apply velocity corrections from forces that were added after post_force
+    //
+    // This handles stochastic forces from Langevin thermostats:
+    // - initial_integrate: ML model updates positions and velocities
+    // - post_force: we snapshot forces (includes pair, bond, and Langevin
+    //   forces)
+    // - Between post_force and final_integrate: additional forces may be added
+    // - final_integrate: we apply only the force difference as a velocity
+    //   correction
+    //
+    // This ensures Langevin forces properly affect the dynamics while allowing
+    // the ML model to handle the deterministic evolution. The first half-step
+    // is done in initial_integrate(); this is the second O in an OBABO integrator.
+
+    double dtf = 0.5 * update->dt * force->ftm2v;
+
+    double** v = atom->v;
+    double** f = atom->f;
+    double* rmass = atom->rmass;
+    double* mass = atom->mass;
+    int* type = atom->type;
+    double m_i;
+
+    int nlocal = atom->nlocal;
+    int* mask = atom->mask;
+    if (igroup == atom->firstgroup) nlocal = atom->nfirst;
+
+    for (int i = 0; i < nlocal; i++) {
+        if (mask[i] & groupbit) {
+            // Apply any force added by other fixes to velocities
+            m_i = rmass ? rmass[i] : mass[type[i]];
+            v[i][0] += f[i][0] * dtf / m_i;
+            v[i][1] += f[i][1] * dtf / m_i;
+            v[i][2] += f[i][2] * dtf / m_i;
+        }
+    }
+}
diff --git a/src/ML-METATOMIC/fix_metatomic.h b/src/ML-METATOMIC/fix_metatomic.h
new file mode 100644
index 00000000000..5c7e87048e4
--- /dev/null
+++ b/src/ML-METATOMIC/fix_metatomic.h
@@ -0,0 +1,80 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifdef FIX_CLASS
+// clang-format off
+FixStyle(metatomic, FixMetatomic);
+// clang-format on
+#else
+
+#ifndef LMP_FIX_METATOMIC_H
+#define LMP_FIX_METATOMIC_H
+
+#include "fix.h"
+
+#include <string>
+#include <optional>
+#include <memory>
+
+namespace c10 {
+    class Device;
+    enum class DeviceType: int8_t;
+}
+
+namespace at {
+    class Tensor;
+}
+
+namespace LAMMPS_NS {
+class MetatomicSystemAdaptor;
+class FixMetatomicData;
+
+class FixMetatomic : public Fix {
+public:
+    FixMetatomic(class LAMMPS *, int, char **);
+    ~FixMetatomic();
+
+    int setmask() override;
+    void init() override;
+
+    // Integration methods for ML-driven dynamics
+    void initial_integrate(int) override;  // ML prediction of positions/momenta
+    void post_force(int) override;         // Snapshot forces for Langevin compatibility
+    void final_integrate() override;       // Apply force corrections
+    void init_list(int id, NeighList *ptr) override;
+
+ protected:
+    virtual void pick_device(c10::Device& device, const char* requested);
+
+    double momentum_conversion_factor;    // Conversion factor for momenta
+    double dt;                            // Timestep
+    std::string model_path;               // Path to ML model file
+    std::optional<std::string> extensions_directory;     // Directory for model extensions
+    std::optional<std::string> requested_device;         // Device to run model on (cpu/cuda/mps)
+
+    // Metatomic model data and configuration
+    FixMetatomicData* mta_data;
+    NeighList *mta_list;
+    int mta_list_reqid;
+
+    // Mapping from LAMMPS atom types to metatomic model types
+    int32_t *type_mapping;
+
+    // Helper class to convert between LAMMPS and metatomic representations
+    std::unique_ptr<MetatomicSystemAdaptor> system_adaptor;
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
+#endif
diff --git a/src/ML-METATOMIC/metatomic_system.cpp b/src/ML-METATOMIC/metatomic_system.cpp
index 1c975eba067..00640b5641f 100644
--- a/src/ML-METATOMIC/metatomic_system.cpp
+++ b/src/ML-METATOMIC/metatomic_system.cpp
@@ -548,3 +548,131 @@ metatomic_torch::System MetatomicSystemAdaptor::system_from_lmp(
 
     return system;
 }
+
+void MetatomicSystemAdaptor::add_masses(metatomic_torch::System& system, double unit_conversion) {
+    double* rmass = atom->rmass;
+    double* mass = atom->mass;
+    int* type = atom->type;
+
+    auto total_n_atoms = atom->nlocal + atom->nghost;
+
+    auto device = system->device();
+    auto dtype = system->scalar_type();
+
+    auto mta_to_lmp_tensor = torch::from_blob(
+        mta_to_lmp.data(),
+        {static_cast<int64_t>(mta_to_lmp.size())},
+        torch::TensorOptions().dtype(torch::kInt).device(torch::kCPU)
+    );
+
+    // gather masses (per-atom) in a tensor and ship to device
+    torch::Tensor masses;
+    auto float_tensor_options = torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU);
+    if (rmass) {
+        masses = torch::from_blob(
+            rmass,
+            {total_n_atoms},
+            float_tensor_options.requires_grad(false)
+        );
+    } else {
+        // need to map from atom type to mass
+        masses = torch::empty({total_n_atoms}, float_tensor_options);
+        auto masses_accessor = masses.accessor<double, 1>();
+        for (int i=0; i<total_n_atoms; i++) {
+            masses_accessor[i] = mass[type[i]];
+        }
+    }
+
+    masses = masses.index_select(0, mta_to_lmp_tensor);
+    masses = masses * unit_conversion;
+
+    auto keys = metatensor_torch::LabelsHolder::single()->to(device);
+    auto label_tensor_options = torch::TensorOptions().dtype(torch::kInt32).device(device);
+    auto samples_values = torch::column_stack({
+        torch::zeros(system->size(), label_tensor_options).unsqueeze(1),
+        torch::arange(system->size(), label_tensor_options).unsqueeze(1)
+    });
+    auto samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system","atom"},
+        samples_values,
+        metatensor::assume_unique{}
+    );
+    auto properties = metatensor_torch::LabelsHolder::single()->to(device);
+    auto block = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+        masses.to(dtype).to(device).unsqueeze(-1),  // add property dimension
+        samples,
+        std::vector<metatensor_torch::Labels>{},
+        properties
+    );
+    auto tensor = torch::make_intrusive<metatensor_torch::TensorMapHolder>(
+        keys,
+        std::vector<metatensor_torch::TensorBlock>{block}
+    );
+
+    system->add_data("masses", tensor, /*override=*/true);
+}
+
+
+void MetatomicSystemAdaptor::add_momenta(metatomic_torch::System& system, double unit_conversion) {
+    double* rmass = atom->rmass;
+    double* mass = atom->mass;
+    double** v = atom->v;
+    int* type = atom->type;
+
+    auto total_n_atoms = atom->nlocal + atom->nghost;
+
+    auto device = system->device();
+    auto dtype = system->scalar_type();
+
+    auto mta_to_lmp_tensor = torch::from_blob(
+        mta_to_lmp.data(),
+        {static_cast<int64_t>(mta_to_lmp.size())},
+        torch::TensorOptions().dtype(torch::kInt).device(torch::kCPU)
+    );
+
+    // gather momenta (per-atom) in a tensor and ship to device
+    torch::Tensor momenta = torch::zeros({total_n_atoms, 3}, torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU));
+    auto momenta_accessor = momenta.accessor<double, 2>();
+    for (int i=0; i<total_n_atoms; i++) {
+        double m = rmass ? rmass[i] : mass[type[i]];
+        momenta_accessor[i][0] = m * v[i][0];
+        momenta_accessor[i][1] = m * v[i][1];
+        momenta_accessor[i][2] = m * v[i][2];
+    }
+
+    momenta = momenta.index_select(0, mta_to_lmp_tensor);
+    momenta = momenta * unit_conversion;
+
+    auto keys = metatensor_torch::LabelsHolder::single()->to(device);
+
+    auto label_tensor_options = torch::TensorOptions().dtype(torch::kInt32).device(device);
+    auto samples_values = torch::column_stack({
+        torch::zeros(system->size(), label_tensor_options).unsqueeze(1),
+        torch::arange(system->size(), label_tensor_options).unsqueeze(1)
+    });
+    auto samples = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"system","atom"},
+        samples_values,
+        metatensor::assume_unique{}
+    );
+
+    auto component_values = torch::arange(3, label_tensor_options).unsqueeze(1);
+    auto component = torch::make_intrusive<metatensor_torch::LabelsHolder>(
+        std::vector<std::string>{"xyz"}, component_values
+    );
+
+    auto properties = metatensor_torch::LabelsHolder::single()->to(device);
+
+    auto block = torch::make_intrusive<metatensor_torch::TensorBlockHolder>(
+        momenta.to(dtype).to(device).unsqueeze(-1),
+        samples,
+        std::vector<metatensor_torch::Labels>{component},
+        properties
+    );
+    auto tensor = torch::make_intrusive<metatensor_torch::TensorMapHolder>(
+        keys,
+        std::vector<metatensor_torch::TensorBlock>{block}
+    );
+
+    system->add_data("momenta", tensor, /*override=*/true);
+}
diff --git a/src/ML-METATOMIC/metatomic_system.h b/src/ML-METATOMIC/metatomic_system.h
index 6e3270a2878..38fa9ed62d8 100644
--- a/src/ML-METATOMIC/metatomic_system.h
+++ b/src/ML-METATOMIC/metatomic_system.h
@@ -75,6 +75,13 @@ class MetatomicSystemAdaptor : public Pointers {
         torch::Device device
     );
 
+    // Add masses as extra data to this system, only for atoms which are not
+    // periodic images of other atoms
+    virtual void add_masses(metatomic_torch::System& system, double unit_conversion);
+    // Add momenta as extra data to this system, only for atoms which are not
+    // periodic images of other atoms
+    virtual void add_momenta(metatomic_torch::System& system, double unit_conversion);
+
     // Explicit strain for virial calculations. This uses the same dtype/device
     // as LAMMPS data (positions, …)
     torch::Tensor strain;
diff --git a/src/ML-METATOMIC/metatomic_types.cpp b/src/ML-METATOMIC/metatomic_types.cpp
index 2867e0e3fea..ab5fe167a89 100644
--- a/src/ML-METATOMIC/metatomic_types.cpp
+++ b/src/ML-METATOMIC/metatomic_types.cpp
@@ -22,12 +22,7 @@
 
 using namespace LAMMPS_NS;
 
-PairMetatomicData::PairMetatomicData(std::string length_unit):
-    device(torch::kCPU),
-    check_consistency(false),
-    non_conservative(false),
-    max_cutoff(-1)
-{
+CommonMetatomicData::CommonMetatomicData(std::string length_unit): device(torch::kCPU) {
     auto options = torch::TensorOptions().dtype(torch::kInt32);
     this->selected_atoms_values = torch::zeros({0, 2}, options);
 
@@ -36,7 +31,7 @@ PairMetatomicData::PairMetatomicData(std::string length_unit):
     this->evaluation_options->set_length_unit(std::move(length_unit));
 }
 
-void PairMetatomicData::load_model(
+void CommonMetatomicData::load_model(
    LAMMPS* lmp,
    const char* path,
    const char* extensions_directory
diff --git a/src/ML-METATOMIC/metatomic_types.h b/src/ML-METATOMIC/metatomic_types.h
index ce1ee64ef8a..9565e76a35a 100644
--- a/src/ML-METATOMIC/metatomic_types.h
+++ b/src/ML-METATOMIC/metatomic_types.h
@@ -25,9 +25,8 @@
 
 namespace LAMMPS_NS {
 
-struct PairMetatomicData {
-   PairMetatomicData(std::string length_unit);
-
+struct CommonMetatomicData {
+   CommonMetatomicData(std::string length_unit);
    void load_model(LAMMPS* lmp, const char* path, const char* extensions_directory);
 
    // the metatomic model
@@ -41,32 +40,37 @@ struct PairMetatomicData {
    // run-time evaluation options, decided by this class
    metatomic_torch::ModelEvaluationOptions evaluation_options;
 
+   // should metatomic check the data LAMMPS send to the model
+   // and the data the model returns?
+   bool check_consistency = false;
+   // how far away the model needs to know about neighbors
+   double max_cutoff = -1;
+
+   // allocation cache for the selected atoms
+   torch::Tensor selected_atoms_values;
+};
+
+struct PairMetatomicData: public CommonMetatomicData {
+   PairMetatomicData(std::string length_unit): CommonMetatomicData(std::move(length_unit)) {}
+
    // the energy output we'll request from a model
    metatomic_torch::ModelOutput energy_output;
    // wether the model capabilities say that it can do per-atom energies
-   bool is_energy_output_per_atom;
+   bool is_energy_output_per_atom = false;
 
    // energy uncertainty output we'll request from a model, or nullptr if the
    // model does not have such output
    metatomic_torch::ModelOutput uncertainty_output;
    // threshold for energy uncertainty warnings
-   double uncertainty_threshold;
+   double uncertainty_threshold = 0.0;
 
    // non-conservative forces/stress outputs we'll request from a model, or
    // nullptr if the model does not have such outputs
    metatomic_torch::ModelOutput nc_forces_output;
    metatomic_torch::ModelOutput nc_stress_output;
 
-   // should metatomic check the data LAMMPS send to the model
-   // and the data the model returns?
-   bool check_consistency;
    // whether non-conservative forces and stresses should be used
-   bool non_conservative;
-   // how far away the model needs to know about neighbors
-   double max_cutoff;
-
-   // allocation cache for the selected atoms
-   torch::Tensor selected_atoms_values;
+   bool non_conservative = false;
 
    // energy key for the model
    std::string energy_key;
@@ -78,6 +82,10 @@ struct PairMetatomicData {
    std::string nc_stress_key;
 };
 
+struct FixMetatomicData: public CommonMetatomicData {
+   FixMetatomicData(std::string length_unit): CommonMetatomicData(std::move(length_unit)) {}
+};
+
 }    // namespace LAMMPS_NS
 
 #endif
diff --git a/src/ML-METATOMIC/pair_metatomic.cpp b/src/ML-METATOMIC/pair_metatomic.cpp
index 88cc83bb5a2..a30c7ade7b0 100644
--- a/src/ML-METATOMIC/pair_metatomic.cpp
+++ b/src/ML-METATOMIC/pair_metatomic.cpp
@@ -379,7 +379,6 @@ void PairMetatomic::settings(int argc, char ** argv) {
 }
 
 void PairMetatomic::pick_device(torch::Device& device, const char* requested) {
-
     torch::optional<std::string> requested_string;
     torch::DeviceType device_type;
 
diff --git a/src/ML-METATOMIC/pair_metatomic.h b/src/ML-METATOMIC/pair_metatomic.h
index 50d49f26042..b8c5dd14b6b 100644
--- a/src/ML-METATOMIC/pair_metatomic.h
+++ b/src/ML-METATOMIC/pair_metatomic.h
@@ -33,11 +33,8 @@ PairStyle(metatomic_9, PairMetatomic);
 
 #include "pair.h"
 
-#include <vector>
-
 namespace c10 {
     class Device;
-    enum class DeviceType: int8_t;
 }
 
 namespace at {
@@ -66,10 +63,6 @@ class PairMetatomic : public Pair {
     virtual void store_forces(const at::Tensor& forces_tensor);
 
 protected:
-    // get the set of devices both available on the current machine and supported
-    // by the model
-    std::vector<c10::DeviceType> available_devices();
-
     // pick the correct device to use from the user request (or nullptr) in
     // `pair_style metatomic`
     virtual void pick_device(c10::Device& device, const char* requested);

From dd4d142926ea6d884a66ddb99fce3dafaf3252b3 Mon Sep 17 00:00:00 2001
From: Guillaume Fraux <luthaf@luthaf.fr>
Date: Fri, 9 Jan 2026 12:55:18 +0100
Subject: [PATCH 37/37] Set a binsize for fix metatomic on large boxes (#37)

---
 src/ML-METATOMIC/fix_metatomic.cpp | 11 +++++++++++
 1 file changed, 11 insertions(+)

diff --git a/src/ML-METATOMIC/fix_metatomic.cpp b/src/ML-METATOMIC/fix_metatomic.cpp
index ab8c95fbcd7..98a886eec8f 100644
--- a/src/ML-METATOMIC/fix_metatomic.cpp
+++ b/src/ML-METATOMIC/fix_metatomic.cpp
@@ -312,6 +312,17 @@ void FixMetatomic::init() {
 
         this->system_adaptor->add_nl_request(cutoff, options);
     }
+
+    // HACK: Explicitly set the binsize for the neighbor list if there is no
+    // pair_style that would set it instead.
+    //
+    // Otherwise, the default binsize of box[0] is used, which crashes kokkos
+    // for large-ish boxes (~40A), and slow down the simulation for non-kokkos.
+    if (strcmp(force->pair_style, "none") == 0) {
+        neighbor->binsize_user = 0.5 * mta_data->max_cutoff;
+        neighbor->binsizeflag = 1;
+    }
+    // END HACK
 }
 
 void FixMetatomic::pick_device(c10::Device& device, const char* requested) {
